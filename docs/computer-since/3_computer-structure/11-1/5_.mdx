---
title: 메모리 할당과 페이지 교체 기법
description: 메모리 부족 시 어떤 페이지를 내보낼지 결정하는 다양한 알고리즘과 메모리 할당 방식을 배웁니다.
slug: memory-allocation-and-replacement
sidebar_position: 5
date: 2024-01-15
---

## 🎯 이번 시간의 목표

- 메모리 할당 방식의 종류와 차이 이해하기
- 페이지 폴트가 무엇인지 배우기
- 페이지 교체 알고리즘의 종류와 원리 학습하기
- 어떤 알고리즘이 효율적인지 비교하기

---

## 📌 메모리 할당 (Memory Allocation)

### 메모리 할당이란?

```
프로세스가 메모리를 필요로 할 때,
물리 메모리의 어디에 배치할지 결정하는 것
```

---

## 🔹 할당 방식 1: 고정 분할 (Fixed Partition)

### 개념

```
물리 메모리를 고정된 크기로 미리 분할
각 프로세스를 분할된 영역에 할당
```

### 메모리 레이아웃

```
물리 메모리:

┌─────────────────────┐
│   운영체제 영역     │  (고정, 함부로 접근 불가)
├─────────────────────┤
│   분할 1 (512MB)    │  → 프로세스 A
├─────────────────────┤
│   분할 2 (512MB)    │  → 프로세스 B
├─────────────────────┤
│   분할 3 (512MB)    │  → 프로세스 C
├─────────────────────┤
│   분할 4 (512MB)    │  → 빈 공간
└─────────────────────┘

(16GB 메모리를 4개의 512MB로 분할)
```

### 장점 ✅

```
1. 구현이 단순하고 이해하기 쉬움
2. 주소 변환이 빠름
3. 관리 복잡도가 낮음
```

### 단점 ✗

```
1. 내부 단편화 발생
   → 프로세스가 512MB보다 작으면 낭비

2. 외부 단편화는 없음
   (분할이 고정이므로)

3. 멀티프로그래밍 수준 제한
   → 분할 개수만큼만 프로세스 실행 가능

예) 512MB × 4 = 최대 4개 프로세스
```

### 예시

```
상황: 300MB 프로세스가 512MB 분할에 배치

┌──────────────────┐
│  프로세스 A      │  300MB 사용
│  (300MB)         │
├──────────────────┤
│  낭비되는 공간   │  212MB 낭비 (내부 단편화)
└──────────────────┘

문제: 212MB는 그 누구도 사용할 수 없다!
```

---

## 🔸 할당 방식 2: 가변 분할 (Variable Partition) / 세그멘테이션

### 개념

```
필요한 크기만큼 메모리 할당
프로세스 크기에 따라 유동적으로 분할
```

### 메모리 레이아웃 (초기)

```
┌─────────────────────┐
│   운영체제 영역     │  
├─────────────────────┤
│   프로세스 A (300MB)│  
├─────────────────────┤
│   프로세스 B (200MB)│  
├─────────────────────┤
│   프로세스 C (150MB)│  
├─────────────────────┤
│   빈 공간           │  (9.35GB)
└─────────────────────┘
```

### 장점 ✅

```
1. 내부 단편화 거의 없음
   → 필요한 크기만 할당

2. 메모리 활용율 높음
   → 프로세스 크기와 정확히 맞춤

3. 멀티프로그래밍 수준 높음
   → 많은 프로세스 실행 가능
```

### 단점 ✗

```
1. 외부 단편화 발생
   → 여러 작은 빈 공간이 분산됨
   
2. 주소 변환이 복잡
   → 동적으로 변하는 크기를 관리해야 함
   
3. 메모리 관리가 어려움
   → 프로세스 종료 시 조각 처리 필요

4. 메모리 압축 필요
   → 주기적으로 빈 공간을 정리해야 함
```

### 외부 단편화 예시

```
프로세스 A 종료 후:

┌─────────────────────┐
│   운영체제 영역     │  
├─────────────────────┤
│   빈 공간 (300MB)   │  ← A가 종료됨
├─────────────────────┤
│   프로세스 B (200MB)│  
├─────────────────────┤
│   프로세스 C (150MB)│  
├─────────────────────┤
│   빈 공간 (9.35GB)  │  
└─────────────────────┘

총 빈 공간: 300MB + 9.35GB = 9.65GB

새 프로세스 D (400MB)가 필요하면?
→ 9.65GB > 400MB 인데도
   연속된 공간이 없어서 배치 불가!
   (외부 단편화)
```

---

## 🔥 페이지 폴트 (Page Fault)

### 페이지 폴트란?

```
프로세스가 필요한 페이지가 물리 메모리에 없는 경우
```

### 발생 상황

```
Step 1: CPU가 주소를 요청
        "페이지 5의 데이터 줘"
        
Step 2: MMU가 페이지 테이블 확인
        "페이지 5은... 메모리에 없네?"
        
Step 3: 페이지 폴트 발생!
        ⚠️ 예외(Exception) 발생
        
Step 4: 운영체제 개입
        "스왑 영역에서 페이지 5을 불러올게"
        
Step 5: 페이지 로드
        하드디스크에서 메모리로 복사
        (약 5-10ms 소요)
        
Step 6: 재시도
        같은 요청을 다시 처리
        이번엔 메모리에 있음!
```

### 처리 흐름도

```
┌─────────────────────────┐
│  CPU가 주소 접근 시도   │
└──────────┬──────────────┘
           │
           ▼
    ┌──────────────┐
    │ 메모리에     │
    │  있나?       │
    └──────┬───────┘
           │
       Yes ✓  No ✗
           │       │
           ▼       ▼
        [데이터 반환] [페이지 폴트 발생]
                        │
                        ▼
                  [스왑 영역에서 로드]
                        │
                        ▼
                  [메모리에 배치]
                        │
                        ▼
                  [요청 재시도]
                        │
                        ▼
                  [데이터 반환]
```

### 페이지 폴트의 비용

```
메모리 접근: ~1 나노초 (ns)
페이지 폴트: ~10,000,000 나노초 (10ms)

차이: 약 1,000만배 느림!

따라서 페이지 폴트를 최소화하는 것이 중요
```

---

## 🔄 페이지 교체 (Page Replacement)

### 필요성

```
상황: 물리 메모리가 가득 찼는데, 새 페이지가 필요하다!

선택지:
1. 어떤 페이지를 메모리에서 제거할 것인가?
2. 어떤 페이지를 스왑 영역으로 내보낼 것인가?

이를 결정하는 알고리즘이 페이지 교체 알고리즘
```

### 기본 절차

```
Step 1: 페이지 폴트 발생
Step 2: 메모리에서 제거할 페이지 선택
Step 3: 선택된 페이지를 스왑 영역에 저장
Step 4: 필요한 페이지를 메모리에 로드
Step 5: 페이지 테이블 업데이트
Step 6: 요청한 명령어 재시도
```

---

## 📊 페이지 교체 알고리즘

### 알고리즘 1: FIFO (First In First Out)

#### 개념

```
가장 오래전에 메모리에 들어온 페이지를 먼저 제거
```

#### 동작 원리

```
메모리에 페이지 들어온 순서:
페이지 1 (가장 먼저) → 페이지 2 → 페이지 3 (가장 나중)

새 페이지가 필요하면:
페이지 1을 제거 (가장 오래됨)
```

#### 예시

```
물리 메모리 크기: 3개 프레임

접근 순서: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5

┌─────────────────────────────────────────┐
│  1번 접근: [1,_,_]     (페이지 1 로드)  │
│  2번 접근: [1,2,_]     (페이지 2 로드)  │
│  3번 접근: [1,2,3]     (페이지 3 로드)  │
│  4번 접근: [4,2,3]  ✗  (페이지 1 제거, 4 로드) - 폴트!
│  1번 접근: [4,1,3]  ✗  (페이지 2 제거, 1 로드) - 폴트!
│  2번 접근: [4,1,2]  ✗  (페이지 3 제거, 2 로드) - 폴트!
│  5번 접근: [5,1,2]  ✗  (페이지 4 제거, 5 로드) - 폴트!
│  1번 접근: [5,1,2]     (메모리에 있음)
│  2번 접근: [5,1,2]     (메모리에 있음)
│  3번 접근: [5,1,3]  ✗  (페이지 2 제거, 3 로드) - 폴트!
│  4번 접근: [4,1,3]  ✗  (페이지 5 제거, 4 로드) - 폴트!
│  5번 접근: [4,5,3]  ✗  (페이지 1 제거, 5 로드) - 폴트!
└─────────────────────────────────────────┘

페이지 폴트 횟수: 9회 / 12번 접근 = 75%
```

#### 장점 ✅

```
1. 구현이 매우 간단
   → 큐(Queue) 자료구조만 사용
   
2. 오버헤드가 적음
```

#### 단점 ✗

```
1. 성능이 좋지 않음
   → 자주 사용하는 페이지도 제거할 수 있음
   
2. 벨래디 이상(Belady's Anomaly)
   → 메모리 증가해도 성능이 나빠질 수 있음
```

---

### 알고리즘 2: LRU (Least Recently Used)

#### 개념

```
가장 최근에 사용되지 않은 페이지를 제거
최근에 자주 쓰는 페이지는 메모리에 유지
```

#### 동작 원리

```
페이지 사용 시간 기록:
페이지 1: 10시간 전 ← 이것 제거 (가장 오래 전)
페이지 2: 5시간 전
페이지 3: 1시간 전   ← 가장 최근

새 페이지가 필요하면 페이지 1 제거
```

#### 예시

```
같은 접근 순서로 재시도: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5

┌──────────────────────────────────────────────────┐
│  1번 접근: [1,_,_]       (페이지 1 사용)        │
│  2번 접근: [1,2,_]       (페이지 2 사용)        │
│  3번 접근: [1,2,3]       (페이지 3 사용)        │
│  4번 접근: [4,2,3]    ✗  (페이지 1 제거) - 폴트! │
│  1번 접근: [4,2,1]    ✗  (페이지 3 제거) - 폴트! │
│  2번 접근: [4,2,1]       (페이지 2 사용)        │
│  5번 접근: [4,5,1]    ✗  (페이지 2 제거) - 폴트! │
│  1번 접근: [4,5,1]       (페이지 1 사용)        │
│  2번 접근: [4,5,2]    ✗  (페이지 4 제거) - 폴트! │
│  3번 접근: [3,5,2]    ✗  (페이지 1 제거) - 폴트! │
│  4번 접근: [3,4,2]    ✗  (페이지 5 제거) - 폴트! │
│  5번 접근: [3,4,5]    ✗  (페이지 2 제거) - 폴트! │
└──────────────────────────────────────────────────┘

페이지 폴트 횟수: 8회 / 12번 접근 = 67%
(FIFO보다 나음!)
```

#### 장점 ✅

```
1. 성능이 좋음
   → 자주 쓰는 페이지는 메모리에 유지
   
2. 현실과 부합
   → 실제 프로그램 동작과 일치
   
3. FIFO보다 페이지 폴트 적음
```

#### 단점 ✗

```
1. 구현이 복잡
   → 페이지 사용 시간을 모두 기록해야 함
   
2. 오버헤드가 큼
   → 매번 타임스탬프 업데이트 필요
   
3. 하드웨어 지원 필요
   → 빠른 처리를 위해 특별한 하드웨어 필요
```

---

### 알고리즘 3: LFU (Least Frequently Used)

#### 개념

```
사용 빈도가 가장 낮은 페이지를 제거
자주 쓰는 페이지는 메모리에 유지
```

#### 동작 원리

```
페이지 사용 빈도 기록:
페이지 1: 1회 ← 이것 제거 (가장 드물게 사용)
페이지 2: 3회
페이지 3: 5회 ← 자주 사용

새 페이지가 필요하면 페이지 1 제거
```

#### 장점 ✅

```
1. 장기적 패턴 인식
   → 오래 걸린 패턴도 학습
```

#### 단점 ✗

```
1. 구현이 복잡
   → 사용 횟수를 모두 기록해야 함
   
2. 초기 데이터 영향 받음
   → 처음 자주 쓰던 페이지는 나중에도 유지됨
```

---

## 📈 알고리즘 비교

### 성능 비교

| 알고리즘 | FIFO | LRU | LFU |
|---------|------|-----|-----|
| **구현 복잡도** | ⭐ 낮음 | ⭐⭐⭐ 높음 | ⭐⭐⭐ 높음 |
| **성능** | ⭐ 낮음 | ⭐⭐⭐⭐ 높음 | ⭐⭐⭐ 중간 |
| **오버헤드** | ⭐ 적음 | ⭐⭐⭐ 많음 | ⭐⭐⭐ 많음 |
| **실무 사용** | ❌ 드물게 | ✅ 자주 | ⭐ 가끔 |

---

## 🎯 최적 알고리즘 (이론적)

### OPT (Optimal) 알고리즘

#### 개념

```
앞으로 가장 오래 사용되지 않을 페이지를 제거
```

#### 예시

```
현재 메모리: [1, 2, 3]
앞으로의 접근: 4, 1, 2, 5, 1, 3, 2, 1

분석:
페이지 1: 다음 사용은 4번 위치
페이지 2: 다음 사용은 5번 위치
페이지 3: 다음 사용은 6번 위치 (가장 오래 뒤)

→ 페이지 3 제거!
```

#### 특징

```
✅ 이론상 최고의 성능
❌ 실제로는 불가능 (미래를 알 수 없음)
📚 성능 비교의 기준으로 사용
```

---

## 💡 실무에서의 선택

### 현대 운영체제의 선택

```
Linux: LRU 변형 (Approximated LRU)
Windows: 여러 알고리즘 조합
macOS: LRU 기반

이유:
- 구현이 상대적으로 간단
- 성능이 좋음
- 오버헤드 허용 범위 내
```

### LRU 근사 구현

```
정확한 사용 시간 기록 대신,
"최근에 사용했는가?"만 판단

비트 사용:
페이지 1: recent_bit = 1 (최근 사용)
페이지 2: recent_bit = 0 (오래됨)

→ 페이지 2 제거
```

---

## 🎓 핵심 정리

### 메모리 할당

| 방식 | 특징 | 내부 단편화 | 외부 단편화 |
|------|------|----------|----------|
| **고정 분할** | 미리 분할 | 많음 | 없음 |
| **가변 분할** | 필요에 따라 | 적음 | 많음 |

### 페이지 교체 알고리즘

| 알고리즘 | 원칙 | 성능 | 구현 |
|---------|------|------|------|
| **FIFO** | 먼저 들어온 것 제거 | 낮음 | 쉬움 |
| **LRU** | 최근 미사용 제거 | 높음 | 어려움 |
| **LFU** | 빈도 낮은 것 제거 | 중간 | 어려움 |
| **OPT** | 가장 오래 미사용 제거 | 최고 | 불가능 |

---

## ❓ 자주 묻는 질문(FAQ)

**Q: LRU가 항상 FIFO보다 좋은가요?**

A: 일반적으로는 그렇습니다. 하지만 특수한 패턴(예: 순차 접근)에서는 비슷할 수 있습니다.

**Q: 페이지 폴트 오버헤드가 정말 크나요?**

A: 네, 메모리 접근은 나노초(ns) 단위인데, 페이지 폴트는 밀리초(ms) 단위입니다. 약 1000배 차이입니다!

**Q: 모든 프로세스가 같은 알고리즘을 사용하나요?**

A: 네, 일반적으로 운영체제가 결정한 하나의 알고리즘을 모든 프로세스가 사용합니다.

---

## 🚀 지금까지의 학습 정리

```
1장: 가상 메모리의 개념 이해
2장: 주소 매핑의 기본 원리
3장: 페이징 기법의 이해
4장: 주소 변환의 실전 계산
5장: 메모리 할당과 교체 기법 (현재 위치)

✅ 가상 메모리의 전반적인 개념 마스터!
```

---

## 📚 다음 학습 방향

### 심화 주제

1. **세그멘테이션**
   - 페이징과 다른 메모리 관리 기법
   - 페이징과의 장단점 비교

2. **다단계 페이지 테이블**
   - 큰 주소 공간의 효율적 관리
   - 메모리 낭비 감소

3. **가상 메모리 성능 최적화**
   - 캐시와의 상호작용
   - 프리페칭 기법

4. **메모리 보호**
   - 각 프로세스의 메모리 영역 보호
   - 접근 권한 관리

축하합니다! 가상 메모리의 기본을 모두 배웠습니다! 🎉