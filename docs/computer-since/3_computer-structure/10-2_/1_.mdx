---
title: "캐시 매핑 개요"
description: "캐시 메모리의 필요성과 사상 방식의 기본 개념을 이해합니다."
slug: "cache-mapping-overview"
sidebar_position: 1
---

# 캐시 매핑 개요

## 캐시 메모리란?

### 도서관 비유로 이해하기

여러분이 대학 도서관에서 공부한다고 상상해보세요.

```
📚 중앙 도서관 (주기억장치 RAM)
- 100만 권의 책 보유
- 책을 찾아오는데 10분 소요
- 매우 크지만 느림

📖 개인 책상 (캐시 메모리)
- 10권만 놓을 수 있음
- 즉시 접근 가능 (1초)
- 매우 작지만 빠름
```

자주 사용하는 책 10권을 책상에 두면, 매번 도서관에 가지 않아도 됩니다!  
이것이 바로 **캐시의 원리**입니다.

:::tip 캐시의 핵심 아이디어
자주 사용하는 데이터를 빠른 메모리(캐시)에 복사해두어, 느린 메모리(RAM)에 접근하는 횟수를 줄입니다!
:::

### 실제 컴퓨터에서의 속도 차이

현대 컴퓨터의 메모리 계층구조를 보면:

```
CPU 레지스터: 0.3ns (가장 빠름)
    ↓
L1 캐시: 1ns (약 3배 느림)
    ↓
L2 캐시: 3~10ns (약 10배 느림)
    ↓
L3 캐시: 10~20ns (약 30배 느림)
    ↓
주기억장치(RAM): 100ns (약 300배 느림!)
    ↓
SSD: 100,000ns = 0.1ms (약 300,000배 느림!)
    ↓
HDD: 10,000,000ns = 10ms (약 30,000,000배 느림!)
```

:::info 속도 차이의 실감
만약 CPU 레지스터 접근을 1초로 환산하면:
- L1 캐시: 3초
- RAM: 5분
- SSD: 약 3.5일
- HDD: 약 1년!

이 정도로 속도 차이가 큽니다!
:::

### 캐시가 없다면?

```c
// 간단한 배열 합계 계산
int sum = 0;
int arr[1000];

for (int i = 0; i < 1000; i++) {
    sum += arr[i];  // 매번 RAM 접근 (100ns)
}

// 캐시 없이: 1000 × 100ns = 100,000ns = 0.1ms
// 캐시 있으면: 대부분 L1 캐시 접근 (1ns) = 약 1,000ns = 0.001ms
// 성능 차이: 100배!
```

---

## 캐시의 동작 원리

### 지역성의 원리 (Principle of Locality)

캐시가 효과적인 이유는 프로그램이 **지역성**을 가지기 때문입니다.

#### 1. 시간 지역성 (Temporal Locality)

최근에 접근한 데이터를 다시 접근할 가능성이 높습니다.

```c
// 예시: 반복문에서 변수 i를 계속 사용
for (int i = 0; i < 100; i++) {  // i를 100번 접근
    printf("%d ", i);
}
```

**실생활 비유:** 오늘 읽은 책을 내일도 다시 볼 가능성이 높습니다.

#### 2. 공간 지역성 (Spatial Locality)

접근한 데이터 근처의 데이터를 곧 접근할 가능성이 높습니다.

```c
// 예시: 배열의 연속된 요소 접근
int arr[100];
for (int i = 0; i < 100; i++) {
    arr[i] = i;  // arr[0], arr[1], arr[2]... 순차적 접근
}
```

**실생활 비유:** 사전에서 "Apple"을 찾으면, "Application"도 곧 찾을 수 있습니다 (같은 페이지에 있음).

### 캐시 Hit와 Miss

```
CPU가 데이터 요청
    ↓
캐시에 있나요?
    ↓
┌───YES─────────────────┐
│ 캐시 Hit!             │
│ 캐시에서 바로 반환     │
│ 속도: 빠름 (1~10ns)   │
└───────────────────────┘
    ↓
┌───NO──────────────────┐
│ 캐시 Miss!            │
│ RAM에서 가져옴        │
│ 속도: 느림 (100ns)    │
│ + 캐시에 복사 저장    │
└───────────────────────┘
```

:::note 용어 정리
- **캐시 Hit (적중)**: 찾는 데이터가 캐시에 있는 경우 ✅
- **캐시 Miss (실패)**: 찾는 데이터가 캐시에 없어서 RAM에서 가져와야 하는 경우 ❌
- **Hit Rate (적중률)**: 전체 접근 중 Hit의 비율
:::

---

## 캐시의 기본 구조

### 블록 (Block)

데이터를 주고받는 기본 단위입니다.

```
왜 1바이트씩이 아니라 블록 단위로 가져올까요?

이유: 공간 지역성!
arr[0]을 읽으면 곧 arr[1], arr[2]도 읽을 것입니다.
그래서 한 번에 여러 바이트를 가져오는 것이 효율적입니다.
```

**블록 크기 예시:**

```
1블록 = 4바이트 (32비트 시스템)
┌─────────┬─────────┬─────────┬─────────┐
│ Byte 0  │ Byte 1  │ Byte 2  │ Byte 3  │
└─────────┴─────────┴─────────┴─────────┘

1블록 = 8바이트 (64비트 시스템, 일반적)
┌───┬───┬───┬───┬───┬───┬───┬───┐
│ 0 │ 1 │ 2 │ 3 │ 4 │ 5 │ 6 │ 7 │
└───┴───┴───┴───┴───┴───┴───┴───┘

1블록 = 64바이트 (현대 CPU의 캐시 라인)
┌─────────────────────────────────┐
│   64바이트의 연속된 데이터        │
└─────────────────────────────────┘
```

### 캐시 라인 (Cache Line)

캐시의 저장 공간 하나를 의미합니다.

```
캐시 라인의 구조:
┌───────┬──────┬──────────────────┐
│ Valid │ Tag  │   Data Block     │
│  Bit  │      │   (실제 데이터)   │
└───────┴──────┴──────────────────┘

- Valid Bit: 이 라인에 유효한 데이터가 있는가? (0 또는 1)
- Tag: 어떤 메모리 블록의 데이터인가? (식별자)
- Data Block: 실제 데이터 (블록 크기만큼)
```

**예시: 4개의 캐시 라인**

```
캐시 메모리
┌─────────┬───────┬──────┬────────────────┐
│ Line 0  │ Valid │ Tag  │ Data Block     │
├─────────┼───────┼──────┼────────────────┤
│ Line 1  │ Valid │ Tag  │ Data Block     │
├─────────┼───────┼──────┼────────────────┤
│ Line 2  │ Valid │ Tag  │ Data Block     │
├─────────┼───────┼──────┼────────────────┤
│ Line 3  │ Valid │ Tag  │ Data Block     │
└─────────┴───────┴──────┴────────────────┘
```

### 메모리 주소의 구성

CPU가 사용하는 메모리 주소는 여러 부분으로 나뉩니다:

```
전체 메모리 주소 (예: 16비트)
┌─────────────┬──────────┬────────────┐
│    태그      │  인덱스   │  오프셋     │
│   (Tag)     │ (Index)  │  (Offset)  │
└─────────────┴──────────┴────────────┘
     어떤 블록?   어느 라인?  몇 번째 바이트?

각 부분의 역할:
1. 오프셋 (Offset): 블록 내에서 몇 번째 바이트인지
2. 인덱스 (Index): 캐시의 어느 라인에 저장할지
3. 태그 (Tag): 여러 블록 중 어떤 블록인지 식별
```

**구체적인 예시:**

```
조건:
- 16비트 주소
- 블록 크기: 4바이트 = 2² → 오프셋 2비트
- 캐시 라인: 8개 = 2³ → 인덱스 3비트
- 나머지: 태그 = 16 - 2 - 3 = 11비트

주소: 0x1A4C = 0001 1010 0100 1100

분해:
┌─────────────┬─────┬────┐
│ 00011010010 │ 011 │ 00 │
│     태그     │인덱스│오프셋│
│    (210)    │ (3) │(0) │
└─────────────┴─────┴────┘

해석:
- 블록 210의 데이터
- 캐시 라인 3번에 저장
- 블록의 0번째 바이트
```

---

## 사상 방식이란?

### 문제 상황

```
주기억장치: 1,048,576개의 블록 (1MB)
캐시: 8개의 라인만 사용 가능

질문: 100만 개의 블록을 8개의 라인에 어떻게 배치할까요?
```

이것이 바로 **매핑(Mapping) 또는 사상(寫像)**의 문제입니다!

### 사상 방식의 종류

컴퓨터 구조에서는 3가지 주요 방식이 있습니다:

#### 1. 직접 사상 (Direct Mapping)

```
규칙: 블록 번호 % 캐시 라인 수 = 캐시 라인 번호

블록 0 → 라인 0
블록 1 → 라인 1
...
블록 7 → 라인 7
블록 8 → 라인 0  ← 블록 0과 같은 위치!
블록 9 → 라인 1
```

**장점:** 빠르고 간단  
**단점:** 충돌이 많이 발생

#### 2. 연관 사상 (Fully Associative Mapping)

```
규칙: 없음! 아무 라인에나 저장 가능

블록 0 → 라인 3
블록 1 → 라인 0
블록 2 → 라인 7
블록 3 → 라인 1
...
(자유롭게 배치)
```

**장점:** 충돌 없음, 유연함  
**단점:** 하드웨어 복잡, 느림

#### 3. 집합 연관 사상 (Set-Associative Mapping)

```
규칙: 캐시를 여러 집합으로 나누고, 집합 내에서는 자유롭게

2-Way 예시:
Set 0: [라인 0, 라인 1]
Set 1: [라인 2, 라인 3]
Set 2: [라인 4, 라인 5]
Set 3: [라인 6, 라인 7]

블록 0 → Set 0의 라인 0 또는 1
블록 1 → Set 1의 라인 2 또는 3
블록 8 → Set 0의 라인 0 또는 1 (블록 0과 같은 집합)
```

**장점:** 속도와 유연성의 균형  
**단점:** 중간 정도의 복잡도

:::tip 현대 CPU의 선택
대부분의 현대 CPU는 **집합 연관 사상**을 사용합니다!
- Intel Core i7: 8-Way 집합 연관
- AMD Ryzen: 8-Way 집합 연관
:::

---

## 성능 지표

### 적중률 (Hit Rate)

```
적중률 = (캐시 Hit 횟수 / 전체 메모리 접근 횟수) × 100%

예시:
전체 접근: 1000회
캐시 Hit: 950회
캐시 Miss: 50회

적중률 = 950 / 1000 × 100% = 95%
```

:::info 적중률이 중요한 이유
적중률이 1%만 차이나도 프로그램 실행 시간이 크게 달라집니다!

95% vs 96%:
- 95% 적중: AMAT = 1ns × 0.95 + 100ns × 0.05 = 5.95ns
- 96% 적중: AMAT = 1ns × 0.96 + 100ns × 0.04 = 4.96ns
- 성능 차이: 약 20% 향상!
:::

### 평균 메모리 접근 시간 (AMAT)

Average Memory Access Time의 약자입니다.

```
AMAT = Hit Time × Hit Rate + Miss Penalty × Miss Rate

여기서:
- Hit Time: 캐시에서 데이터를 가져오는 시간
- Miss Penalty: 캐시 미스 시 추가로 걸리는 시간 (RAM 접근)
- Miss Rate = 1 - Hit Rate
```

**구체적인 계산 예시:**

```
조건:
- L1 캐시 접근 시간: 1ns
- RAM 접근 시간: 100ns
- 적중률: 95%

계산:
AMAT = 1ns × 0.95 + 100ns × 0.05
     = 0.95ns + 5ns
     = 5.95ns

해석:
평균적으로 한 번의 메모리 접근에 약 6ns가 걸립니다.
캐시가 없었다면 항상 100ns가 걸렸을 것입니다!
성능 향상: 100 / 5.95 ≈ 16.8배
```

### 실제 성능 비교

```c
// 1MB 데이터 읽기

// 캐시 없을 때:
// 1,000,000바이트 × 100ns = 100,000,000ns = 0.1초

// 캐시 있을 때 (95% 적중률):
// 950,000바이트 × 1ns = 950,000ns
// 50,000바이트 × 100ns = 5,000,000ns
// 합계 = 5,950,000ns = 0.006초

// 성능 향상: 약 17배!
```

---

## 캐시의 종류

현대 CPU는 여러 레벨의 캐시를 사용합니다.

### L1 캐시 (Level 1 Cache)

```
특징:
- CPU 코어 내부에 위치
- 가장 빠름 (1~2ns)
- 가장 작음 (32KB~64KB)
- 명령어 캐시(I-Cache)와 데이터 캐시(D-Cache)로 분리

사상 방식: 보통 8-Way 집합 연관
```

### L2 캐시 (Level 2 Cache)

```
특징:
- CPU 코어마다 존재
- 빠름 (3~10ns)
- 중간 크기 (256KB~512KB)
- 명령어와 데이터 통합

사상 방식: 보통 8-Way 또는 16-Way 집합 연관
```

### L3 캐시 (Level 3 Cache)

```
특징:
- 모든 코어가 공유
- 느림 (10~20ns, 하지만 RAM보다는 훨씬 빠름)
- 가장 큼 (4MB~32MB)

사상 방식: 보통 12-Way~20-Way 집합 연관
```

**계층 구조 시각화:**

```
     CPU Core 0              CPU Core 1
     ┌────────┐              ┌────────┐
     │L1 I-$  │              │L1 I-$  │  32KB, 1ns
     │L1 D-$  │              │L1 D-$  │  32KB, 1ns
     └────┬───┘              └───┬────┘
          │                      │
     ┌────▼────┐            ┌───▼─────┐
     │  L2 $   │            │  L2 $   │  256KB, 5ns
     └────┬────┘            └───┬─────┘
          │                     │
          └──────────┬──────────┘
                     │
                ┌────▼─────┐
                │   L3 $   │  8MB, 15ns
                └────┬─────┘
                     │
                ┌────▼─────┐
                │   RAM    │  8GB, 100ns
                └──────────┘

$ = Cache (캐시)
```

---

## 간단한 시뮬레이션

### 캐시 동작 예시

```c
#include <stdio.h>
#include <stdbool.h>

// 매우 간단한 캐시 시뮬레이션 (개념 이해용)

#define CACHE_SIZE 4  // 4개의 캐시 라인

typedef struct {
    bool valid;           // 유효한 데이터가 있나?
    int tag;             // 어떤 블록의 데이터인가?
    char data[4];        // 실제 데이터 (4바이트 블록)
} CacheLine;

CacheLine cache[CACHE_SIZE];

void init_cache() {
    // 캐시 초기화: 모든 라인을 무효(invalid)로 설정
    for (int i = 0; i < CACHE_SIZE; i++) {
        cache[i].valid = false;
        cache[i].tag = -1;
    }
    printf("캐시 초기화 완료\n\n");
}

void access_memory(int block_number) {
    // 간단한 직접 사상 예시
    int line = block_number % CACHE_SIZE;  // 어느 라인에 저장?
    
    printf("블록 %d 접근 요청 → 캐시 라인 %d\n", block_number, line);
    
    // 캐시 확인
    if (cache[line].valid && cache[line].tag == block_number) {
        // 캐시 Hit!
        printf("  ✅ 캐시 Hit! (데이터가 캐시에 있음)\n");
    } else {
        // 캐시 Miss!
        printf("  ❌ 캐시 Miss! (RAM에서 가져와야 함)\n");
        
        // 캐시에 저장
        cache[line].valid = true;
        cache[line].tag = block_number;
        printf("  → 블록 %d를 캐시 라인 %d에 저장\n", block_number, line);
    }
    printf("\n");
}

void print_cache() {
    printf("=== 현재 캐시 상태 ===\n");
    for (int i = 0; i < CACHE_SIZE; i++) {
        printf("라인 %d: ", i);
        if (cache[i].valid) {
            printf("블록 %d의 데이터\n", cache[i].tag);
        } else {
            printf("비어있음\n");
        }
    }
    printf("\n");
}

int main() {
    init_cache();
    
    printf("=== 캐시 동작 시뮬레이션 ===\n\n");
    
    // 여러 블록에 순차적으로 접근
    access_memory(0);   // 블록 0 → 라인 0
    print_cache();
    
    access_memory(1);   // 블록 1 → 라인 1
    print_cache();
    
    access_memory(0);   // 블록 0 다시 접근 → Hit!
    print_cache();
    
    access_memory(4);   // 블록 4 → 라인 0 (블록 0과 충돌!)
    print_cache();
    
    access_memory(0);   // 블록 0 다시 접근 → Miss! (블록 4에 의해 교체됨)
    print_cache();
    
    return 0;
}
```

**실행 결과:**

```
캐시 초기화 완료

=== 캐시 동작 시뮬레이션 ===

블록 0 접근 요청 → 캐시 라인 0
  ❌ 캐시 Miss! (RAM에서 가져와야 함)
  → 블록 0를 캐시 라인 0에 저장

=== 현재 캐시 상태 ===
라인 0: 블록 0의 데이터
라인 1: 비어있음
라인 2: 비어있음
라인 3: 비어있음

블록 1 접근 요청 → 캐시 라인 1
  ❌ 캐시 Miss! (RAM에서 가져와야 함)
  → 블록 1를 캐시 라인 1에 저장

=== 현재 캐시 상태 ===
라인 0: 블록 0의 데이터
라인 1: 블록 1의 데이터
라인 2: 비어있음
라인 3: 비어있음

블록 0 접근 요청 → 캐시 라인 0
  ✅ 캐시 Hit! (데이터가 캐시에 있음)

=== 현재 캐시 상태 ===
라인 0: 블록 0의 데이터
라인 1: 블록 1의 데이터
라인 2: 비어있음
라인 3: 비어있음

블록 4 접근 요청 → 캐시 라인 0
  ❌ 캐시 Miss! (RAM에서 가져와야 함)
  → 블록 4를 캐시 라인 0에 저장

=== 현재 캐시 상태 ===
라인 0: 블록 4의 데이터  ← 블록 0이 교체됨!
라인 1: 블록 1의 데이터
라인 2: 비어있음
라인 3: 비어있음

블록 0 접근 요청 → 캐시 라인 0
  ❌ 캐시 Miss! (RAM에서 가져와야 함)
  → 블록 0를 캐시 라인 0에 저장

=== 현재 캐시 상태 ===
라인 0: 블록 0의 데이터
라인 1: 블록 1의 데이터
라인 2: 비어있음
라인 3: 비어있음
```

---

## 핵심 정리

### 1. 캐시의 필요성

- CPU와 RAM의 속도 차이 극복 (약 100배)
- 지역성 원리를 활용하여 자주 사용하는 데이터를 빠르게 접근

### 2. 기본 구성 요소

- **블록**: 데이터 전송 단위
- **캐시 라인**: 캐시의 저장 공간
- **주소**: 태그 + 인덱스 + 오프셋

### 3. 사상 방식

- **직접 사상**: 빠르지만 충돌 많음
- **연관 사상**: 충돌 없지만 복잡함
- **집합 연관 사상**: 둘의 장점을 결합 (현대 CPU 표준)

### 4. 성능 지표

- **적중률**: 캐시에서 찾은 비율
- **AMAT**: 평균 메모리 접근 시간

---

## 다음 단계

이제 기본 개념을 이해했으니, 각 사상 방식을 자세히 공부해봅시다:

1. **직접 사상**: 가장 간단하지만 충돌이 많은 방식
2. **연관 사상**: 가장 유연하지만 복잡한 방식
3. **집합 연관 사상**: 실제로 가장 많이 사용되는 방식

각 방식의 동작 원리, 장단점, 구현 방법을 상세히 다룰 예정입니다!

:::tip 학습 팁
각 사상 방식을 공부할 때:
1. 시각화 그림을 그려보세요
2. 간단한 예시로 직접 계산해보세요
3. 코드 시뮬레이션을 실행해보세요
:::