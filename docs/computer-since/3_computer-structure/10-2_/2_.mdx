---
title: "직접 사상 (Direct Mapping)"
description: "가장 간단한 캐시 매핑 방식인 직접 사상의 원리와 동작 과정을 상세히 학습합니다."
slug: "direct-mapping"
sidebar_position: 2
---

# 직접 사상 (Direct Mapping)

## 개념

직접 사상은 **가장 간단한** 캐시 매핑 방식입니다.  
주기억장치의 각 블록이 **정확히 하나의 캐시 라인**에만 저장될 수 있습니다.

:::tip 핵심 아이디어
블록 번호를 캐시 라인 수로 나눈 나머지가 캐시 라인 번호입니다!
```
캐시 라인 번호 = 블록 번호 % 캐시 라인 수
```
:::

---

## 도서관 비유

직접 사상을 도서관에 비유하면:

```
📚 중앙 도서관: 1000권의 책 (주기억장치의 1000개 블록)
📖 개인 책상: 10개의 공간 (캐시의 10개 라인)

규칙: ISBN의 마지막 자리로 책상 위치를 정한다!

ISBN이 ...0으로 끝나는 책 → 0번 자리
ISBN이 ...1으로 끝나는 책 → 1번 자리
...
ISBN이 ...9로 끝나는 책 → 9번 자리

예시:
- 책 A (ISBN: 1234567890) → 0번 자리
- 책 B (ISBN: 9876543210) → 0번 자리 ← 책 A와 같은 자리!
```

이처럼 **서로 다른 책이 같은 자리에 배치**되어야 하는 문제가 발생합니다.  
이것이 바로 직접 사상의 **충돌(Conflict)** 문제입니다.

---

## 매핑 규칙

### 기본 공식

```
캐시 라인 번호 = (블록 번호) mod (캐시 라인 개수)
              = (블록 번호) % (캐시 라인 개수)
```

### 구체적인 예시

**조건:**
- 주기억장치: 32개의 블록 (0~31번)
- 캐시: 8개의 라인 (0~7번)

**매핑 결과:**

```
블록 번호 → 계산 → 캐시 라인

블록 0  →  0 % 8 = 0 → 라인 0
블록 1  →  1 % 8 = 1 → 라인 1
블록 2  →  2 % 8 = 2 → 라인 2
블록 3  →  3 % 8 = 3 → 라인 3
블록 4  →  4 % 8 = 4 → 라인 4
블록 5  →  5 % 8 = 5 → 라인 5
블록 6  →  6 % 8 = 6 → 라인 6
블록 7  →  7 % 8 = 7 → 라인 7
블록 8  →  8 % 8 = 0 → 라인 0  ← 블록 0과 같은 라인!
블록 9  →  9 % 8 = 1 → 라인 1  ← 블록 1과 같은 라인!
...
블록 16 → 16 % 8 = 0 → 라인 0  ← 블록 0, 8과 같은 라인!
...
블록 31 → 31 % 8 = 7 → 라인 7
```

### 시각화

```
주기억장치 (32개 블록)         캐시 (8개 라인)
┌─────────┐                   ┌──────┬────────┐
│ 블록 0  │───────────────────→│Line 0│ Tag: 0 │
│ 블록 1  │───────────────────→│Line 1│ Tag: 0 │
│ 블록 2  │───────────────────→│Line 2│ Tag: 0 │
│ 블록 3  │───────────────────→│Line 3│ Tag: 0 │
│ 블록 4  │───────────────────→│Line 4│ Tag: 0 │
│ 블록 5  │───────────────────→│Line 5│ Tag: 0 │
│ 블록 6  │───────────────────→│Line 6│ Tag: 0 │
│ 블록 7  │───────────────────→│Line 7│ Tag: 0 │
├─────────┤                   └──────┴────────┘
│ 블록 8  │──┐                     ↑
│ 블록 9  │  │                     │
│ 블록 10 │  │    같은 라인에      │
│ 블록 11 │  │    매핑됨!          │
│ 블록 12 │  │                     │
│ 블록 13 │  │                     │
│ 블록 14 │  │                     │
│ 블록 15 │──┴─────────────────────┘
├─────────┤
│ 블록 16 │──→ Line 0 (블록 0, 8과 경쟁)
│  ...    │
│ 블록 31 │
└─────────┘

※ 블록 0, 8, 16, 24는 모두 라인 0에 매핑됩니다!
```

---

## 주소 구조

직접 사상에서 메모리 주소는 세 부분으로 나뉩니다.

### 주소 분해

```
전체 메모리 주소 (n비트)
┌────────────┬──────────┬────────────┐
│    태그     │  인덱스   │  오프셋     │
│   (Tag)    │ (Index)  │  (Offset)  │
└────────────┴──────────┴────────────┘
     ↑            ↑           ↑
어떤 블록?   어느 라인?  몇 번째 바이트?
```

### 각 부분의 크기 계산

**조건:**
- 전체 주소: 16비트
- 블록 크기: 4바이트 = 2²바이트
- 캐시 라인: 8개 = 2³개

**계산:**

```
1. 오프셋 비트 수
   = log₂(블록 크기)
   = log₂(4)
   = 2비트

2. 인덱스 비트 수
   = log₂(캐시 라인 수)
   = log₂(8)
   = 3비트

3. 태그 비트 수
   = 전체 비트 - 오프셋 비트 - 인덱스 비트
   = 16 - 2 - 3
   = 11비트
```

**결과:**

```
┌───────────────┬─────────┬────────┐
│     태그       │ 인덱스   │ 오프셋  │
│    11비트      │  3비트   │  2비트  │
└───────────────┴─────────┴────────┘
```

### 구체적인 예시

주소 `0x1A4C` (16진수) = `0001 1010 0100 1100` (2진수)

```
주소: 0001 1010 0100 1100

분해:
┌─────────────────┬─────┬────┐
│ 000 1101 0010   │ 011 │ 00 │
│      태그        │인덱스│오프셋│
└─────────────────┴─────┴────┘

10진수 변환:
- 태그: 000 1101 0010 = 210
- 인덱스: 011 = 3
- 오프셋: 00 = 0

해석:
- 블록 210의 데이터를 요청
- 캐시의 3번 라인을 확인
- 블록의 0번째 바이트를 반환
```

---

## 동작 과정

CPU가 메모리 주소에 접근할 때의 단계별 과정입니다.

### 전체 흐름도

```
CPU가 주소 요청
    ↓
┌─────────────────────┐
│ 1. 주소 분해        │
│  - 태그             │
│  - 인덱스           │
│  - 오프셋           │
└──────┬──────────────┘
       ↓
┌─────────────────────┐
│ 2. 인덱스로         │
│    캐시 라인 접근   │
└──────┬──────────────┘
       ↓
┌─────────────────────┐
│ 3. 유효 비트 확인   │
│    Valid = 1?       │
└──────┬──────────────┘
       ↓
┌─────────────────────┐
│ 4. 태그 비교        │
│    저장된 태그 =    │
│    요청한 태그?     │
└──────┬──────────────┘
       ↓
    ┌──┴──┐
    │일치?│
    └──┬──┘
   YES │ NO
       │  │
   ┌───▼──▼────────┐
   │ 5. Hit / Miss │
   └───────────────┘
```

### 단계별 상세 설명

#### 1단계: 주소 분해

```c
unsigned int address = 0x1A4C;  // 요청 주소

// 비트 마스크를 사용하여 각 부분 추출
unsigned int offset = address & 0x0003;        // 하위 2비트
unsigned int index = (address >> 2) & 0x0007;  // 다음 3비트
unsigned int tag = (address >> 5);             // 상위 11비트

printf("주소: 0x%04X\n", address);
printf("  오프셋: %u\n", offset);   // 0
printf("  인덱스: %u\n", index);    // 3
printf("  태그: %u\n", tag);        // 210
```

**비트 연산 설명:**

```
address = 0001 1010 0100 1100

오프셋 추출 (하위 2비트):
0001 1010 0100 1100
              ↓↓
AND 0000 0000 0000 0011
    ─────────────────────
    0000 0000 0000 0000  → 0

인덱스 추출 (2~4번째 비트):
먼저 2비트 오른쪽 시프트:
0001 1010 0100 1100 >> 2
= 0000 0110 1001 0011

그 다음 하위 3비트만:
0000 0110 1001 0011
            ↓↓↓
AND 0000 0000 0000 0111
    ─────────────────────
    0000 0000 0000 0011  → 3

태그 추출 (상위 11비트):
0001 1010 0100 1100 >> 5
= 0000 0000 1101 0010  → 210
```

#### 2단계: 캐시 라인 접근

```c
// 인덱스로 캐시 라인에 직접 접근
CacheLine *line = &cache[index];  // cache[3]

// 캐시 라인의 구조
typedef struct {
    bool valid;           // 유효 비트
    unsigned int tag;     // 저장된 태그
    unsigned char data[4]; // 실제 데이터 (4바이트 블록)
} CacheLine;
```

인덱스가 `3`이므로 캐시의 **3번 라인**을 확인합니다.  
다른 라인은 전혀 확인하지 않습니다! (빠른 이유)

#### 3단계: 유효 비트 확인

```c
if (!line->valid) {
    // 유효하지 않음 → 이 라인에 아직 데이터가 없음
    printf("캐시 Miss (유효하지 않음)\n");
    // 주기억장치에서 데이터 가져오기
}
```

**유효 비트의 의미:**

```
초기 상태 (전원 켜짐):
┌──────┬───────┬──────┬──────┐
│Line 3│Valid:0│Tag:? │Data:?│  ← 쓰레기 값
└──────┴───────┴──────┴──────┘

첫 번째 접근 후:
┌──────┬───────┬───────┬────────┐
│Line 3│Valid:1│Tag:210│Data:...│  ← 유효한 데이터
└──────┴───────┴───────┴────────┘
```

#### 4단계: 태그 비교

```c
if (line->valid && line->tag == tag) {
    // 태그 일치 → 캐시 Hit!
    printf("캐시 Hit!\n");
    return line->data[offset];
} else {
    // 태그 불일치 → 캐시 Miss!
    printf("캐시 Miss (태그 불일치)\n");
    // 주기억장치에서 데이터 가져오기
}
```

**태그 비교의 필요성:**

```
라인 3에는 여러 블록이 매핑될 수 있습니다:
- 블록 3 (3 % 8 = 3) → 태그 = 0
- 블록 11 (11 % 8 = 3) → 태그 = 1
- 블록 19 (19 % 8 = 3) → 태그 = 2
- 블록 27 (27 % 8 = 3) → 태그 = 3

현재 어떤 블록의 데이터가 있는지 태그로 구분합니다!
```

#### 5단계: Hit 또는 Miss 처리

**캐시 Hit인 경우:**

```c
// 캐시에서 직접 데이터 반환
unsigned char result = line->data[offset];
printf("데이터: 0x%02X (캐시에서 반환, 빠름!)\n", result);

// 시간: 약 1ns
```

**캐시 Miss인 경우:**

```c
// 1. 주기억장치에서 블록 전체를 가져옴
unsigned char block[4];
fetch_from_memory(tag, index, block);  // 100ns 소요

// 2. 캐시 라인에 저장
line->valid = true;
line->tag = tag;
memcpy(line->data, block, 4);

// 3. 요청한 바이트 반환
unsigned char result = line->data[offset];
printf("데이터: 0x%02X (주기억장치에서 가져옴, 느림)\n", result);

// 시간: 약 100ns
```

---

## 실전 예제

### 예제 1: 순차적 접근

```c
// 배열의 연속된 요소에 접근
int arr[16];  // 블록 0~15에 위치한다고 가정

for (int i = 0; i < 16; i++) {
    arr[i] = i;  // 블록 0, 1, 2, ..., 15 순차 접근
}
```

**캐시 동작 분석:**

```
접근 순서:   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
캐시 라인:   0   1   2   3   4   5   6   7   0   1   2   3   4   5   6   7
결과:       Miss Miss Miss Miss Miss Miss Miss Miss Hit Hit Hit Hit Hit Hit Hit Hit

전체 16번 접근:
- Miss: 8번 (블록 0~7)
- Hit: 8번 (블록 8~15는 같은 라인에 있음)
적중률: 50%
```

**왜 이렇게 될까요?**

```
블록 0 → 라인 0 (Miss, 저장)
블록 1 → 라인 1 (Miss, 저장)
...
블록 7 → 라인 7 (Miss, 저장)

이제 캐시가 가득 참!

블록 8 → 라인 0 (8 % 8 = 0)
         태그 비교: 현재 라인 0에는 블록 0 (태그=0)
                   요청은 블록 8 (태그=1)
         태그 불일치 → Miss!
         블록 0 교체, 블록 8 저장

블록 9 → 라인 1 (9 % 8 = 1)
         같은 방식으로 블록 1 교체, 블록 9 저장
...
```

### 예제 2: 충돌 발생

```c
// 두 배열이 같은 캐시 라인을 공유하는 경우
int arr1[100];  // 블록 0~24 (0*4 ~ 24*4 바이트)
int arr2[100];  // 블록 25~49

// 가정: 블록 0과 블록 8이 같은 라인에 매핑됨 (0 % 8 = 8 % 8)

for (int i = 0; i < 100; i++) {
    arr1[i] = 1;   // 블록 0 접근
    arr2[i] = 2;   // 블록 8 접근
}
```

**캐시 동작 분석:**

```
i=0:
  arr1[0] 접근 → 블록 0 → 라인 0 (Miss, 블록 0 저장)
  arr2[0] 접근 → 블록 8 → 라인 0 (Miss, 블록 0 교체, 블록 8 저장)

i=1:
  arr1[1] 접근 → 블록 0 → 라인 0 (Miss, 블록 8 교체, 블록 0 저장)
  arr2[1] 접근 → 블록 8 → 라인 0 (Miss, 블록 0 교체, 블록 8 저장)

...

결과: 100번 반복 → 200번 Miss!
적중률: 0%

이런 현상을 "캐시 스래싱(Cache Thrashing)"이라고 합니다.
```

:::warning 캐시 스래싱
두 개 이상의 블록이 같은 캐시 라인을 놓고 계속 교체되면서  
캐시 적중률이 극도로 낮아지는 현상입니다.  
직접 사상의 가장 큰 문제점입니다!
:::

### 예제 3: 실제 코드 시뮬레이션

```c
#include <stdio.h>
#include <stdbool.h>
#include <string.h>

#define CACHE_LINES 8
#define BLOCK_SIZE 4
#define OFFSET_BITS 2  // log2(4)
#define INDEX_BITS 3   // log2(8)

// 캐시 라인 구조체
typedef struct {
    bool valid;
    unsigned int tag;
    unsigned char data[BLOCK_SIZE];
} CacheLine;

// 캐시 배열
CacheLine cache[CACHE_LINES];

// 통계
int total_accesses = 0;
int hits = 0;
int misses = 0;

// 주소에서 태그 추출
unsigned int get_tag(unsigned int address) {
    return address >> (OFFSET_BITS + INDEX_BITS);
}

// 주소에서 인덱스 추출
unsigned int get_index(unsigned int address) {
    unsigned int mask = (1 << INDEX_BITS) - 1;  // 0b111
    return (address >> OFFSET_BITS) & mask;
}

// 주소에서 오프셋 추출
unsigned int get_offset(unsigned int address) {
    unsigned int mask = (1 << OFFSET_BITS) - 1;  // 0b11
    return address & mask;
}

// 캐시 초기화
void init_cache() {
    for (int i = 0; i < CACHE_LINES; i++) {
        cache[i].valid = false;
        cache[i].tag = 0;
        memset(cache[i].data, 0, BLOCK_SIZE);
    }
    total_accesses = 0;
    hits = 0;
    misses = 0;
}

// 주기억장치에서 블록 가져오기 (시뮬레이션)
void fetch_from_memory(unsigned int address, unsigned char *block) {
    // 실제로는 RAM에서 데이터를 가져오지만,
    // 여기서는 주소 값으로 간단히 시뮬레이션
    for (int i = 0; i < BLOCK_SIZE; i++) {
        block[i] = (unsigned char)((address + i) & 0xFF);
    }
}

// 캐시 접근 함수
bool cache_access(unsigned int address) {
    total_accesses++;
    
    // 주소 분해
    unsigned int tag = get_tag(address);
    unsigned int index = get_index(address);
    unsigned int offset = get_offset(address);
    
    printf("\n주소 0x%04X 접근:\n", address);
    printf("  태그: %u, 인덱스: %u, 오프셋: %u\n", tag, index, offset);
    
    // 캐시 라인 확인
    CacheLine *line = &cache[index];
    
    // 유효하고 태그가 일치하면 Hit
    if (line->valid && line->tag == tag) {
        printf("  ✅ 캐시 Hit! (라인 %u에서 발견)\n", index);
        hits++;
        return true;
    } else {
        // Miss
        if (!line->valid) {
            printf("  ❌ 캐시 Miss (라인 비어있음)\n");
        } else {
            printf("  ❌ 캐시 Miss (태그 불일치: 저장됨=%u, 요청=%u)\n", 
                   line->tag, tag);
            printf("     → 블록 %u를 교체함\n", 
                   (line->tag << INDEX_BITS) | index);
        }
        
        misses++;
        
        // 주기억장치에서 블록 가져오기
        fetch_from_memory(address, line->data);
        line->valid = true;
        line->tag = tag;
        
        printf("     → 블록을 라인 %u에 저장\n", index);
        return false;
    }
}

// 캐시 상태 출력
void print_cache() {
    printf("\n=== 현재 캐시 상태 ===\n");
    for (int i = 0; i < CACHE_LINES; i++) {
        printf("라인 %d: ", i);
        if (cache[i].valid) {
            unsigned int block_num = (cache[i].tag << INDEX_BITS) | i;
            printf("Valid, Tag=%u (블록 %u)", cache[i].tag, block_num);
        } else {
            printf("Empty");
        }
        printf("\n");
    }
}

// 통계 출력
void print_stats() {
    printf("\n=== 캐시 성능 통계 ===\n");
    printf("총 접근 횟수: %d\n", total_accesses);
    printf("Hit: %d\n", hits);
    printf("Miss: %d\n", misses);
    if (total_accesses > 0) {
        printf("적중률: %.2f%%\n", (float)hits / total_accesses * 100);
    }
}

int main() {
    init_cache();
    
    printf("=== 직접 사상 캐시 시뮬레이션 ===\n");
    printf("캐시 크기: %d 라인\n", CACHE_LINES);
    printf("블록 크기: %d 바이트\n", BLOCK_SIZE);
    
    // 테스트 1: 순차 접근
    printf("\n\n>>> 테스트 1: 순차 접근 (블록 0~9)\n");
    for (int i = 0; i < 10; i++) {
        unsigned int addr = i * BLOCK_SIZE;  // 블록 경계에 맞춤
        cache_access(addr);
    }
    print_cache();
    print_stats();
    
    // 테스트 2: 충돌 테스트
    printf("\n\n>>> 테스트 2: 충돌 테스트 (블록 0과 8 반복)\n");
    init_cache();
    for (int i = 0; i < 5; i++) {
        cache_access(0);   // 블록 0 → 라인 0
        cache_access(32);  // 블록 8 → 라인 0 (충돌!)
    }
    print_cache();
    print_stats();
    
    // 테스트 3: 지역성 활용
    printf("\n\n>>> 테스트 3: 지역성 활용 (같은 블록 반복)\n");
    init_cache();
    for (int i = 0; i < 10; i++) {
        cache_access(0);   // 블록 0을 10번 접근
    }
    print_cache();
    print_stats();
    
    return 0;
}
```

**실행 결과 (일부):**

```
=== 직접 사상 캐시 시뮬레이션 ===
캐시 크기: 8 라인
블록 크기: 4 바이트


>>> 테스트 1: 순차 접근 (블록 0~9)

주소 0x0000 접근:
  태그: 0, 인덱스: 0, 오프셋: 0
  ❌ 캐시 Miss (라인 비어있음)
     → 블록을 라인 0에 저장

주소 0x0004 접근:
  태그: 0, 인덱스: 1, 오프셋: 0
  ❌ 캐시 Miss (라인 비어있음)
     → 블록을 라인 1에 저장

...

주소 0x0020 접근:
  태그: 1, 인덱스: 0, 오프셋: 0
  ❌ 캐시 Miss (태그 불일치: 저장됨=0, 요청=1)
     → 블록 0을 교체함
     → 블록을 라인 0에 저장

=== 현재 캐시 상태 ===
라인 0: Valid, Tag=1 (블록 8)
라인 1: Valid, Tag=1 (블록 9)
라인 2: Valid, Tag=0 (블록 2)
라인 3: Valid, Tag=0 (블록 3)
라인 4: Valid, Tag=0 (블록 4)
라인 5: Valid, Tag=0 (블록 5)
라인 6: Valid, Tag=0 (블록 6)
라인 7: Valid, Tag=0 (블록 7)

=== 캐시 성능 통계 ===
총 접근 횟수: 10
Hit: 0
Miss: 10
적중률: 0.00%


>>> 테스트 2: 충돌 테스트 (블록 0과 8 반복)

주소 0x0000 접근:
  태그: 0, 인덱스: 0, 오프셋: 0
  ❌ 캐시 Miss (라인 비어있음)
     → 블록을 라인 0에 저장

주소 0x0020 접근:
  태그: 1, 인덱스: 0, 오프셋: 0
  ❌ 캐시 Miss (태그 불일치: 저장됨=0, 요청=1)
     → 블록 0을 교체함
     → 블록을 라인 0에 저장

주소 0x0000 접근:
  태그: 0, 인덱스: 0, 오프셋: 0
  ❌ 캐시 Miss (태그 불일치: 저장됨=1, 요청=0)
     → 블록 8을 교체함
     → 블록을 라인 0에 저장

...

=== 캐시 성능 통계 ===
총 접근 횟수: 10
Hit: 0
Miss: 10
적중률: 0.00%


>>> 테스트 3: 지역성 활용 (같은 블록 반복)

주소 0x0000 접근:
  태그: 0, 인덱스: 0, 오프셋: 0
  ❌ 캐시 Miss (라인 비어있음)
     → 블록을 라인 0에 저장

주소 0x0000 접근:
  태그: 0, 인덱스: 0, 오프셋: 0
  ✅ 캐시 Hit! (라인 0에서 발견)

주소 0x0000 접근:
  태그: 0, 인덱스: 0, 오프셋: 0
  ✅ 캐시 Hit! (라인 0에서 발견)

...

=== 캐시 성능 통계 ===
총 접근 횟수: 10
Hit: 9
Miss: 1
적중률: 90.00%
```

---

## 장점과 단점

### 장점 ✅

#### 1. 구현이 매우 간단함

```
하드웨어 회로가 단순:
- 비교기 1개만 필요 (태그 비교)
- 복잡한 검색 로직 불필요
- 인덱스로 직접 접근 가능
```

**회로 구성:**

```
주소 입력
    ↓
┌───────────────┐
│ 주소 분해기   │
│ (비트 추출)   │
└───┬───┬───┬───┘
    │   │   │
  태그 인덱스 오프셋
    │   │
    │   └──→ 캐시 라인 선택
    │
    └──→ 비교기 (1개) ──→ Hit/Miss
              ↑
           저장된 태그
```

#### 2. 빠른 접근 속도

```
검색 시간 = O(1) (상수 시간)

과정:
1. 인덱스 추출 (비트 연산)
2. 캐시 라인 직접 접근 (배열 인덱싱)
3. 태그 비교 (1번)
4. 결과 반환

→ 모든 연산이 병렬로 처리 가능
→ 클럭 사이클 1~2회면 완료
```

#### 3. 저렴한 비용

```
필요한 하드웨어:
- 캐시 메모리 (SRAM)
- 태그 저장소
- 비교기 1개
- 멀티플렉서 (데이터 선택)

→ 다른 방식에 비해 트랜지스터 수가 적음
→ 칩 면적 절약
→ 전력 소비 감소
```

### 단점 ❌

#### 1. 충돌 (Conflict) 발생

```
문제: 서로 다른 블록이 같은 라인을 공유

예시:
캐시 8라인, 주소 패턴:
블록 0, 8, 16, 24, 32, ... (모두 라인 0)

→ 이 블록들을 번갈아 사용하면 계속 교체 발생!
```

**충돌의 영향:**

```c
// 최악의 경우
int a[1024];  // 블록 0~255
int b[1024];  // 블록 256~511

// 블록 0과 블록 256이 같은 라인에 매핑되면:
for (int i = 0; i < 1024; i++) {
    a[i] = b[i];  // 계속 Miss 발생!
}

// 적중률: 거의 0%
```

#### 2. 캐시 활용도 저하

```
문제: 캐시 공간을 충분히 활용하지 못함

시나리오:
- 캐시: 8라인 (모두 비어있음)
- 접근 패턴: 블록 0, 8, 16, 24

결과:
- 라인 0만 계속 사용됨
- 나머지 7개 라인은 비어있음
- 공간 낭비: 87.5%!
```

#### 3. 성능 예측 어려움

```
같은 프로그램이라도 데이터 배치에 따라 성능이 크게 달라짐

예시 1: 좋은 경우
배열 A: 블록 0~7
배열 B: 블록 8~15
→ 충돌 없음, 적중률 높음

예시 2: 나쁜 경우
배열 A: 블록 0~7
배열 B: 블록 8~15 (8 % 8 = 0부터 시작)
→ 충돌 많음, 적중률 낮음
```

---

## 성능 개선 기법

### 1. 데이터 정렬 (Data Alignment)

```c
// ❌ 나쁜 예: 캐시 라인 경계를 고려하지 않음
struct Data {
    char a;      // 1바이트
    int b;       // 4바이트
    char c;      // 1바이트
};  // 총 10바이트 (패딩 포함 시 12바이트)

// ✅ 좋은 예: 캐시 라인에 맞춤
struct Data {
    int b;       // 4바이트
    char a;      // 1바이트
    char c;      // 1바이트
    char pad[2]; // 패딩
};  // 총 8바이트 (캐시 라인 크기의 배수)
```

### 2. 루프 타일링 (Loop Tiling)

```c
// ❌ 나쁜 예: 큰 배열 전체를 순회
for (int i = 0; i < 1024; i++) {
    for (int j = 0; j < 1024; j++) {
        C[i][j] = A[i][j] + B[i][j];
    }
}

// ✅ 좋은 예: 작은 타일로 나누어 처리
#define TILE_SIZE 64
for (int ii = 0; ii < 1024; ii += TILE_SIZE) {
    for (int jj = 0; jj < 1024; jj += TILE_SIZE) {
        for (int i = ii; i < ii + TILE_SIZE; i++) {
            for (int j = jj; j < jj + TILE_SIZE; j++) {
                C[i][j] = A[i][j] + B[i][j];
            }
        }
    }
}
```

### 3. 데이터 재배치

```c
// ❌ 나쁜 예: 충돌하는 배열
int arr1[100] __attribute__((aligned(256)));  // 블록 0부터
int arr2[100] __attribute__((aligned(256)));  // 블록 64부터 (충돌 가능)

// ✅ 좋은 예: 충돌 회피
int arr1[100] __attribute__((aligned(512)));  // 블록 0부터
int arr2[100] __attribute__((aligned(512)));  // 블록 128부터 (충돌 없음)
```

---

## 실무 활용 사례

### 1. 임베디드 시스템

```
특징:
- 비용과 전력이 중요
- 간단한 캐시로도 성능 향상
- 예측 가능한 메모리 접근 패턴

사용 예:
- 마이크로컨트롤러
- IoT 기기
- 단순한 실시간 시스템
```

### 2. 저가형 프로세서

```
ARM Cortex-M 시리즈:
- 직접 사상 I-Cache (명령어 캐시)
- 4KB~16KB 크기
- 32바이트 캐시 라인

성능:
- 적중률: 70~85%
- 충분히 실용적
```

### 3. 특수 목적 캐시

```
TLB (Translation Lookaside Buffer):
- 가상 주소 → 물리 주소 변환 캐시
- 작은 크기 (16~64 엔트리)
- 직접 사상 또는 집합 연관 사상

이유:
- 크기가 작아서 직접 사상으로도 충분
- 빠른 속도가 중요
```

---

## 핵심 정리

### 직접 사상의 특징

```
✅ 장점:
1. 구현 간단 (비교기 1개)
2. 빠른 접근 (O(1))
3. 저렴한 비용

❌ 단점:
1. 충돌 발생 (같은 라인 공유)
2. 낮은 캐시 활용도
3. 예측 어려운 성능
```

### 주소 구조

```
┌────────┬────────┬────────┐
│  태그   │ 인덱스  │ 오프셋  │
└────────┴────────┴────────┘
  어떤 블록  어느 라인  몇 번째

태그 크기 = 전체 비트 - 인덱스 비트 - 오프셋 비트
인덱스 비트 = log₂(캐시 라인 수)
오프셋 비트 = log₂(블록 크기)
```

### 동작 원리

```
1. 주소 분해 (태그, 인덱스, 오프셋)
2. 인덱스로 캐시 라인 접근
3. 유효 비트 확인
4. 태그 비교
5. Hit/Miss 처리
```

### 성능 공식

```
적중률 = Hit / (Hit + Miss) × 100%

AMAT = Hit Time × Hit Rate + Miss Penalty × Miss Rate

예: Hit Time=1ns, Miss Penalty=100ns, Hit Rate=95%
AMAT = 1×0.95 + 100×0.05 = 5.95ns
```

---

## 연습 문제

### 문제 1

16비트 주소, 블록 크기 8바이트, 캐시 라인 16개일 때:
1. 오프셋, 인덱스, 태그의 비트 수는?
2. 주소 0x1234의 태그, 인덱스, 오프셋은?

<details>
<summary>답안 보기</summary>

1. 비트 수 계산:
   - 오프셋: log₂(8) = 3비트
   - 인덱스: log₂(16) = 4비트
   - 태그: 16 - 3 - 4 = 9비트

2. 0x1234 = 0001 0010 0011 0100
   - 태그: 000100100 (상위 9비트) = 36
   - 인덱스: 0110 (다음 4비트) = 6
   - 오프셋: 100 (하위 3비트) = 4

</details>

### 문제 2

캐시 8라인에서 블록 0, 8, 16, 0, 8, 16 순으로 접근할 때:
1. 각 접근의 Hit/Miss는?
2. 최종 적중률은?

<details>
<summary>답안 보기</summary>

1. 접근 결과:
   - 블록 0: Miss (라인 0에 저장)
   - 블록 8: Miss (라인 0, 블록 0 교체)
   - 블록 16: Miss (라인 0, 블록 8 교체)
   - 블록 0: Miss (라인 0, 블록 16 교체)
   - 블록 8: Miss (라인 0, 블록 0 교체)
   - 블록 16: Miss (라인 0, 블록 8 교체)

2. 적중률: 0% (모두 Miss)
   → 캐시 스래싱 발생!

</details>

---

## 다음 단계

직접 사상의 한계를 이해했다면, 다음 주제로 넘어가봅시다:

- **연관 사상**: 충돌 문제를 해결하는 유연한 방식
- **집합 연관 사상**: 직접 사상과 연관 사상의 장점을 결합

각 방식의 장단점을 비교하면서 현대 CPU가 왜 특정 방식을 선택했는지 이해할 수 있습니다!