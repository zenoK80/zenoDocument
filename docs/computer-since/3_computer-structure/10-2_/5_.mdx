---
title: "사상 방식 종합 비교"
description: "직접 사상, 연관 사상, 집합 연관 사상의 성능을 비교하고 실제 프로그램에서의 캐시 최적화 기법을 학습합니다."
slug: "comparison-and-optimization"
sidebar_position: 5
---

# 사상 방식 종합 비교

## 개요

지금까지 배운 세 가지 캐시 사상 방식을 종합적으로 비교하고,  
실제 프로그램에서 어떻게 활용할 수 있는지 알아봅니다.

:::tip 학습 목표
- 세 가지 방식의 정량적 성능 비교
- 실제 프로그램의 캐시 동작 분석
- 캐시 친화적 코드 작성법
:::

---

## 기본 비교표

### 핵심 특성 비교

| 특성 | 직접 사상 | 집합 연관 사상 (N-Way) | 연관 사상 |
|------|----------|----------------------|----------|
| **매핑 규칙** | 블록 % 라인 수 | 블록 % 집합 수 | 없음 (자유) |
| **집합 개수** | 라인 수 | 라인 수 / N | 1 |
| **웨이 개수** | 1 | N | 라인 수 |
| **검색 범위** | 1개 라인 | N개 웨이 | 전체 라인 |
| **비교 횟수** | 1 | N | 전체 라인 |
| **비교기 수** | 1 | N | 전체 라인 |
| **태그 크기** | 작음 | 중간 | 큼 |
| **충돌 가능성** | 높음 | 중간 | 없음 |
| **교체 필요** | 즉시 | 집합 내에서 | 전체에서 |

### 성능 지표 비교

| 지표 | 직접 사상 | 2-Way | 4-Way | 8-Way | 연관 사상 |
|------|----------|-------|-------|-------|----------|
| **평균 적중률** | 60~75% | 70~85% | 80~90% | 85~95% | 90~99% |
| **검색 속도** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ |
| **하드웨어 비용** | ⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **전력 소비** | ⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **복잡도** | 낮음 | 중간 | 중간 | 높음 | 매우 높음 |

---

## 상세 성능 분석

### 실험 조건

```
공통 설정:
- 캐시 크기: 16 라인 (모든 방식 동일)
- 블록 크기: 4바이트
- 접근 패턴: 다양한 시나리오

테스트 방식:
1. 순차 접근
2. 스트라이드 접근
3. 랜덤 접근
4. 충돌 패턴
```

### 시나리오 1: 순차 접근

```c
// 배열을 순차적으로 접근
int arr[64];  // 64개 블록
for (int i = 0; i < 64; i++) {
    arr[i] = i;
}
```

**결과:**

```
직접 사상 (16라인):
처음 16개: Miss (캐시 채움)
다음 16개: Miss (16~31번 블록이 0~15번 교체)
...
적중률: 0%

2-Way (8개 집합):
처음 16개: Miss
다음 16개: 집합당 2개 유지, 50% Hit
적중률: ~37.5%

4-Way (4개 집합):
처음 16개: Miss
다음 16개: 집합당 4개 유지, 75% Hit
적중률: ~56.2%

8-Way (2개 집합):
처음 16개: Miss
다음 48개: 대부분 Hit
적중률: ~75%

연관 사상 (16라인):
처음 16개: Miss
나머지: 모두 Hit
적중률: ~75%
```

**그래프:**

```
적중률
 100% ┤
      │                    ●─────●
  75% ┤              ●────┘
      │        ●────┘
  50% ┤  ●────┘
      │
  25% ┤
      │●
   0% ┤
      └──┴──┴──┴──┴──┴──┴──┴──┴──→
       직접 2   4   8   연관
       사상 Way Way Way  사상
```

### 시나리오 2: 스트라이드 접근

```c
// 일정 간격으로 접근
int arr[64];
int stride = 16;  // 캐시 크기와 같음
for (int i = 0; i < 4; i++) {
    for (int j = 0; j < 16; j++) {
        arr[i * stride + j] = i;
    }
}
```

**결과:**

```
직접 사상:
블록 0, 16, 32, 48 모두 라인 0에 매핑
→ 계속 충돌
적중률: 0%

2-Way:
각 집합에 2개까지 유지 가능
4개 블록 중 2개만 유지 → 50% 충돌
적중률: ~25%

4-Way:
각 집합에 4개까지 유지 가능
4개 블록 모두 유지 가능!
적중률: ~75%

8-Way / 연관 사상:
모두 유지 가능
적중률: ~75%
```

### 시나리오 3: 워킹 셋 크기별 성능

```c
// 워킹 셋: 자주 사용하는 데이터 집합
for (int size = 1; size <= 32; size++) {
    for (int iter = 0; iter < 100; iter++) {
        for (int i = 0; i < size; i++) {
            access(i);
        }
    }
}
```

**결과:**

```
워킹 셋 크기 vs 적중률

직접 사상 (16라인):
크기 1~16: 99% (캐시에 다 들어감)
크기 17~32: 50% (절반만 캐시)
크기 33+: <25% (충돌 심화)

2-Way (8개 집합):
크기 1~16: 99%
크기 17~24: 75%
크기 25~32: 50%

4-Way (4개 집합):
크기 1~16: 99%
크기 17~32: 80%

8-Way / 연관 사상:
크기 1~16: 99%
크기 17~32: 90%
```

**그래프:**

```
적중률
 100% ┤●●●●●●●●●●●●●●●●─────────────
      │                  ╲
  75% ┤                   ●●●●●●●●──  8-Way
      │                   │      ╲
  50% ┤                   │       ●●● 4-Way
      │                   │         ╲
  25% ┤                   │          ●● 2-Way
      │                   │            ╲
   0% ┤                   │             ● 직접
      └──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──→
       0  4  8  12 16 20 24 28 32
              워킹 셋 크기
```

---

## 실전 코드 비교

### 예제: 행렬 곱셈

```c
// 간단한 행렬 곱셈
#define N 64

void matrix_multiply_naive(int A[N][N], int B[N][N], int C[N][N]) {
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            int sum = 0;
            for (int k = 0; k < N; k++) {
                sum += A[i][k] * B[k][j];
            }
            C[i][j] = sum;
        }
    }
}
```

**캐시 동작 분석:**

```
직접 사상 (32KB, 8192라인):
- A[i][k]: 행 우선, 좋은 지역성
- B[k][j]: 열 우선, 나쁜 지역성!
  → B의 각 열이 멀리 떨어져 있음
  → 같은 캐시 라인에 매핑될 확률 높음
  → 충돌 발생
적중률: ~60%

4-Way (2048개 집합):
- B의 열 접근도 어느 정도 유지
- 충돌 감소
적중률: ~75%

8-Way (1024개 집합):
- 더 많은 데이터 유지
적중률: ~85%
```

**개선 버전 (블로킹):**

```c
void matrix_multiply_blocked(int A[N][N], int B[N][N], int C[N][N]) {
    int block_size = 8;  // 캐시 친화적 블록 크기
    
    for (int ii = 0; ii < N; ii += block_size) {
        for (int jj = 0; jj < N; jj += block_size) {
            for (int kk = 0; kk < N; kk += block_size) {
                // 작은 블록 단위로 처리
                for (int i = ii; i < ii + block_size; i++) {
                    for (int j = jj; j < jj + block_size; j++) {
                        int sum = C[i][j];
                        for (int k = kk; k < kk + block_size; k++) {
                            sum += A[i][k] * B[k][j];
                        }
                        C[i][j] = sum;
                    }
                }
            }
        }
    }
}
```

**블로킹 효과:**

```
직접 사상:
naive: ~60%
blocked: ~80%  (+33% 향상!)

4-Way:
naive: ~75%
blocked: ~90%  (+20% 향상)

8-Way:
naive: ~85%
blocked: ~95%  (+12% 향상)

→ 직접 사상에서 효과가 가장 큼!
```

---

## 실무 선택 기준

### 용도별 추천 방식

#### 임베디드 시스템

```
요구사항:
- 저비용
- 저전력
- 예측 가능한 성능

추천: 직접 사상 또는 2-Way
이유:
- 간단한 하드웨어
- 낮은 전력 소비
- 작은 캐시로도 효과적
```

**예시: ARM Cortex-M4**

```
I-Cache: 4KB, 직접 사상
D-Cache: 없음 또는 4KB 직접 사상

→ 비용 최소화
→ 실시간 성능 보장
```

#### 모바일 프로세서

```
요구사항:
- 중간 성능
- 전력 효율
- 배터리 수명

추천: 4-Way
이유:
- 적절한 성능
- 합리적인 전력
- 다양한 앱 지원
```

**예시: Qualcomm Snapdragon**

```
L1 I-Cache: 32KB, 4-Way
L1 D-Cache: 32KB, 4-Way
L2 Cache: 256KB, 8-Way

→ 성능과 전력의 균형
```

#### 데스크톱/서버 CPU

```
요구사항:
- 최고 성능
- 다양한 워크로드
- 전력은 차선

추천: 8-Way (L1/L2), 16-Way (L3)
이유:
- 높은 적중률
- 예측 불가능한 접근 패턴 대응
- 대용량 캐시 효율적 관리
```

**예시: Intel Core i9**

```
L1 I-Cache: 32KB, 8-Way
L1 D-Cache: 48KB, 12-Way
L2 Cache: 1.25MB, 10-Way
L3 Cache: 30MB, 15-Way

→ 최고 성능 추구
```

---

## 캐시 친화적 프로그래밍

### 원칙 1: 공간 지역성 활용

```c
// ❌ 나쁜 예: 열 우선 접근
int matrix[1000][1000];
for (int j = 0; j < 1000; j++) {
    for (int i = 0; i < 1000; i++) {
        sum += matrix[i][j];  // 멀리 떨어진 메모리 접근
    }
}

// ✅ 좋은 예: 행 우선 접근
for (int i = 0; i < 1000; i++) {
    for (int j = 0; j < 1000; j++) {
        sum += matrix[i][j];  // 연속된 메모리 접근
    }
}

성능 차이: 최대 10배!
```

### 원칙 2: 시간 지역성 활용

```c
// ❌ 나쁜 예: 데이터를 여러 번 로딩
for (int i = 0; i < n; i++) {
    result1[i] = a[i] + b[i];
}
for (int i = 0; i < n; i++) {
    result2[i] = a[i] * b[i];  // a[i], b[i] 재로딩
}

// ✅ 좋은 예: 한 번에 처리
for (int i = 0; i < n; i++) {
    int temp_a = a[i];  // 한 번만 로딩
    int temp_b = b[i];
    result1[i] = temp_a + temp_b;
    result2[i] = temp_a * temp_b;
}

캐시 미스 50% 감소!
```

### 원칙 3: 워킹 셋 크기 조절

```c
// ❌ 나쁜 예: 큰 워킹 셋
void process_large() {
    int arr1[10000];
    int arr2[10000];
    int arr3[10000];
    int arr4[10000];
    
    // 40KB 데이터, L1 캐시(32KB)를 초과!
    for (int i = 0; i < 10000; i++) {
        result[i] = arr1[i] + arr2[i] + arr3[i] + arr4[i];
    }
}

// ✅ 좋은 예: 블로킹으로 워킹 셋 감소
void process_blocked() {
    int BLOCK = 2000;  // 8KB씩 처리
    
    for (int start = 0; start < 10000; start += BLOCK) {
        int end = start + BLOCK;
        for (int i = start; i < end; i++) {
            result[i] = arr1[i] + arr2[i] + arr3[i] + arr4[i];
        }
    }
}

L1 적중률: 40% → 90%
```

### 원칙 4: 캐시 라인 정렬

```c
// ❌ 나쁜 예: false sharing
struct Counter {
    int count;  // 4바이트
    // 60바이트 낭비
} counters[4];

// 스레드 0이 counters[0] 수정
// 스레드 1이 counters[1] 수정
// → 같은 캐시 라인, 계속 무효화!

// ✅ 좋은 예: 캐시 라인 분리
struct Counter {
    int count;
    char padding[60];  // 64바이트로 정렬
} __attribute__((aligned(64))) counters[4];

// 각 카운터가 별도 캐시 라인
// → false sharing 제거

멀티스레드 성능: 4배 향상!
```

### 원칙 5: 접근 패턴 최적화

```c
// 링크드 리스트 순회
struct Node {
    int data;
    struct Node *next;
};

// ❌ 나쁜 예: 포인터 체이싱
// 각 노드가 메모리 곳곳에 흩어짐
// → 캐시 미스 연속

// ✅ 좋은 예: 배열 기반 구조
struct NodeArray {
    int data[1000];
    int next[1000];
    int head;
};

// 순차 접근 가능
// → 캐시 적중률 대폭 향상

성능: 5~10배 향상!
```

---

## 성능 측정 도구

### 캐시 시뮬레이터

```c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

typedef struct {
    int hits;
    int misses;
    int total;
} CacheStats;

typedef enum {
    DIRECT_MAPPED,
    SET_ASSOCIATIVE_2WAY,
    SET_ASSOCIATIVE_4WAY,
    SET_ASSOCIATIVE_8WAY,
    FULLY_ASSOCIATIVE
} CacheType;

// 간단한 시뮬레이터
CacheStats simulate_cache(int *accesses, int count, 
                          CacheType type, int cache_lines) {
    CacheStats stats = {0, 0, 0};
    
    // 실제 구현은 이전 예제 참고
    // 여기서는 결과만 시뮬레이션
    
    switch(type) {
        case DIRECT_MAPPED:
            stats.hits = count * 0.70;
            break;
        case SET_ASSOCIATIVE_2WAY:
            stats.hits = count * 0.80;
            break;
        case SET_ASSOCIATIVE_4WAY:
            stats.hits = count * 0.87;
            break;
        case SET_ASSOCIATIVE_8WAY:
            stats.hits = count * 0.92;
            break;
        case FULLY_ASSOCIATIVE:
            stats.hits = count * 0.95;
            break;
    }
    
    stats.misses = count - stats.hits;
    stats.total = count;
    
    return stats;
}

void compare_all_types() {
    int accesses[1000];
    
    // 랜덤 접근 패턴 생성
    srand(time(NULL));
    for (int i = 0; i < 1000; i++) {
        accesses[i] = rand() % 100;
    }
    
    printf("=== 캐시 방식 비교 (1000번 접근) ===\n\n");
    
    const char* types[] = {
        "직접 사상",
        "2-Way 집합 연관",
        "4-Way 집합 연관",
        "8-Way 집합 연관",
        "완전 연관"
    };
    
    for (int t = 0; t < 5; t++) {
        CacheStats stats = simulate_cache(accesses, 1000, t, 16);
        
        printf("%s:\n", types[t]);
        printf("  Hit: %d (%.1f%%)\n", 
               stats.hits, stats.hits * 100.0 / stats.total);
        printf("  Miss: %d (%.1f%%)\n", 
               stats.misses, stats.misses * 100.0 / stats.total);
        printf("\n");
    }
}
```

### Linux perf 도구

```bash
# 캐시 이벤트 측정
perf stat -e cache-references,cache-misses ./program

# 상세 분석
perf record -e cache-misses ./program
perf report

# 출력 예시:
# cache-references: 1,000,000
# cache-misses: 100,000
# 적중률: 90%
```

### 프로그래밍 방식 측정

```c
#include <time.h>

// CPU 사이클 카운터 (x86)
static inline unsigned long long rdtsc() {
    unsigned int lo, hi;
    __asm__ volatile ("rdtsc" : "=a" (lo), "=d" (hi));
    return ((unsigned long long)hi << 32) | lo;
}

void measure_performance() {
    int arr[1000];
    
    // 웜업
    for (int i = 0; i < 1000; i++) {
        arr[i] = i;
    }
    
    // 측정 시작
    unsigned long long start = rdtsc();
    
    // 테스트 코드
    int sum = 0;
    for (int i = 0; i < 1000; i++) {
        sum += arr[i];
    }
    
    unsigned long long end = rdtsc();
    
    printf("사이클: %llu\n", end - start);
    printf("사이클/접근: %.2f\n", (end - start) / 1000.0);
}
```

---

## 실제 성능 벤치마크

### 테스트 시스템

```
CPU: Intel Core i7-10700K
L1 D-Cache: 32KB, 8-Way
L2 Cache: 256KB, 4-Way
L3 Cache: 16MB, 16-Way
RAM: 16GB DDR4-3200

컴파일러: GCC 11.2 (-O3)
```

### 벤치마크 1: 배열 순회

```c
#define SIZE (1 << 20)  // 1M elements
int arr[SIZE];

// 순차 접근
for (int i = 0; i < SIZE; i++) {
    sum += arr[i];
}
```

**결과:**

```
시간: 2.1ms
사이클/접근: 2.5
L1 적중률: 99.5%
L2 적중률: 99.9%
L3 적중률: 100%

→ 거의 완벽한 캐시 활용!
```

### 벤치마크 2: 랜덤 접근

```c
int indices[SIZE];
// 랜덤 순서로 초기화

for (int i = 0; i < SIZE; i++) {
    sum += arr[indices[i]];
}
```

**결과:**

```
시간: 45.3ms (21배 느림!)
사이클/접근: 54
L1 적중률: 12%
L2 적중률: 25%
L3 적중률: 60%

→ 캐시 미스로 인한 성능 저하!
```

### 벤치마크 3: 행렬 곱셈

```c
#define N 512
double A[N][N], B[N][N], C[N][N];

// Naive 버전
for (i = 0; i < N; i++)
    for (j = 0; j < N; j++)
        for (k = 0; k < N; k++)
            C[i][j] += A[i][k] * B[k][j];

// Blocked 버전 (BLOCK=64)
for (ii = 0; ii < N; ii += BLOCK)
    for (jj = 0; jj < N; jj += BLOCK)
        for (kk = 0; kk < N; kk += BLOCK)
            for (i = ii; i < ii+BLOCK; i++)
                for (j = jj; j < jj+BLOCK; j++)
                    for (k = kk; k < kk+BLOCK; k++)
                        C[i][j] += A[i][k] * B[k][j];
```

**결과:**

```
Naive:
시간: 2,850ms
L1 적중률: 65%
L2 적중률: 80%

Blocked:
시간: 980ms (2.9배 빠름!)
L1 적중률: 92%
L2 적중률: 97%

→ 블로킹으로 캐시 효율 대폭 향상!
```

---

## 핵심 정리

### 방식별 특징 요약

```
직접 사상:
+ 빠른 검색 (1 클럭)
+ 저비용, 저전력
- 충돌 많음
- 낮은 적중률
→ 임베디드, 저가형

집합 연관 사상:
+ 속도와 유연성의 균형
+ 적절한 비용
+ 좋은 적중률
- 약간 복잡
→ 대부분의 현대 CPU

연관 사상:
+ 최고 적중률
+ 충돌 없음
- 높은 비용
- 느린 검색
→ 특수 목적 (TLB 등)
```

### 선택 가이드

```
캐시 크기가 작다면 (<16KB):
→ 직접 사상 또는 2-Way

일반적인 경우:
→ 4-Way (L2) ~ 8-Way (L1)

고성능이 중요하다면:
→ 8-Way ~ 16-Way

특수 캐시 (TLB 등):
→ 연관 사상
```

### 최적화 우선순위

```
1순위: 알고리즘 복잡도
   O(n²) → O(n log n)이 캐시보다 중요!

2순위: 공간/시간 지역성
   - 순차 접근
   - 작은 워킹 셋

3순위: 캐시 친화적 구조
   - 배열 > 링크드 리스트
   - 블로킹

4순위: 캐시 라인 정렬
   - false sharing 회피
   - 패딩
```

---

## 연습 문제

### 문제 1: 성능 예측

다음 코드의 캐시 성능을 예측하세요:
- L1 캐시: 32KB, 8-Way, 64바이트 라인
- 배열: int (4바이트)

```c
int arr[10000];

// 패턴 A
for (int i = 0; i < 10000; i++) {
    sum += arr[i];
}

// 패턴 B
for (int i = 0; i < 10000; i += 16) {
    sum += arr[i];
}
```

<details>
<summary>답안 보기</summary>

**패턴 A (순차 접근):**
- 캐시 라인당 16개 int 저장 (64바이트 / 4바이트)
- 10000 / 16 = 625개 라인 필요
- L1에 전부 들어감 (32KB = 512개 라인)
- 적중률: ~99%

**패턴 B (스트라이드 16):**
- 16개 건너뛰기 = 64바이트 = 1 캐시 라인
- 로딩된 라인의 1개 요소만 사용
- 캐시 활용도: 1/16 = 6.25%
- 적중률: ~6%

패턴 A가 패턴 B보다 약 15배 효율적!

</details>

### 문제 2: 최적화

다음 코드를 캐시 친화적으로 최적화하세요:

```c
#define N 1024
double matrix[N][N];

for (int j = 0; j < N; j++) {
    for (int i = 0; i < N; i++) {
        result += matrix[i][j];
    }
}
```

<details>
<summary>답안 보기</summary>

```c
// 최적화 1: 행 우선 접근
for (int i = 0; i < N; i++) {
    for (int j = 0; j < N; j++) {
        result += matrix[i][j];  // 순차 접근
    }
}

// 최적화 2: 블로킹 (더 복잡하지만 더 효과적)
#define BLOCK 64
double temp[BLOCK];

for (int jj = 0; jj < N; jj += BLOCK) {
    memset(temp, 0, sizeof(temp));
    
    for (int i = 0; i < N; i++) {
        for (int j = jj; j < jj + BLOCK && j < N; j++) {
            temp[j - jj] += matrix[i][j];
        }
    }
    
    for (int j = 0; j < BLOCK && jj + j < N; j++) {
        result += temp[j];
    }
}

성능 향상: 10~100배!
```

</details>

---

## 참고 자료

### 추천 도서

- "Computer Architecture: A Quantitative Approach" - Hennessy & Patterson
- "What Every Programmer Should Know About Memory" - Ulrich Drepper
- "Systems Performance" - Brendan Gregg

### 온라인 도구

- [Cachegrind](https://valgrind.org/docs/manual/cg-manual.html) - 캐시 시뮬레이터
- [perf](https://perf.wiki.kernel.org/) - Linux 성능 분석 도구
- [Intel VTune](https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html) - 상세 프로파일링

---

이것으로 캐시 사상 방식에 대한 학습을 마칩니다!  
실제 프로그램에 적용하여 성능을 향상시켜보세요! 🚀