---
title: "캐시 메모리의 개념과 기본 동작"
description: "캐시 메모리가 무엇인지, 왜 필요한지, 어떻게 동작하는지 기초부터 상세히 학습합니다."
slug: "cache-memory-basics"
sidebar_position: 1
---

# 캐시 메모리의 개념과 기본 동작

## 캐시 메모리란?

캐시 메모리(Cache Memory)는 CPU와 주기억장치(RAM) 사이에 위치한 **고속 임시 저장 장치**입니다.

### 일상 비유로 이해하기

캐시 메모리를 도서관에 비유하면 다음과 같습니다:

```
🏛️ 도서관 (메인 메모리)
  - 모든 책이 있음
  - 멀리 있어서 왕복 시간이 오래 걸림
  
📚 책상 옆 책꽂이 (캐시 메모리)
  - 자주 보는 책만 보관
  - 가까워서 즉시 꺼낼 수 있음
  
👨‍💻 책상 (CPU)
  - 실제로 책을 읽는 곳
  - 필요한 책을 빨리 받고 싶음
```

매번 도서관까지 가는 대신, 자주 보는 책을 책상 옆에 두면 훨씬 빠르게 접근할 수 있습니다!

## 왜 캐시 메모리가 필요한가?

### CPU와 RAM의 속도 차이 문제

현대 컴퓨터에서 CPU와 주기억장치(RAM) 사이에는 **엄청난 속도 차이**가 존재합니다.

```
CPU 동작 속도:  3.0 GHz (1초에 30억 번 동작)
                ⚡️⚡️⚡️ 초고속!

RAM 접근 시간:  50 나노초 (0.00000005초)
                🐢 상대적으로 매우 느림
```

**문제 상황:**

```javascript
// CPU가 데이터를 요청하는 상황
CPU: "RAM에 있는 데이터 주세요!"
    ↓ 요청
RAM: "네, 잠시만요... (50ns 소요)"
    ↓ 대기... 대기... 대기...
CPU: "..." (아무것도 못하고 기다림)
    ↓ 데이터 도착
CPU: "감사합니다! (드디어 작업 시작)"

// CPU 입장에서는 엄청나게 긴 대기 시간!
```

### 대기 시간의 누적

프로그램 실행 중에는 수억 번의 메모리 접근이 발생합니다:

```javascript
// 간단한 루프 예시
for (let i = 0; i < 1000000000; i++) {  // 10억 번 반복
    sum += array[i];  // 매번 메모리 접근!
}

// 만약 매번 RAM에서 가져온다면?
총 대기 시간 = 10억 번 × 50ns = 50초!
// 프로그램이 너무 느려짐 😱
```

### 캐시의 역할

캐시는 이 **대기 시간을 대폭 줄이는 완충 장치**입니다:

```
캐시 없을 때:
CPU → [긴 대기] → RAM → [데이터] → CPU
평균 시간: 50ns

캐시 있을 때:
CPU → [거의 즉시] → 캐시 → [데이터] → CPU
평균 시간: 5ns (10배 빠름!)
```

## 캐시 메모리의 특징

### 1. SRAM으로 제작

캐시는 **SRAM (Static RAM)**이라는 특수한 메모리로 만들어집니다.

**SRAM vs DRAM 비교:**

| 특성 | SRAM (캐시용) | DRAM (메인 메모리용) |
|------|--------------|-------------------|
| **속도** | 매우 빠름 ⚡ | 상대적으로 느림 |
| **가격** | 매우 비쌈 💰💰💰 | 저렴함 💰 |
| **전력 소비** | 높음 | 낮음 |
| **용량** | 작음 | 큼 |
| **구조** | 복잡 (트랜지스터 6개) | 간단 (트랜지스터 1개) |
| **리프레시** | 불필요 | 필요 |

**SRAM의 동작 원리:**

```
DRAM (메인 메모리):
┌─────────┐
│ 커패시터 │ → 전하를 저장
└─────────┘
- 시간이 지나면 전하 방전
- 주기적으로 리프레시 필요 (느림)

SRAM (캐시):
┌──────────────┐
│ 플립플롭 회로 │ → 전원만 있으면 유지
└──────────────┘
- 리프레시 불필요
- 즉시 접근 가능 (빠름)
```

### 2. 작은 용량

**캐시는 왜 작을까요?**

```
비용 문제:
SRAM 1MB = DRAM 100MB 정도의 가격
→ 대용량으로 만들면 너무 비쌈!

공간 문제:
CPU 칩 내부 공간 제한
→ 물리적으로 많이 넣을 수 없음

복잡도 문제:
용량이 커지면 주소 해독 회로 복잡
→ 접근 시간 증가
```

**현실적인 캐시 크기:**

```javascript
// 현대 CPU의 전형적인 캐시 구성
L1 캐시: 32KB ~ 64KB
L2 캐시: 256KB ~ 1MB
L3 캐시: 4MB ~ 32MB

// 메인 메모리와 비교
메인 메모리: 8GB ~ 64GB

// 용량 비율
메인 메모리 / L1 캐시 = 약 100,000 배!
```

### 3. CPU 내부 위치

캐시는 CPU 칩 **안에** 위치합니다:

```
┌─────────────────────────────┐
│         CPU 칩              │
│  ┌────────┐  ┌──────────┐  │
│  │  코어  │  │ L1 캐시  │  │ ← CPU 내부
│  └────────┘  └──────────┘  │
│  ┌──────────┐              │
│  │ L2 캐시  │              │ ← CPU 내부
│  └──────────┘              │
└─────────────────────────────┘
         ↕ 외부 버스
┌─────────────────────────────┐
│      메인 메모리 (RAM)       │ ← CPU 외부
└─────────────────────────────┘
```

**위치가 중요한 이유:**

```
CPU 내부:
- 전기 신호 이동 거리: 수 mm
- 접근 시간: 1~5 나노초

CPU 외부 (메인보드):
- 전기 신호 이동 거리: 수십 cm
- 버스 통과 필요
- 접근 시간: 50~100 나노초

→ 거리가 멀수록 느림!
```

### 4. 고가의 메모리

**가격 비교:**

```javascript
// 2024년 기준 대략적인 가격 (예시)
SRAM (캐시용):
  1MB ≈ $50~100

DRAM (메인 메모리용):
  1GB ≈ $3~5
  1MB ≈ $0.003~0.005

// SRAM이 약 10,000배 이상 비쌈!
```

**그럼에도 캐시를 사용하는 이유:**

```
성능 향상 효과 >> 비용

작은 용량의 SRAM으로도
전체 시스템 성능을 2~10배 향상!
```

## 캐시 메모리의 계층 구조

### 전체 메모리 계층

컴퓨터의 메모리는 **피라미드 구조**로 되어 있습니다:

```
          ▲ 속도
          │
   [레지스터]          ← 가장 빠름, 가장 작음, 가장 비쌈
    (CPU 내부)           0.3ns, 수백 바이트
          │
    [L1 캐시]          ← 매우 빠름, 작음, 매우 비쌈
    (CPU 내부)           1~2ns, 32~64KB
          │
    [L2 캐시]          ← 빠름, 중간, 비쌈
    (CPU 내부)           3~10ns, 256KB~1MB
          │
    [L3 캐시]          ← 보통, 큼, 비쌈
    (CPU 패키지)         10~20ns, 4~32MB
          │
  [메인 메모리]        ← 느림, 매우 큼, 저렴
    (RAM)              50~100ns, 8~64GB
          │
 [보조기억장치]        ← 매우 느림, 초대용량, 매우 저렴
  (SSD/HDD)           수 ms, 수백 GB ~ TB
          ▼
        용량
```

### 데이터 전송 방식

캐시와 메인 메모리 사이의 데이터 전송은 특별한 방식을 사용합니다:

```
메인 메모리 → 캐시: 블록 전송 (Block Transfer)
캐시 → CPU:        워드 전송 (Word Transfer)
```

**워드 (Word):**

```
워드 = CPU가 한 번에 처리하는 데이터 단위

32비트 시스템: 1 워드 = 4 바이트
64비트 시스템: 1 워드 = 8 바이트

예시:
int x = 10;  // 32비트 시스템에서 4바이트 = 1워드
```

**블록 (Block):**

```
블록 = 여러 워드를 묶은 단위

블록 크기: 보통 8~32 바이트
         = 2~8 워드 (32비트 시스템 기준)

┌──────┬──────┬──────┬──────┐
│워드0 │워드1 │워드2 │워드3 │  = 1블록 (16바이트)
└──────┴──────┴──────┴──────┘
```

**왜 블록 단위로 전송할까?**

```
이유 1: 공간적 지역성 활용
- 한 번에 인접 데이터를 함께 가져옴
- 다음 접근 시 캐시 히트 확률 높아짐

이유 2: 전송 효율성
- 한 번에 여러 데이터 전송이 개별 전송보다 효율적
- 버스 오버헤드 감소

예시:
array[0] 요청 시
→ array[0]~array[7]까지 블록으로 한꺼번에 가져옴
→ array[1], array[2] 접근 시 이미 캐시에 있음!
```

**전송 과정 시각화:**

```javascript
// CPU가 메모리 주소 1000번 요청

1단계: 주기억장치에서 블록 읽기
메모리 → 캐시
┌──────────────────────────┐
│ 주소 1000~1015 (16바이트) │ → 블록 전송
└──────────────────────────┘
        ↓
    [캐시 저장]

2단계: 캐시에서 CPU로 워드 전송
캐시 → CPU
┌──────┐
│ 1000 │ (4바이트) → 워드 전송
└──────┘
    ↓
  [CPU]
```

## 캐시의 기본 동작 원리

### 동작 흐름도

캐시는 다음과 같은 순서로 동작합니다:

```
[시작]
  ↓
[CPU가 메모리 접근 요청]
  ↓
[1단계: 캐시 먼저 조사]
  ↓
┌─────────────────┐
│ 캐시에 있나요?  │
└─────────────────┘
  ↓          ↓
 Yes        No
  ↓          ↓
[캐시 히트]  [캐시 미스]
  ↓          ↓
[즉시 읽기]  [메모리 접근]
  ↓          ↓
            [블록을 캐시로]
             ↓
            [캐시에 저장]
             ↓
            [CPU로 전달]
             ↓
           [완료]
```

### 상세 동작 과정

#### 1단계: CPU에서 주소 수신

```javascript
// CPU가 메모리 주소 요청
CPU.request({
    type: "READ",
    address: 0x1000,  // 읽고 싶은 주소
    size: 4           // 4바이트 읽기
});
```

**실제 상황 예시:**

```c
// C 프로그램
int x = array[10];  // array의 10번째 요소 읽기

// CPU 입장에서는:
// "메모리 주소 0x1000에 있는 4바이트를 달라!"
```

#### 2단계: 캐시 검사

```javascript
// 캐시가 주소를 확인하는 과정
function checkCache(address) {
    // 캐시의 각 라인을 검사
    for (let i = 0; i < cache.lineCount; i++) {
        if (cache.lines[i].tag === getTag(address)) {
            // 태그가 일치하면 캐시 히트!
            return {
                hit: true,
                data: cache.lines[i].data
            };
        }
    }
    
    // 모든 라인을 검사했지만 없음
    return {
        hit: false
    };
}
```

**캐시 검사 시각화:**

```
캐시 라인들:
┌────────┬──────────┐
│ 라인 0 │ 태그:100 │ ← 요청한 주소와 다름
├────────┼──────────┤
│ 라인 1 │ 태그:200 │ ← 요청한 주소와 다름
├────────┼──────────┤
│ 라인 2 │ 태그:1000│ ← 일치! 히트!
├────────┼──────────┤
│ 라인 3 │ 태그:300 │
└────────┴──────────┘

요청 주소: 0x1000
→ 라인 2에서 발견!
→ 캐시 히트!
```

#### 3-A: 캐시 히트 (Cache Hit)

데이터가 캐시에 있는 경우:

```javascript
// 캐시 히트 처리
function handleCacheHit(address) {
    // 1. 캐시에서 데이터 즉시 읽기
    const data = cache.read(address);
    
    // 2. CPU로 즉시 전달
    CPU.receiveData(data);
    
    // 3. 완료! (매우 빠름 - 약 1~5ns)
    console.log("캐시 히트! 빠른 접근 완료 ⚡");
}
```

**타임라인:**

```
0ns:  CPU 요청
1ns:  캐시 검사
2ns:  데이터 발견
3ns:  CPU로 전달
4ns:  완료!

총 소요 시간: 약 4ns
```

#### 3-B: 캐시 미스 (Cache Miss)

데이터가 캐시에 없는 경우:

```javascript
// 캐시 미스 처리
async function handleCacheMiss(address) {
    console.log("캐시 미스 발생... 메모리 접근 필요");
    
    // 1. 메인 메모리에서 블록 읽기
    const block = await mainMemory.readBlock(address);
    // (약 50ns 소요 - 느림!)
    
    // 2. 읽어온 블록을 캐시에 저장
    cache.writeBlock(address, block);
    
    // 3. 해당 워드를 CPU로 전달
    const word = block.getWord(address);
    CPU.receiveData(word);
    
    console.log("캐시 미스 처리 완료");
}
```

**타임라인:**

```
0ns:   CPU 요청
1ns:   캐시 검사
2ns:   캐시에 없음! (미스)
3ns:   메인 메모리 접근 시작
...    (대기...)
53ns:  메모리에서 블록 도착
54ns:  캐시에 저장
55ns:  CPU로 전달
56ns:  완료

총 소요 시간: 약 56ns (히트보다 14배 느림!)
```

### 전체 동작 코드 예시

```javascript
// 캐시 메모리 시뮬레이션
class CacheMemory {
    constructor() {
        this.lines = [];  // 캐시 라인들
        this.hitCount = 0;
        this.missCount = 0;
    }
    
    // 메모리 접근 요청
    async access(address) {
        console.log(`주소 ${address} 접근 요청`);
        
        // 1단계: 캐시 검사
        const result = this.checkCache(address);
        
        if (result.hit) {
            // 2-A단계: 캐시 히트
            this.hitCount++;
            console.log("✅ 캐시 히트! 즉시 반환");
            return result.data;
            
        } else {
            // 2-B단계: 캐시 미스
            this.missCount++;
            console.log("❌ 캐시 미스! 메모리 접근...");
            
            // 3단계: 메인 메모리에서 가져오기
            const block = await this.fetchFromMemory(address);
            
            // 4단계: 캐시에 저장
            this.storeInCache(address, block);
            
            // 5단계: 데이터 반환
            return block.getData(address);
        }
    }
    
    // 캐시 검사
    checkCache(address) {
        for (let line of this.lines) {
            if (line.contains(address)) {
                return {
                    hit: true,
                    data: line.getData(address)
                };
            }
        }
        return { hit: false };
    }
    
    // 메인 메모리에서 가져오기
    async fetchFromMemory(address) {
        // 실제로는 50ns 정도 소요
        await this.delay(50);
        return mainMemory.readBlock(address);
    }
    
    // 캐시에 저장
    storeInCache(address, block) {
        // 캐시 라인에 블록 저장
        const line = this.findEmptyLine() || this.evictLine();
        line.store(address, block);
    }
    
    // 통계 출력
    getStats() {
        const total = this.hitCount + this.missCount;
        const hitRate = this.hitCount / total;
        
        console.log(`
통계:
- 총 접근: ${total}회
- 히트: ${this.hitCount}회
- 미스: ${this.missCount}회
- 히트율: ${(hitRate * 100).toFixed(2)}%
        `);
    }
}
```

### 동작 예시 시뮬레이션

```javascript
// 캐시 사용 예시
const cache = new CacheMemory();

// 프로그램 실행
async function runProgram() {
    // 첫 번째 접근 - 캐시 미스
    await cache.access(0x1000);
    // 출력: ❌ 캐시 미스! 메모리 접근... (56ns)
    
    // 두 번째 접근 - 같은 주소
    await cache.access(0x1000);
    // 출력: ✅ 캐시 히트! 즉시 반환 (4ns)
    
    // 세 번째 접근 - 인접 주소 (같은 블록)
    await cache.access(0x1004);
    // 출력: ✅ 캐시 히트! 즉시 반환 (4ns)
    // (블록 단위로 가져왔기 때문!)
    
    // 통계 출력
    cache.getStats();
    // 출력:
    // 총 접근: 3회
    // 히트: 2회
    // 미스: 1회
    // 히트율: 66.67%
}
```

## 캐시의 효과

### 성능 향상 예시

```javascript
// 배열 합계 계산 (캐시 없이)
let sum = 0;
for (let i = 0; i < 1000; i++) {
    sum += array[i];  // 매번 50ns 소요
}
// 총 시간: 1000 × 50ns = 50,000ns = 50μs

// 배열 합계 계산 (캐시 사용)
let sum = 0;
for (let i = 0; i < 1000; i++) {
    sum += array[i];  // 첫 접근만 50ns, 나머지는 4ns
}
// 블록 크기가 8워드라고 가정하면:
// 미스: 1000/8 = 125번 × 50ns = 6,250ns
// 히트: 875번 × 4ns = 3,500ns
// 총 시간: 9,750ns = 9.75μs

// 성능 향상: 50μs / 9.75μs ≈ 5배 빠름! 🚀
```

## 정리

### 핵심 개념

1. **캐시는 속도 격차 해결**
   - CPU와 RAM 사이의 속도 차이 완화
   - 대기 시간 감소

2. **SRAM 기반**
   - 빠르지만 비싸고 용량 작음
   - CPU 내부에 위치

3. **블록 단위 전송**
   - 메모리 → 캐시: 블록 전송
   - 캐시 → CPU: 워드 전송

4. **히트와 미스**
   - 히트: 빠름 (1~5ns)
   - 미스: 느림 (50~100ns)

### 다음 단계

다음 문서에서는 **캐시 히트와 미스**를 더 깊이 있게 다룹니다:
- 히트율과 미스율 계산
- 평균 메모리 접근 시간
- 성능 분석 방법

:::tip 학습 팁
캐시의 기본 동작 원리를 확실히 이해하면, 이후 내용들이 훨씬 쉬워집니다!
"히트는 빠르고, 미스는 느리다"는 기본 원리를 꼭 기억하세요.
:::