---
title: "계층적 캐시와 캐시 구조"
description: "L1, L2, L3 다단계 캐시 시스템의 동작 원리와 성능 분석, 통합 캐시와 분리 캐시의 차이를 상세히 학습합니다."
slug: "hierarchical-cache-structure"
sidebar_position: 6
---

# 계층적 캐시와 캐시 구조

## 왜 여러 단계의 캐시가 필요한가?

### 단일 캐시의 한계

하나의 캐시만 사용하면 **trade-off** 문제가 발생합니다:

```
큰 캐시 (예: 8MB):
  ✅ 장점: 높은 히트율
  ❌ 단점: 접근 시간 느림 (20ns)
         칩 면적 많이 차지
         전력 소비 많음

작은 캐시 (예: 32KB):
  ✅ 장점: 접근 시간 빠름 (1ns)
         칩 면적 적게 차지
  ❌ 단점: 낮은 히트율
```

### 해결책: 계층적 구조

**여러 단계의 캐시**를 사용하여 둘의 장점을 모두 취합니다!

```
작고 빠른 캐시 (L1)
   ↓ 미스
중간 크기 캐시 (L2)
   ↓ 미스
큰 캐시 (L3)
   ↓ 미스
메인 메모리
```

## 계층적 캐시 구조

### 전형적인 3단계 캐시

```
┌─────────────────────────────┐
│         CPU 코어            │
│  ┌────────┐  ┌──────────┐  │
│  │ 레지스터│  │ L1 캐시  │  │ ← 가장 빠름, 가장 작음
│  └────────┘  │ I-Cache  │  │   (코어마다 독립)
│              │ D-Cache  │  │
│              └──────────┘  │
│  ┌──────────────────────┐  │
│  │      L2 캐시         │  │ ← 빠름, 작음
│  │    (통합 캐시)       │  │   (코어마다 독립)
│  └──────────────────────┘  │
└─────────────────────────────┘
         ↕
┌─────────────────────────────┐
│        L3 캐시              │ ← 보통, 큼
│      (통합 캐시)            │   (모든 코어 공유)
└─────────────────────────────┘
         ↕
┌─────────────────────────────┐
│      메인 메모리 (RAM)       │ ← 느림, 매우 큼
└─────────────────────────────┘
```

### 각 레벨의 특성

| 캐시 | 크기 | 속도 | 위치 | 공유 |
|------|------|------|------|------|
| **L1** | 32~64 KB | 1~2 ns | CPU 코어 내부 | 코어 독립 |
| **L2** | 256KB~1MB | 3~10 ns | CPU 칩 내부 | 코어 독립 |
| **L3** | 4~32 MB | 10~20 ns | CPU 패키지 | 모든 코어 |
| **RAM** | 8~64 GB | 50~100 ns | 메인보드 | 시스템 전체 |

**크기와 속도의 관계:**

```
크기 ↑
속도 ↓

RAM    ████████████████  (매우 큼, 느림)
L3     ████████          (큼, 보통)
L2     ████              (중간, 빠름)
L1     ██                (작음, 매우 빠름)
레지스터 █                (매우 작음, 초고속)
```

## L1 캐시 (Level 1 Cache)

### 특징

**L1 캐시**는 CPU 코어에 가장 가까운 최상위 캐시입니다.

```
위치: CPU 코어 내부
크기: 32~64 KB (매우 작음)
속도: 1~2 ns (매우 빠름)
히트율: 95~99%
```

### 분리 캐시 구조

L1은 보통 **명령어 캐시(I-Cache)**와 **데이터 캐시(D-Cache)**로 분리됩니다.

```
CPU 코어
├─ L1 I-Cache (32KB)  ← 명령어 전용
│    └─ 프로그램 코드 저장
│
└─ L1 D-Cache (32KB)  ← 데이터 전용
     └─ 변수, 배열 등 저장
```

**왜 분리할까요?**

```c
// 프로그램 실행
int sum = 0;           // 데이터
for (int i = 0; i < 100; i++) {  // 명령어 + 데이터
    sum += array[i];   // 명령어 + 데이터
}

// 동시 접근 가능!
명령어 캐시에서 "sum += array[i]" 명령 가져옴
     +
데이터 캐시에서 "array[i]" 데이터 가져옴
```

**이점:**

1. **병렬 처리**
   ```
   명령어 인출과 데이터 읽기를 동시에!
   → 파이프라인 효율 향상
   ```

2. **충돌 제거**
   ```
   명령어와 데이터가 같은 캐시 라인 경쟁 안 함
   ```

3. **성능 향상**
   ```
   CPI (Cycles Per Instruction) 감소
   → 더 빠른 실행
   ```

### L1 캐시 동작 예제

```c
// 프로그램
int array[100];
int sum = 0;

for (int i = 0; i < 100; i++) {
    sum += array[i];
}
```

**캐시 접근 분석:**

```javascript
// 루프 첫 반복
1. I-Cache: "for" 명령 가져오기 (1ns)
2. D-Cache: i 값 읽기 (1ns)
3. I-Cache: "sum += array[i]" 명령 (히트, 0ns)
4. D-Cache: array[0] 읽기 (미스, 블록 로드)
5. D-Cache: sum 읽기/쓰기 (히트)

// 루프 두 번째 반복
1. I-Cache: 명령 (히트, 거의 0ns)  ← 이미 로드됨
2. D-Cache: i 값 (히트)
3. D-Cache: array[1] (히트)  ← 블록에 포함됨
4. D-Cache: sum (히트)

// I-Cache와 D-Cache가 동시 동작 → 빠름!
```

## L2 캐시 (Level 2 Cache)

### 특징

**L2 캐시**는 L1보다 크고 느리지만, 메모리보다는 훨씬 빠릅니다.

```
위치: CPU 칩 내부 (코어 근처)
크기: 256KB ~ 1MB
속도: 3~10 ns
히트율: 80~95% (L1 미스 중)
구조: 통합 캐시 (명령어 + 데이터)
```

### 통합 캐시 구조

L2는 보통 **통합 캐시(Unified Cache)**입니다.

```
L2 캐시 (512KB)
┌────────────────────────┐
│ 명령어 + 데이터 혼합    │
│ [코드][데이터][코드]... │
└────────────────────────┘
```

**통합 캐시의 장점:**

1. **유연성**
   ```
   명령어:데이터 비율 자동 조정
   프로그램 특성에 따라 최적화
   ```

2. **공간 효율**
   ```
   전체 크기 동일 시 더 많은 데이터 저장 가능
   ```

**예시:**

```c
// 프로그램 A: 명령어 많음
void complexCalculation() {
    // 수백 줄의 코드
}
// L2에서 명령어 70%, 데이터 30% 사용

// 프로그램 B: 데이터 많음
int bigArray[10000];
// L2에서 명령어 30%, 데이터 70% 사용

// 통합 캐시는 자동으로 비율 조정!
```

### L2 캐시 동작

```
CPU 요청
  ↓
L1 캐시 확인
  ↓ 미스
L2 캐시 확인
  ↓ 히트
L2에서 데이터 가져옴
  ↓
L1에도 저장 (포함 정책)
  ↓
CPU로 전달
```

**코드 예시:**

```javascript
function accessMemory(address) {
    // 1단계: L1 확인
    if (L1.contains(address)) {
        return L1.read(address);  // 1~2ns
    }
    
    // 2단계: L2 확인
    if (L2.contains(address)) {
        const data = L2.read(address);  // 3~10ns
        L1.write(address, data);  // L1에도 저장
        return data;
    }
    
    // 3단계: L3 또는 메모리
    // ...
}
```

## L3 캐시 (Level 3 Cache)

### 특징

**L3 캐시**는 모든 CPU 코어가 **공유**하는 대용량 캐시입니다.

```
위치: CPU 패키지 내부
크기: 4~32 MB (매우 큼)
속도: 10~20 ns
히트율: 70~90% (L2 미스 중)
공유: 모든 코어
```

### 멀티코어 시스템에서의 L3

```
┌─────────────────────────────────────┐
│         CPU 패키지                  │
│  ┌──────┐  ┌──────┐  ┌──────┐      │
│  │ 코어0│  │ 코어1│  │ 코어2│      │
│  │ L1   │  │ L1   │  │ L1   │      │
│  │ L2   │  │ L2   │  │ L2   │      │
│  └──┬───┘  └──┬───┘  └──┬───┘      │
│     └─────────┼─────────┘           │
│               ↓                      │
│     ┌─────────────────────┐         │
│     │   L3 캐시 (공유)     │         │
│     │      (16 MB)        │         │
│     └─────────────────────┘         │
└─────────────────────────────────────┘
```

### L3의 역할

**1. 코어 간 데이터 공유**

```c
// 코어 0
int shared_data = 100;  // L3에 저장

// 코어 1
int value = shared_data;  // L3에서 빠르게 읽기
                          // (메모리 안 가도 됨)
```

**2. L1/L2 미스 완충**

```
L1 미스율: 5%
L2 미스율: 20% (L1 미스 중)
L3 히트율: 80% (L2 미스 중)

L3 덕분에 메모리 접근 대폭 감소!
```

**3. 대용량 작업 지원**

```c
// 큰 데이터셋
int bigArray[1000000];  // 4MB

// L1/L2는 작아서 다 못 담음
// L3의 일부를 사용하여 캐시
```

## 계층적 캐시의 동작

### 포함 정책 (Inclusive Cache)

**포함 정책**은 "상위 캐시의 데이터는 하위 캐시에도 있다"는 정책입니다.

```
L3: [A, B, C, D, E, F, G, H]
       ↑  ↑  ↑
L2:    [A, B, C]
          ↑
L1:       [A]

// L1 ⊆ L2 ⊆ L3
```

**장점:**
- 캐시 일관성 유지 쉬움
- L3 제거 시 L1/L2도 자동 무효화

**단점:**
- 공간 중복 (비효율적)

### 배타적 정책 (Exclusive Cache)

**배타적 정책**은 "각 레벨이 서로 다른 데이터를 갖는다"는 정책입니다.

```
L3: [D, E, F, G, H]
L2:    [B, C]
L1:       [A]

// L1 ∩ L2 ∩ L3 = ∅
```

**장점:**
- 전체 캐시 용량 최대 활용

**단점:**
- 구현 복잡
- 일관성 유지 어려움

### 다단계 접근 과정

```javascript
// 계층적 캐시 접근 알고리즘
async function hierarchicalCacheAccess(address) {
    // Level 1 확인
    if (L1.contains(address)) {
        console.log("L1 히트! (1ns)");
        return L1.read(address);
    }
    
    // Level 2 확인
    if (L2.contains(address)) {
        console.log("L1 미스, L2 히트! (5ns)");
        const data = L2.read(address);
        L1.write(address, data);  // L1에 저장
        return data;
    }
    
    // Level 3 확인
    if (L3.contains(address)) {
        console.log("L2 미스, L3 히트! (15ns)");
        const data = L3.read(address);
        L2.write(address, data);  // L2에 저장
        L1.write(address, data);  // L1에 저장
        return data;
    }
    
    // 메모리 접근
    console.log("모든 캐시 미스! 메모리 접근 (100ns)");
    const data = await mainMemory.read(address);
    L3.write(address, data);  // L3에 저장
    L2.write(address, data);  // L2에 저장
    L1.write(address, data);  // L1에 저장
    return data;
}
```

## 평균 접근 시간 계산

### 2단계 캐시 (L1 + L2)

**공식:**

```
Ta = h1 × T1 + (1-h1) × h2 × T2 + (1-h1) × (1-h2) × Tm

여기서:
h1 = L1 히트율
h2 = L2 히트율 (L1 미스 중)
T1 = L1 접근 시간
T2 = L2 접근 시간
Tm = 메모리 접근 시간
```

**예제:**

```javascript
// 조건
const T1 = 2;   // ns
const T2 = 5;   // ns
const Tm = 50;  // ns
const h1 = 0.95;  // 95%
const h2 = 0.90;  // 90% (L1 미스 중)

// 계산
const Ta = h1 * T1 +                    // L1 히트
           (1-h1) * h2 * T2 +           // L1 미스, L2 히트
           (1-h1) * (1-h2) * Tm;        // 모두 미스

// 결과
Ta = 0.95 * 2 + 0.05 * 0.90 * 5 + 0.05 * 0.10 * 50
   = 1.9 + 0.225 + 0.25
   = 2.375 ns

// L1만 있었다면:
Ta_L1 = 0.95 * 2 + 0.05 * 50 = 4.4 ns

// 성능 향상: 4.4 / 2.375 ≈ 1.85배! 🚀
```

### 3단계 캐시 (L1 + L2 + L3)

**공식:**

```
Ta = h1 × T1 + 
     (1-h1) × h2 × T2 +
     (1-h1) × (1-h2) × h3 × T3 +
     (1-h1) × (1-h2) × (1-h3) × Tm
```

**예제:**

```javascript
// 조건
const T1 = 2;   // ns
const T2 = 5;   // ns
const T3 = 15;  // ns
const Tm = 100; // ns
const h1 = 0.90;  // 90%
const h2 = 0.85;  // 85% (L1 미스 중)
const h3 = 0.75;  // 75% (L2 미스 중)

// 계산
Ta = 0.90 * 2 +                              // L1 히트
     0.10 * 0.85 * 5 +                       // L2 히트
     0.10 * 0.15 * 0.75 * 15 +               // L3 히트
     0.10 * 0.15 * 0.25 * 100;               // 메모리

Ta = 1.8 + 0.425 + 0.16875 + 0.375
   = 2.77 ns

// 엄청난 성능! 🚀
```

## 통합 캐시 vs 분리 캐시

### 통합 캐시 (Unified Cache)

**특징:**

```
┌─────────────────────────┐
│    통합 L1 캐시 64KB    │
├─────────────────────────┤
│ [명령어][데이터][명령어]│
│ [데이터][데이터][명령어]│
└─────────────────────────┘
```

**장점:**

1. **유연성**
   ```c
   // 코드 많은 프로그램
   → 명령어에 더 많은 공간 할당
   
   // 데이터 많은 프로그램
   → 데이터에 더 많은 공간 할당
   ```

2. **효율성**
   ```
   전체 크기 동일 시:
   통합 > 분리 (활용도)
   ```

**단점:**

1. **충돌**
   ```
   명령어와 데이터가 같은 라인 경쟁
   → 미스율 증가 가능
   ```

2. **순차 접근**
   ```
   명령어 인출과 데이터 읽기를
   동시에 못함 (병렬성 감소)
   ```

### 분리 캐시 (Split Cache)

**특징:**

```
┌─────────────────┐  ┌─────────────────┐
│ I-Cache (32KB)  │  │ D-Cache (32KB)  │
├─────────────────┤  ├─────────────────┤
│ [명령어]        │  │ [데이터]        │
│ [명령어]        │  │ [데이터]        │
└─────────────────┘  └─────────────────┘
```

**장점:**

1. **병렬 처리**
   ```
   명령어 인출 + 데이터 읽기 동시
   → CPI 감소
   ```

2. **충돌 제거**
   ```
   명령어와 데이터 독립 공간
   → 안정적인 성능
   ```

**단점:**

1. **유연성 부족**
   ```
   명령어 캐시 남는데 데이터 캐시 부족
   → 비효율 발생 가능
   ```

2. **복잡도 증가**
   ```
   두 개의 캐시 관리 필요
   ```

### 현대 시스템의 선택

```
L1: 분리 캐시 ✅
  - 병렬성 극대화
  - 최고 속도 필요

L2: 통합 캐시 ✅
  - 유연성
  - 공간 효율

L3: 통합 캐시 ✅
  - 대용량
  - 코어 간 공유
```

## 실전 예제

### 프로그램 성능 분석

```c
// 프로그램
void process() {
    int data[1000];
    
    for (int i = 0; i < 1000; i++) {
        data[i] = calculate(i);  // 복잡한 계산
    }
}
```

**캐시 동작 분석:**

```javascript
// 계층적 캐시 시뮬레이션

// 루프 첫 반복
1. I-Cache L1: "for" 명령 (미스)
   → I-Cache L2에서 로드 (5ns)
   → I-Cache L1에 저장

2. D-Cache L1: i 읽기 (미스)
   → D-Cache L2에서 로드 (5ns)
   
3. I-Cache L1: "calculate" 명령 (미스)
   → L2 확인 (미스)
   → L3에서 로드 (15ns)
   
4. D-Cache L1: data[0] 쓰기 (할당)

// 루프 두 번째 반복
1. I-Cache L1: 명령 (히트, 0ns)  ✅
2. D-Cache L1: i (히트, 0ns)  ✅
3. I-Cache L1: calculate (히트, 0ns)  ✅
4. D-Cache L1: data[1] (히트, 0ns)  ✅

// 이후 반복: 거의 모든 접근이 L1 히트!
// 평균 시간: 약 2ns (매우 빠름)
```

## 정리

### 핵심 개념

**1. 계층적 구조**
```
L1 (작고 빠름) → L2 (중간) → L3 (크고 느림) → RAM
각 레벨이 미스를 보완
```

**2. 레벨별 특징**
```
L1: 32-64KB, 1-2ns, 분리 캐시
L2: 256KB-1MB, 3-10ns, 통합 캐시
L3: 4-32MB, 10-20ns, 공유 캐시
```

**3. 성능 공식**
```
다단계 캐시의 평균 시간:
각 레벨의 히트율과 시간을 곱하여 합산
```

**4. 캐시 구조**
```
L1: 분리 (병렬성)
L2/L3: 통합 (유연성)
```

### 설계 원칙

```
작고 빠른 것 + 크고 느린 것 = 빠르고 충분한 용량

계층적 구조로:
- 대부분은 L1에서 히트 (빠름)
- 못 찾으면 L2, L3 (점진적으로 느려짐)
- 최악의 경우만 메모리 (드묾)

결과: 평균 2~5ns의 빠른 접근!
```

### 다음 단계

캐시 메모리의 기본 학습이 완료되었습니다!  
더 깊이 공부하고 싶다면:
- 캐시 일관성 프로토콜 (MESI, MOESI)
- 캐시 매핑 방식 (Direct, Associative, Set-Associative)
- TLB와 가상 메모리

:::tip 성능의 핵심
현대 CPU 성능의 비밀은 바로 **계층적 캐시**!  
L1 히트율 95%만 유지해도 거의 캐시 속도로 동작합니다.
:::