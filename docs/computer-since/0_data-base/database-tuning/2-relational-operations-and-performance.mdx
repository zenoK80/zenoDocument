---
title: "관계대수 연산과 성능 문제"
description: "관계대수 연산과 성능 문제에 대해 초보자도 쉽게 이해할 수 있도록 설명합니다."
slug: "/database-tuning/2-relational-operations-and-performance"
sidebar_label: "관계대수 연산과 성능"
date: "2026-02-21"
---

## 🎯 데이터베이스 튜닝이란 무엇인가?

### 튜닝의 개념: 자동차 엔진 조율처럼

여러분은 **"튜닝"**이라는 단어를 일상에서 많이 들어보셨을 겁니다. 자동차를 튜닝한다, 기타 줄을 튜닝한다, 피아노를 튜닝한다… 이 모든 것의 공통점은 **"성능이나 상태를 최적으로 맞추기 위해 조정하는 행위"**라는 점입니다.

기타를 예로 들어볼까요? 기타 줄의 음이 맞지 않으면 아무리 좋은 노래를 연주해도 듣기 싫은 소리가 납니다. 이때 각 줄의 장력을 조절해서 정확한 음을 맞추는 과정이 바로 튜닝입니다. 피아노도 마찬가지로, 줄의 음이 맞지 않으면 전문가가 와서 하나하나 음을 조정합니다.

**데이터베이스 튜닝**도 똑같은 원리입니다. 데이터베이스의 성능이 떨어졌거나, 더 빠르게 만들고 싶을 때, 여러 가지 설정값과 구조를 조정하는 모든 행위를 통틀어 **데이터베이스 튜닝**이라고 합니다.

> 💡 데이터베이스 튜닝 = 데이터베이스의 성능을 향상시키기 위해 수행하는 **모든 종류의 조정과 최적화 작업**

구체적으로는 데이터베이스 응용 프로그램, 데이터베이스 자체, 운영체제(OS) 등을 일부 조절해서 DBMS(데이터베이스 관리 시스템 — Oracle, MSSQL, MySQL 등)의 성능을 향상시켜주는 방법을 모두 포함합니다.

### 튜닝은 누가 하는가?

튜닝은 일반 응용 프로그래머가 하는 일이라기보다는 주로 **DBA(Database Administrator, 데이터베이스 관리자)** 급에서 수행하는 전문적인 작업입니다. IT 분야에서 일하고 계시거나 준비 중이신 분들은 이러한 튜닝 역량을 갖추면 **전문 IT 컨설턴트**로 성장할 수 있으며, 단순 개발만 하는 것보다 몸값을 훨씬 높일 수 있습니다.

:::tip 커리어 팁
단순히 프로그램을 개발하는 것에서 그치지 말고, 성능 분석과 튜닝까지 할 수 있는 역량을 갖추면 설계 → 개발 → 유지보수 → 성능 컨설팅까지 영역을 확장할 수 있습니다. 이것이 바로 시니어 개발자와 주니어 개발자의 차이입니다.
:::

---

## 🔍 관계대수 연산과 접근 루틴

### 관계대수 연산이 왜 중요한가?

이전 시간에 다뤘던 **관계대수(Relational Algebra)** 연산에는 **Selection(선택)**, **Projection(투영)**, **Join(조인)** 등 다양한 연산이 있습니다. 이 중에서 특히 **Join 연산**은 성능을 크게 떨어뜨리는 대표적인 "주범"입니다.

왜 Join이 성능에 나쁜 영향을 미칠까요? 생각해보세요:

- **하나의 테이블**에서 결과를 가져올 수 있다면, 그냥 그 테이블 하나만 읽으면 됩니다.
- 하지만 **하나의 테이블에서 원하는 결과를 모두 가져올 수 없기 때문에**, 여러 테이블을 가지고 와서 서로의 키(Key)를 비교하고, 맞는 결과를 찾아내야 합니다.
- 이 과정에서 **여러 테이블을 읽고**, **값을 비교하고**, **맞는 값을 추출하는** 여러 단계를 거쳐야 합니다.

마치 여러분이 서로 다른 서류 더미에서 같은 이름의 문서를 찾아 하나로 합치는 작업을 상상해보세요. 서류 더미가 많을수록, 각 더미의 양이 많을수록 작업 시간은 기하급수적으로 늘어나겠죠? Join 연산이 바로 이런 상황입니다.

> ⚠️ Join 연산이 많아진다 = 여러 테이블을 읽고, 비교하고, 추출하는 연산이 늘어난다 = **성능이 떨어진다**

그렇다고 Join을 아예 안 쓸 수는 없습니다. 여러 테이블에서 원하는 결과를 가져오려면 Join은 필수적일 수밖에 없습니다. 그래서 중요한 것은 **Join을 어떻게 효율적으로 수행하느냐**입니다.

### 접근 루틴이란?

**접근 루틴(Access Routine)**이란, 관계대수 연산(Selection, Join 등)을 **프로그래밍적으로 구현한 프로시저(절차)**를 말합니다. 쉽게 말해, "데이터를 어떤 방법으로 찾아갈 것인가"를 코드로 구현한 것입니다.

마치 도서관에서 책을 찾는 방법이 여러 가지인 것처럼 — 처음부터 끝까지 하나씩 보는 방법, 분류 번호를 이용하는 방법, 검색 시스템을 이용하는 방법 등 — 데이터를 찾는 방법도 여러 가지가 있고, 각각의 방법을 구현한 것이 바로 접근 루틴입니다.

:::info 알아두기
접근 루틴의 범위는 넓습니다. 관계대수 연산뿐 아니라, 결합(조합) 연산, 집단 함수(SUM, AVG, COUNT 등)를 실행하는 루틴도 모두 접근 루틴에 포함됩니다. 그리고 하나의 연산(예: Selection)도 **여러 가지 다른 접근 루틴**으로 구현할 수 있습니다.
:::

이러한 알고리즘을 이해하면, 나중에 데이터를 접근하거나 검색하는 프로그램을 개발할 때 **이론을 알고 개발하는 것**과 **모르고 그냥 개발하는 것** 사이에 엄청난 차이가 생깁니다.

---

## 📊 Selection(선택) 연산의 구현 방법

### Selection 연산이란?

Selection 연산은 **조건에 맞는 데이터를 찾아내는 연산**입니다. 마치 학생 명단에서 "시험 점수가 50점 이하인 학생"을 찾는 것과 같습니다.

예를 들어, 다음과 같은 학생 데이터가 있다고 가정해봅시다:

| 학번 | 점수 |
|------|------|
| 1    | 100  |
| 2    | 80   |
| 3    | 50   |
| 4    | 70   |
| 5    | 90   |

여기서 **"점수가 50점 이하인 학생의 학번을 찾아라"**라는 질의를 수행하려면, 관계대수로는 다음과 같이 표현합니다:

```
π(학번) σ(점수 ≤ 50) (R)
```

즉, R 테이블에서 점수가 50점 이하인 행을 **Selection(σ)**으로 찾고, 그중 학번만 **Projection(π)**으로 출력하는 것입니다.

그렇다면 이 50점을 어떻게 찾을 것인가? 여기에 **4가지 방법**이 있습니다.

### 방법 1: 선형 탐색 (Linear Search) 🐢

**선형 탐색**은 가장 단순한 방법입니다. 데이터가 정렬되어 있지 않은 상태에서, **처음부터 끝까지 하나씩 차례대로** 확인하는 방식입니다.

마치 책장에 꽂힌 책들이 아무 순서 없이 뒤섞여 있을 때, 원하는 책을 찾으려면 첫 번째 책부터 마지막 책까지 하나하나 확인해야 하는 것과 같습니다.

```python
# ✅ 선형 탐색 - 올바른 예시
def linear_search(students, target_score):
    """
    학생 리스트에서 목표 점수 이하인 학생을 찾는 선형 탐색
    - students: (학번, 점수) 튜플의 리스트
    - target_score: 찾고자 하는 기준 점수
    """
    results = []  # 결과를 저장할 빈 리스트
    for student in students:  # 모든 학생을 처음부터 끝까지 순회
        if student[1] <= target_score:  # 점수가 기준 이하인지 확인
            results.append(student[0])  # 조건 만족 시 학번을 결과에 추가
    return results  # 조건을 만족하는 학번 리스트 반환

# 학생 데이터: (학번, 점수)
students = [(1, 100), (2, 80), (3, 50), (4, 70), (5, 90)]

# 50점 이하인 학생 찾기
result = linear_search(students, 50)
print(result)  # 출력: [3] → 3번 학생만 50점 이하
```

위 코드를 한 줄씩 살펴보겠습니다:
- `results = []`: 조건에 맞는 학번을 모아둘 빈 리스트를 만듭니다.
- `for student in students`: 학생 리스트를 **처음부터 끝까지** 순서대로 하나씩 꺼냅니다.
- `if student[1] <= target_score`: 현재 학생의 점수(`student[1]`)가 목표 점수 이하인지 확인합니다.
- `results.append(student[0])`: 조건을 만족하면 해당 학생의 학번(`student[0]`)을 결과 리스트에 추가합니다.

**선형 탐색의 특징:**
- 데이터가 **정렬되어 있지 않아도** 사용 가능합니다.
- 최선의 경우(찾는 데이터가 맨 앞): **1번만에** 찾습니다.
- 최악의 경우(찾는 데이터가 맨 뒤): **N번** 확인해야 합니다.
- 평균적으로 **전체의 약 50%**를 탐색합니다.

:::warning 주의
선형 탐색은 데이터가 적을 때는 괜찮지만, 데이터가 100만 건, 1,000만 건이 되면 **매우 느려집니다**. 이때는 다른 방법을 사용해야 합니다.
:::

### 방법 2: 이진 탐색 (Binary Search) 🚀

**이진 탐색**은 데이터를 먼저 **정렬**한 후, **절반씩 잘라가며** 찾는 방법입니다.

마치 사전에서 단어를 찾는 것과 비슷합니다. "Korea"를 찾으려면, 사전을 한가운데 펴서 현재 페이지의 알파벳이 K보다 큰지 작은지 확인하고, K보다 크면 앞쪽 절반에서, 작으면 뒤쪽 절반에서 다시 가운데를 펴는 식으로 찾습니다.

구체적인 예시를 들어볼까요? 점수 데이터를 정렬하면:

| 순서 | 점수 |
|------|------|
| 1    | 50   |
| 2    | 70   |
| 3    | 80   |
| 4    | 90   |
| 5    | 100  |

50점을 찾고 싶다면:
1. **가운데 값(80)**과 비교 → 50은 80보다 작으므로 **왼쪽 절반**에 있다
2. 왼쪽 절반(50, 70)에서 다시 가운데 값을 찾아 비교
3. 50을 찾음!

```python
# ✅ 이진 탐색 - 올바른 예시
def binary_search(sorted_scores, target):
    """
    정렬된 점수 리스트에서 목표 점수를 찾는 이진 탐색
    - sorted_scores: 오름차순 정렬된 점수 리스트
    - target: 찾고자 하는 점수
    """
    left = 0                        # 탐색 범위의 왼쪽 끝 인덱스
    right = len(sorted_scores) - 1  # 탐색 범위의 오른쪽 끝 인덱스

    while left <= right:            # 탐색 범위가 유효한 동안 반복
        mid = (left + right) // 2   # 중간 인덱스 계산 (정수 나눗셈)
        if sorted_scores[mid] == target:  # 중간 값이 목표와 같으면
            return mid              # 해당 인덱스 반환 (찾았다!)
        elif sorted_scores[mid] > target: # 중간 값이 목표보다 크면
            right = mid - 1         # 왼쪽 절반으로 범위 축소
        else:                       # 중간 값이 목표보다 작으면
            left = mid + 1          # 오른쪽 절반으로 범위 축소

    return -1  # 찾지 못한 경우 -1 반환

# 정렬된 점수 데이터
sorted_scores = [50, 70, 80, 90, 100]

# 50점 찾기
index = binary_search(sorted_scores, 50)
print(f"50점의 위치: {index}")  # 출력: 50점의 위치: 0
```

```python
# ❌ 잘못된 예시 - 정렬되지 않은 데이터에 이진 탐색 적용
unsorted_scores = [100, 80, 50, 70, 90]  # 정렬 안 됨!
# 이진 탐색은 반드시 정렬된 데이터에서만 사용해야 합니다.
# 정렬되지 않은 데이터에 사용하면 잘못된 결과가 나옵니다!
index = binary_search(unsorted_scores, 50)
print(f"결과: {index}")  # ❌ 잘못된 결과가 나올 수 있음!
```

**이진 탐색의 핵심 조건:**
- 데이터가 반드시 **정렬되어 있어야** 합니다.
- 절반씩 잘라가므로 **탐색 횟수를 크게 줄여**줍니다.
- N개 데이터에서 최대 **log₂(N)번**만에 찾을 수 있습니다 (예: 100만 건 → 최대 약 20번).

### 방법 3: 인덱스를 이용한 탐색 📚

**인덱스(Index)**를 이용한 탐색은 마치 **책의 목차**를 활용하는 것과 같습니다.

여러분이 두꺼운 교과서에서 "데이터베이스 정규화"라는 내용이 있는 페이지를 찾고 싶다면 어떻게 하시겠습니까? 1페이지부터 한 장씩 넘기면서 찾겠습니까? 아닙니다. **목차를 먼저 보고**, 목차에서 해당 내용이 120페이지에 있다는 것을 확인한 후, 바로 120페이지로 이동합니다.

인덱스가 바로 이 "목차" 역할을 합니다. 데이터베이스에서 인덱스를 설정해두면, 원하는 데이터의 위치를 목차처럼 빠르게 찾아갈 수 있습니다.

### 방법 4: 해싱(Hashing)을 이용한 탐색 ⚡

**해싱**은 가장 빠른 방법입니다. **해시 함수(Hash Function)**라는 특수한 함수에 찾고 싶은 값을 넣으면, **바로 해당 데이터의 주소가 계산되어 나옵니다.**

마치 택배 송장 번호를 입력하면 바로 택배의 현재 위치가 나오는 것과 같습니다. 중간에 이것저것 찾을 필요 없이, 입력 → 결과가 바로 나오는 방식입니다.

예를 들어, `h("db")` 라는 해시 함수에 "db"를 넣으면 바로 **120**이라는 주소가 나오고, 120번 위치로 바로 이동해서 데이터를 가져올 수 있습니다.

### 4가지 탐색 방법 비교

| 방법 | 정렬 필요 | 속도 | 특징 |
|------|-----------|------|------|
| **선형 탐색** | ❌ 불필요 | 🐢 느림 | 처음부터 끝까지 하나씩 확인 |
| **이진 탐색** | ✅ 필요 | 🐇 빠름 | 절반씩 잘라가며 탐색 |
| **인덱스 탐색** | ❌ 불필요(인덱스 필요) | 🐇 빠름 | 목차(인덱스)를 통해 위치 확인 후 접근 |
| **해싱** | ❌ 불필요 | ⚡ 매우 빠름 | 해시 함수로 주소를 계산해 한 번에 접근 |

---

## 🔗 Join(조인) 연산의 구현 방법

Join 연산은 Selection보다 **훨씬 복잡**합니다. 하나의 테이블이 아니라 **두 개 이상의 테이블**을 엮어서 결과를 만들어내야 하기 때문입니다.

R이라는 테이블과 S라는 테이블이 있을 때, R에 있는 특정 컬럼(열)의 값과 S에 있는 특정 컬럼의 값을 비교해서 일치하는 것들을 합치는 것이 바로 **Join 연산**입니다.

### 방법 1: 정렬 병합 조인 (Sort-Merge Join) 📋

**정렬 병합 조인(Sort-Merge Join)**은 이름 그대로 **"정렬(Sort)한 후 병합(Merge)하는"** 방식입니다.

#### 실생활 비유로 이해하기

여러분 앞에 두 묶음의 종이가 있다고 상상해보세요:
- **왼쪽 묶음(R)**: 학생 정보가 적힌 종이들 (뒤죽박죽 섞여 있음)
- **오른쪽 묶음(S)**: 성적 정보가 적힌 종이들 (뒤죽박죽 섞여 있음)

두 묶음에서 **같은 학번**의 종이를 찾아 짝지어야 합니다.

**비효율적인 방법**: 왼쪽에서 A를 꺼내고, 오른쪽 전체를 뒤져서 A를 찾고. 왼쪽에서 B를 꺼내고, 오른쪽 전체를 또 뒤져서 B를 찾고... 이러면 너무 오래 걸립니다.

**정렬 병합 조인 방법**: 
1. 먼저 **왼쪽 묶음을 학번 순서대로 정렬**합니다 (A, B, C, D, ...)
2. **오른쪽 묶음도 학번 순서대로 정렬**합니다 (A, B, C, D, ...)
3. 이제 양쪽 모두 정렬되어 있으니, **맨 위부터 동시에** 하나씩 비교하면서 같은 것을 찾아가면 됩니다!

양쪽 다 정렬되어 있으면, 맨 위에는 당연히 A와 A가 있겠죠? 그다음엔 B와 B... 이렇게 **순서대로 쉽게 매칭**할 수 있습니다.

```python
# ✅ 정렬 병합 조인 - 올바른 예시
def sort_merge_join(table_r, table_s, key_r, key_s):
    """
    정렬 병합 조인 구현
    - table_r: 왼쪽 테이블 (딕셔너리 리스트)
    - table_s: 오른쪽 테이블 (딕셔너리 리스트)
    - key_r: R 테이블의 조인 키 이름
    - key_s: S 테이블의 조인 키 이름
    """
    # 1단계: 양쪽 테이블을 조인 키 기준으로 정렬
    sorted_r = sorted(table_r, key=lambda x: x[key_r])  # R을 키 기준 정렬
    sorted_s = sorted(table_s, key=lambda x: x[key_s])  # S를 키 기준 정렬

    result = []     # 조인 결과를 저장할 리스트
    i = 0           # R 테이블의 현재 위치를 가리키는 포인터
    j = 0           # S 테이블의 현재 위치를 가리키는 포인터

    # 2단계: 양쪽을 동시에 순회하면서 비교
    while i < len(sorted_r) and j < len(sorted_s):  # 둘 다 끝에 도달하지 않은 동안
        if sorted_r[i][key_r] == sorted_s[j][key_s]:   # 키 값이 같으면
            # 조인 성공! 두 레코드를 합쳐서 결과에 추가
            merged = {**sorted_r[i], **sorted_s[j]}
            result.append(merged)
            i += 1  # R의 다음 레코드로 이동
            j += 1  # S의 다음 레코드로 이동
        elif sorted_r[i][key_r] < sorted_s[j][key_s]:  # R의 키가 더 작으면
            i += 1  # R을 앞으로 이동 (S에서 매칭되는 값이 없으므로)
        else:       # S의 키가 더 작으면
            j += 1  # S를 앞으로 이동

    return result

# 학생 테이블 (R)
students = [
    {"학번": 3, "이름": "김철수"},
    {"학번": 1, "이름": "이영희"},
    {"학번": 2, "이름": "박민수"},
]

# 성적 테이블 (S)
scores = [
    {"학번": 2, "점수": 80},
    {"학번": 3, "점수": 50},
    {"학번": 1, "점수": 100},
]

# 정렬 병합 조인 실행
joined = sort_merge_join(students, scores, "학번", "학번")
for row in joined:
    print(row)
# 출력:
# {'학번': 1, '이름': '이영희', '점수': 100}
# {'학번': 2, '이름': '박민수', '점수': 80}
# {'학번': 3, '이름': '김철수', '점수': 50}
```

코드를 한 줄씩 살펴보겠습니다:

- `sorted_r = sorted(table_r, key=lambda x: x[key_r])`: R 테이블을 조인 키(학번) 기준으로 **오름차순 정렬**합니다. 이것이 정렬 병합 조인의 핵심 첫 단계입니다.
- `sorted_s = sorted(table_s, key=lambda x: x[key_s])`: S 테이블도 마찬가지로 정렬합니다.
- `i = 0`, `j = 0`: 두 개의 **포인터(현재 위치를 가리키는 변수)**를 준비합니다. 마치 두 손가락으로 각각의 묶음을 짚는 것과 같습니다.
- `while` 루프: 양쪽 테이블을 **동시에** 순회하면서 키 값을 비교합니다.
- 키 값이 같으면 조인하고, R이 작으면 R을 앞으로, S가 작으면 S를 앞으로 이동합니다.

**정렬 병합 조인의 특징:**

| 항목 | 설명 |
|------|------|
| **전제 조건** | 양쪽 테이블이 반드시 **정렬**되어 있어야 함 |
| **적합한 상황** | **전체 데이터**를 처리해야 할 때, 처리량이 많을 때 |
| **핵심 원리** | 정렬 후 양쪽을 동시에 비교하며 매칭 |

> 🔑 정렬 병합 조인 = 양쪽 정렬 → 동시에 처음부터 끝까지 비교하며 매칭

### 방법 2: 중첩 루프 조인 (Nested Loop Join) 🔄

**중첩 루프 조인(Nested Loop Join)**은 정렬 병합 조인과 다르게, **데이터를 정렬하지 않습니다.** 대신, 한쪽 테이블의 특정 범위에 해당하는 레코드를 가지고, 다른 쪽 테이블 전체를 **반복(루프)하면서** 매칭되는 것을 찾는 방식입니다.

#### 핵심 용어: 선행(Driving) 테이블과 후행(Driven) 테이블

- **선행 테이블(Driving Table)**: 처리 범위를 결정하는 테이블 (바깥쪽 루프)
- **후행 테이블(Driven Table)**: 선행 테이블에서 추출된 값으로 검색 대상이 되는 테이블 (안쪽 루프)

마치 식당에서 주문표(선행 테이블)를 보고, 각 주문에 맞는 재료를 창고(후행 테이블)에서 찾는 것과 같습니다. 주문표에 있는 메뉴 하나하나마다 창고를 뒤져서 재료를 가져오는 방식입니다.

```python
# ✅ 중첩 루프 조인 - 올바른 예시
def nested_loop_join(driving_table, driven_table, key_d, key_v):
    """
    중첩 루프 조인 구현
    - driving_table: 선행(Driving) 테이블 - 바깥 루프
    - driven_table: 후행(Driven) 테이블 - 안쪽 루프
    - key_d: 선행 테이블의 조인 키
    - key_v: 후행 테이블의 조인 키
    """
    result = []  # 결과 저장용 리스트

    # 바깥 루프: 선행 테이블의 각 레코드를 순회
    for r_row in driving_table:
        # 안쪽 루프: 후행 테이블 전체를 순회하며 매칭 검색
        for s_row in driven_table:
            # 선행 테이블의 키 값과 후행 테이블의 키 값이 같으면 조인
            if r_row[key_d] == s_row[key_v]:
                merged = {**r_row, **s_row}  # 두 레코드를 합침
                result.append(merged)        # 결과에 추가

    return result

# 부서 테이블 - 선행 테이블 (Driving: 범위를 결정)
departments = [
    {"부서코드": "A", "부서명": "생산부"},
    {"부서코드": "B", "부서명": "영업부"},
]

# 직원 테이블 - 후행 테이블 (Driven: 검색 대상)
employees = [
    {"사번": 101, "이름": "홍길동", "부서코드": "A"},
    {"사번": 102, "이름": "김영수", "부서코드": "B"},
    {"사번": 103, "이름": "이수진", "부서코드": "A"},
    {"사번": 104, "이름": "박지은", "부서코드": "C"},
]

# 중첩 루프 조인 실행
joined = nested_loop_join(departments, employees, "부서코드", "부서코드")
for row in joined:
    print(row)
# 출력:
# {'부서코드': 'A', '부서명': '생산부', '사번': 101, '이름': '홍길동'}
# {'부서코드': 'A', '부서명': '생산부', '사번': 103, '이름': '이수진'}
# {'부서코드': 'B', '부서명': '영업부', '사번': 102, '이름': '김영수'}
```

```python
# ❌ 잘못된 예시 - 큰 테이블을 선행(Driving)으로 놓는 경우
# 직원이 10만 명이고 부서가 5개라면...
# 직원 테이블을 바깥 루프에 놓으면 바깥 루프가 10만 번 돕니다!
joined_bad = nested_loop_join(employees, departments, "부서코드", "부서코드")
# ❌ 비효율적! 작은 테이블을 선행으로 놓아야 합니다.
```

:::warning 중요한 성능 팁
중첩 루프 조인에서는 **작은 테이블을 선행(Driving) 테이블로** 놓아야 합니다. 바깥 루프의 횟수가 전체 성능을 결정하기 때문입니다. 또한 후행(Driven) 테이블에 **인덱스가 설정되어 있으면** 안쪽 루프에서 훨씬 빠르게 검색할 수 있어 성능이 크게 향상됩니다.
:::

**중첩 루프 조인의 특징:**

| 항목 | 설명 |
|------|------|
| **전제 조건** | 정렬 불필요, 후행 테이블에 인덱스가 있으면 유리 |
| **적합한 상황** | **부분 범위 처리**, 처리량이 적거나 특정 범위만 처리할 때 |
| **핵심 원리** | 선행 테이블의 범위가 처리량을 결정 |

### 방법 3: 해시 조인 (Hash Join) #️⃣

**해시 조인(Hash Join)**은 **해시 함수(Hash Function)**를 이용해서 양쪽 테이블의 조인 키에 대한 **주소를 계산**하고, 같은 주소를 가진 레코드끼리 매칭하는 방식입니다.

마치 택배 물류 센터에서 우편번호별로 택배를 분류하는 것과 같습니다. 왼쪽 테이블의 레코드를 해시 함수에 넣어 "바구니 번호"를 계산하고, 오른쪽 테이블의 레코드도 같은 해시 함수에 넣어 같은 바구니에 들어가는 것끼리 매칭합니다.

```python
# ✅ 해시 조인 - 올바른 예시
def hash_join(table_r, table_s, key_r, key_s):
    """
    해시 조인 구현
    - table_r: R 테이블
    - table_s: S 테이블
    - key_r: R의 조인 키
    - key_s: S의 조인 키
    """
    # 1단계: R 테이블로 해시 테이블(딕셔너리) 구축
    hash_table = {}  # 해시 테이블 생성 (파이썬 딕셔너리 사용)
    for row in table_r:
        key_value = row[key_r]          # 조인 키 값 추출
        if key_value not in hash_table:
            hash_table[key_value] = []  # 해당 키가 없으면 빈 리스트 생성
        hash_table[key_value].append(row)  # 해시 테이블에 레코드 추가

    # 2단계: S 테이블을 순회하며 해시 테이블에서 매칭 검색
    result = []
    for s_row in table_s:
        key_value = s_row[key_s]        # S의 조인 키 값 추출
        if key_value in hash_table:     # 해시 테이블에 해당 키가 있으면
            for r_row in hash_table[key_value]:  # 매칭되는 R 레코드와 조인
                merged = {**r_row, **s_row}
                result.append(merged)

    return result

# R 테이블 (학생)
students = [
    {"학번": 1, "이름": "이영희"},
    {"학번": 2, "이름": "박민수"},
    {"학번": 3, "이름": "김철수"},
]

# S 테이블 (성적)
scores = [
    {"학번": 2, "과목": "수학", "점수": 80},
    {"학번": 1, "과목": "영어", "점수": 95},
    {"학번": 3, "과목": "국어", "점수": 70},
]

# 해시 조인 실행
joined = hash_join(students, scores, "학번", "학번")
for row in joined:
    print(row)
```

**해시 조인의 특징:**

| 항목 | 설명 |
|------|------|
| **전제 조건** | 정렬 불필요, 인덱스 불필요 |
| **적합한 상황** | **동일 조인(Equi-Join, = 조건)**에서만 사용 가능 |
| **장점** | 정렬도, 인덱스도 필요 없어 빠름 |
| **단점** | 해시 함수로 주소를 계산해야 하므로 **CPU 비용**이 발생 |
| **활용** | 비용 기반 옵티마이저(Cost-Based Optimizer)에서 주로 사용 |

:::danger 해시 조인의 제약
해시 조인은 **반드시 동일 조인(=)에서만** 사용할 수 있습니다. "보다 크다(>)", "보다 작다(<)" 같은 범위 조건에서는 사용할 수 없습니다. 해시 함수는 하나의 입력에 하나의 주소만 계산하므로, **정확히 같은 값**만 매칭할 수 있기 때문입니다.
:::

### 3가지 조인 방법 종합 비교

| 조인 방법 | 정렬 필요 | 인덱스 필요 | 적합한 상황 | 비유 |
|-----------|-----------|-------------|-------------|------|
| **정렬 병합 조인** | ✅ 필요 | ❌ 불필요 | 전체 데이터, 대용량 처리 | 카드를 정렬 후 동시에 매칭 |
| **중첩 루프 조인** | ❌ 불필요 | ✅ 있으면 유리 | 부분 범위, 소량 처리 | 주문표 보고 창고에서 찾기 |
| **해시 조인** | ❌ 불필요 | ❌ 불필요 | 동일 조인(=), 비용 최적화 | 우편번호별 분류 후 매칭 |

---

## 💰 연산 비용과 카탈로그 정보

### 질의 처리에 들어가는 5가지 비용

데이터베이스에서 질의(Query)를 처리할 때는 다양한 비용이 발생합니다. 어떤 조인 방법이 가장 효율적인지 판단하려면 이 비용들을 계산해야 합니다.

**① 보조기억장치(I/O) 비용**

하드디스크에서 데이터를 읽고 쓰는 데 들어가는 비용입니다. 하드디스크는 메모리에 비해 매우 느리기 때문에, I/O 횟수가 많을수록 성능은 크게 떨어집니다. 마치 멀리 있는 창고에서 물건을 가져오는 것처럼, 왔다 갔다 하는 횟수가 많으면 시간이 오래 걸립니다.

**② 저장 비용**

R과 S를 조인하면 중간 결과가 발생합니다. 예를 들어, `R × S × T`를 계산한다면, 먼저 `R × S`의 중간 결과를 어딘가에 저장해두고, 그 결과에 다시 T를 조인해야 합니다. 이 **중간 결과를 저장하는 데 드는 비용**이 저장 비용입니다.

**③ 계산 비용 (CPU 비용)**

CPU에서 연산을 수행하는 데 들어가는 비용입니다. 해시 함수로 주소를 계산하거나, 값을 비교하거나, 정렬하는 등의 CPU 처리에 시간이 소요됩니다.

**④ 메모리 사용 비용**

질의를 수행하는 동안 데이터를 메모리에 올려놓고 CPU 코어에서 처리해야 하므로, 그에 필요한 메모리 공간의 비용입니다.

**⑤ 네트워크 통신 비용**

분산 데이터베이스(여러 서버에 데이터가 나누어 저장된 환경)의 경우, 서버 간에 네트워크를 통해 데이터를 주고받아야 하므로 추가적인 통신 비용이 발생합니다.

### 비용 계산에 필요한 카탈로그(Catalog) 정보

위의 비용을 계산하기 위해서는 **데이터 사전(카탈로그)**에 저장된 여러 정보가 필요합니다:

- **레코드 개수**: 전체 레코드가 몇 개인지 (10개와 100만 개는 성능에 엄청난 차이가 남)
- **블록 수**: 데이터를 저장하는 블록(I/O의 단위)의 개수
- **블로킹 팩터(BFR, Blocking Factor)**: 하나의 블록에 레코드를 몇 개 저장할 수 있는지 (블록 크기 ÷ 레코드 크기)
- **인덱스 단계 수**: 인덱스가 1단계인지, 2단계인지, 3단계인지
- **첫 번째 단계 인덱스의 블록 수**: 영어 사전에서 첫 글자(A, B, C...)를 얼마나 빠르게 찾느냐가 전체 검색 속도를 결정하듯이, 첫 번째 인덱스의 블록 수가 성능에 큰 영향을 미침
- **인덱스의 고유 값 수(Cardinality)**: 인덱스 값이 얼마나 서로 다른지. 중복이 많으면 인덱스 효과가 떨어짐
- **선택도(Selectivity)**: 하나의 조건으로 검색했을 때 평균 몇 개의 레코드가 나오는지

:::info 카탈로그(데이터 사전)란?
카탈로그는 데이터베이스에 대한 **메타데이터(데이터에 대한 데이터)**를 저장하는 곳입니다. 테이블 구조, 인덱스 정보, 통계 정보 등이 여기에 저장되어 있으며, DBMS의 옵티마이저가 최적의 실행 계획을 세울 때 이 정보를 참조합니다.
:::

---

## 🛠️ 튜닝의 단계별 방법

### 1단계: 하드웨어 튜닝 (가장 낮은 단계) 🔧

가장 직접적이고 단순한 방법입니다. 마치 컴퓨터가 느려졌을 때 **새 컴퓨터를 사는 것**과 같습니다.

- **디스크 성능이 떨어지면** → 디스크를 추가하거나 SSD로 교체
- **버퍼 메모리가 병목이면** → 메모리를 증설
- **CPU에 문제가 있으면** → CPU를 교체
- **인터넷 속도가 느리면** → 더 빠른 네트워크로 교체

#### 메모리 크기 결정의 법칙

메모리 크기를 얼마로 설정할지 결정할 때 참고하는 규칙이 있습니다:

- **5분 규칙(5-Minute Rule)**: 메모리에 올린 데이터가 **5분 이내에 다시 사용될 가능성**이 있다면, 메모리에 유지해두는 것이 효율적입니다. 자주 쓰는 데이터를 메모리에서 빼버리면 다시 디스크에서 읽어와야 하므로 느려집니다.
- **1분 규칙(1-Minute Rule)**: **1분마다 계속 사용되는 데이터**라면 당연히 메모리에 유지해야 합니다.

이런 규칙에 맞춰 메모리 크기를 충분히 설정해야 합니다.

### 2단계: 인스턴스 파라미터 조정 ⚙️

데이터베이스의 다양한 **설정값(파라미터)**을 조정하는 방법입니다.

#### 체크포인트 간격의 예시

여러분이 한글(HWP)이나 워드프로세서에서 문서를 작성할 때, **자동 저장 기능**을 사용하시죠? 이 자동 저장 간격이 바로 데이터베이스의 **체크포인트(Checkpoint)**와 같은 개념입니다.

실제 사례를 들어보겠습니다:

```
❌ 자동 저장 간격: 1분 → 1분마다 저장하려고 프로그램이 멈춤 → 작업 방해
✅ 자동 저장 간격: 30분 → 30분에 한 번만 저장 → 작업 흐름이 끊기지 않음
```

한 분이 한글에서 자동 저장 간격이 **1분**으로 설정되어 있어서, 무언가 입력하려고 하면 갑자기 한글이 멈춰버리는 문제를 겪었습니다. 확인해보니 1분마다 자동 저장이 실행되고 있었던 것입니다. 이를 **30분**으로 늘려놓으니 문제가 해결되었습니다.

데이터베이스의 체크포인트도 마찬가지입니다. 너무 자주 실행하면 성능이 떨어지고, 너무 드물게 실행하면 장애 시 데이터 손실 위험이 커집니다. **적절한 균형**을 찾는 것이 중요합니다.

이 밖에도 **버퍼 크기**, **블로킹 팩터**, **데이터베이스 세션 수** 등의 파라미터를 조정하여 성능을 향상시킬 수 있습니다.

### 3단계: 구조적 튜닝 (가장 윗 단계) 📐

가장 효과적이면서도 전문적인 단계입니다. 데이터베이스의 **구조 자체**를 최적화하는 방법입니다.

- **정규화 / 역정규화**: 테이블 구조를 정규화하거나, 성능을 위해 의도적으로 역정규화(비정규화)
- **인덱스 추가 / 제거**: 검색 성능이 필요하면 인덱스 추가, 갱신 성능이 필요하면 인덱스 제거
- **실체화된 뷰(Materialized View)** 활용
- **트랜잭션 방법 변경**

:::warning 인덱스의 양면성
인덱스는 **검색 성능은 향상**시키지만, **갱신(INSERT, UPDATE, DELETE) 성능은 떨어뜨립니다.** 인덱스를 많이 설정해 놓은 테이블에서 갱신 작업이 주로 이루어진다면, 오히려 인덱스를 제거하는 것이 더 효율적일 수 있습니다.

| 작업 유형 | 인덱스 효과 |
|-----------|-------------|
| **검색(SELECT)** 위주 | ✅ 인덱스 추가 → 성능 향상 |
| **갱신(INSERT/UPDATE/DELETE)** 위주 | ❌ 인덱스 제거 → 성능 향상 |
:::

---

## ⚡ SQL 성능 최적화 팁

### 불필요한 정렬을 피하라

정렬은 비용이 많이 드는 연산입니다. 100만 개의 데이터를 정렬한다고 생각해보세요. 그 자체만으로도 엄청난 연산이 필요합니다. 따라서 **꼭 필요한 경우에만** 정렬을 수행해야 합니다.

```sql
-- ❌ 불필요한 정렬 + 중복 제거 (UNION은 자동으로 정렬 + 중복 제거)
SELECT 이름 FROM 학생 WHERE 학년 = 1
UNION
SELECT 이름 FROM 학생 WHERE 학년 = 2;
-- UNION은 두 결과를 합친 후 정렬하고 중복을 제거합니다.
-- 이 과정에서 불필요한 비용이 발생할 수 있습니다.

-- ✅ 중복 제거가 필요 없다면 UNION ALL 사용 (정렬/중복 제거 안 함)
SELECT 이름 FROM 학생 WHERE 학년 = 1
UNION ALL
SELECT 이름 FROM 학생 WHERE 학년 = 2;
-- UNION ALL은 정렬도, 중복 제거도 하지 않아 훨씬 빠릅니다.
```

### DISTINCT 대신 EXISTS 고려하기

```sql
-- ❌ DISTINCT: 결과에서 중복을 제거하기 위해 전체를 정렬해야 함
SELECT DISTINCT 부서명 
FROM 부서 
JOIN 직원 ON 부서.부서코드 = 직원.부서코드;
-- DISTINCT는 결과 전체를 정렬한 후 중복을 제거하므로 비용이 큼

-- ✅ 중복 제거가 필요 없는 경우 DISTINCT를 빼기
SELECT 부서명, 직원명 
FROM 부서 
JOIN 직원 ON 부서.부서코드 = 직원.부서코드;
-- 꼭 필요하지 않다면 DISTINCT 없이 사용하는 것이 빠릅니다.
```

### 존재 여부만 확인할 때는 COUNT를 피하라

```sql
-- ❌ 전체 건수를 세는 비효율적인 방법
SELECT COUNT(*) 
FROM 주문 
WHERE 고객번호 = 100;
-- 레코드가 존재하는지만 확인하면 되는데, 전체 건수를 세고 있음

-- ✅ 존재 여부만 확인하면 되는 경우 EXISTS 사용
SELECT CASE WHEN EXISTS (
    SELECT 1 FROM 주문 WHERE 고객번호 = 100
) THEN '존재' ELSE '없음' END;
-- EXISTS는 조건에 맞는 첫 번째 레코드를 찾으면 즉시 멈추므로 빠릅니다.
```

### SORT AGGREGATE 대신 HASH AGGREGATE 사용

**SORT AGGREGATE**는 데이터를 물리적으로 정렬한 후 그룹핑하는 방식이고, **HASH AGGREGATE**는 정렬 없이 해시 함수를 이용해 그룹핑하는 방식입니다. 정렬이 필요 없는 경우 HASH AGGREGATE가 더 효율적입니다.

> 📌 핵심 원칙: **정렬할 필요 없는 것은 정렬하지 말고, 중복 제거할 필요 없는 것은 중복 제거하지 마라.** 이것만으로도 상당한 성능 향상을 얻을 수 있습니다.

### 미니 배치 트랜잭션 활용

전체 데이터를 한꺼번에 처리하는 것보다, **작은 단위로 쪼개서(미니 배치)** 처리하는 것이 더 효율적입니다.

예를 들어, 1시간 분량의 데이터를 한꺼번에 저장하는 것이 아니라, **10분 단위로 쪼개서** 나눠 저장하면 파일 사이즈가 줄어들고 부하도 분산되어 훨씬 효율적으로 처리할 수 있습니다.

---

## 📈 성능 평가 기준: TPC

### TPC란 무엇인가?

**TPC(Transaction Processing Performance Council)**는 데이터베이스 시스템의 성능을 평가하기 위한 **국제 표준 벤치마크**입니다.

성능 측정의 기본 기준은 **처리율(Throughput)** — 즉, **1초에 몇 건의 트랜잭션(Transaction)을 처리하느냐**입니다.

- 1초에 10건 처리 → 처리율 10 TPS(Transactions Per Second)
- 1초에 100건 처리 → 처리율 100 TPS

비즈니스 관점에서는 단순 처리율보다 **Price per TPS(단위 트랜잭션당 비용)**가 더 와닿습니다. 즉, "1건 처리하는 데 비용이 얼마 드느냐"로 평가합니다.

### TPC의 종류

| 종류 | 용도 | 설명 |
|------|------|------|
| **TPC-A** | 단순 입출금 | 은행 ATM 같은 단순 거래 시스템 평가 |
| **TPC-B** | 운영체제 | OS 레벨의 성능 평가 |
| **TPC-C** | 주문 처리 | 전자상거래, 항공권 예약, 주문 처리 시스템 (가장 보편적) |
| **TPC-D** | 의사결정 | 의사결정 지원 시스템(DSS) 성능 평가 |
| **TPC-H** | 대용량 분석 | 예측 불가능한 다양한 질의를 처리하는 시스템 |
| **TPC-R** | 보고서 | 요약, 통계 보고서 기능 평가 |
| **TPC-W** | 웹/인터넷 | 웹 기반 전자상거래 시스템 평가 |

:::note 객체지향 데이터베이스의 벤치마크
객체지향(Object-Oriented) 데이터베이스는 기존 관계형 DB와 트랜잭션 처리 개념이 다르기 때문에, **별도의 벤치마크 표준**(OO1, OO7 등)이 존재합니다.
:::

---

## 🏆 데이터 품질 관리

### 성능만으로는 부족하다

아무리 성능이 뛰어난 시스템이라도, **품질**이 나쁘면 쓸 수 없습니다. 마치 시속 500km로 달릴 수 있는 슈퍼카가 있는데, 가끔씩 엔진이 폭발한다면 아무도 타지 않을 것입니다.

> 성능이 일정 수준을 만족하면서 + 품질도 일정 수준 이상이어야 = **좋은 시스템**

**데이터 품질(Data Quality)**이란, 데이터 이용자를 만족시킬 수 있는 수준을 말하며, 그 수준을 유지하고 관리하는 모든 활동을 **데이터 품질 관리**라고 합니다. 이것은 특정 사람만 하는 것이 아니라, 전 부서에서 전체 생명주기에 걸쳐 관리해야 합니다.

### 품질 진단의 3가지 관점

**① 값(Value) 진단**

테이블, 속성, 코드, 관계, 비즈니스 규칙 등을 기준으로 **데이터 값**을 분석합니다. 값이 정확한지, 오류가 없는지, 잘못된 값이 들어가 있지 않은지 등을 평가합니다.

마치 요리사가 음식의 간을 보는 것처럼, 데이터의 값이 올바른지 수시로 점검해야 합니다.

**② 구조(Structure) 진단**

시스템의 모델링과 스키마 구조가 제대로 설계되어 있는지 확인합니다. 마치 건물의 설계도가 올바른지 검토하는 것과 같습니다.

이 진단은 주로 **설계 관점**에서 품질을 진단할 때 사용하며, **리버스 모델링(Reverse Modeling)** 기법을 활용합니다. 리버스 모델링이란, 완성된 시스템을 분해해서 거꾸로 설계도를 만들어내는 것입니다. 마치 초창기 우리나라가 외국 자동차를 수입해와서 분해하고, 거꾸로 설계도를 만들어낸 **리버스 엔지니어링**과 같은 개념입니다.

**③ 관리 프로세스 진단**

값과 구조의 품질이 체계적인 프로세스에 따라 잘 관리되고 있는지 확인합니다. 전체 품질 관리의 주기가 정해진 규칙대로 잘 운영되고 있는지를 점검하는 것입니다.

---

## 📌 핵심 정리

- **데이터베이스 튜닝**이란 DB 성능 향상을 위해 하드웨어, 파라미터, 구조 등을 조정하는 모든 행위를 말한다
- **Join 연산**은 여러 테이블을 읽고 비교해야 하므로 성능 저하의 주요 원인이 된다
- **Selection 연산의 4가지 탐색 방법**: 선형 탐색(순차), 이진 탐색(정렬 후 절반씩), 인덱스 탐색(목차 활용), 해싱(주소 계산)
- **정렬 병합 조인**: 양쪽 정렬 후 동시 비교, 대용량 전체 처리에 적합
- **중첩 루프 조인**: 선행 테이블 범위 결정 후 후행 테이블 루프, 부분 범위 처리에 적합하며 후행 테이블에 인덱스가 있으면 유리
- **해시 조인**: 해시 함수로 주소 계산 후 매칭, 동일 조인(=)에서만 사용 가능
- **질의 처리 비용** 5가지: I/O 비용, 저장 비용, 계산(CPU) 비용, 메모리 비용, 네트워크 비용
- **튜닝 3단계**: 하드웨어 교체(최하위) → 인스턴스 파라미터 조정(중간) → 정규화/인덱스/뷰 등 구조적 튜닝(최상위)
- **인덱스는 양면성**이 있다: 검색 성능 ↑ / 갱신 성능 ↓
- 불필요한 **정렬(SORT)과 중복 제거(DISTINCT)**를 피하면 성능이 향상된다
- **UNION ALL**은 UNION보다 빠르다 (정렬과 중복 제거를 하지 않으므로)
- **TPC**는 데이터베이스 성능 평가의 국제 표준 벤치마크이며, TPS(초당 트랜잭션 수)로 측정한다
- **데이터 품질 관리**는 성능 못지않게 중요하며, 값 진단 / 구조 진단 / 프로세스 진단으로 나뉜다

---

작성일: 2026-02-21