---
title: "로그 레코드 버퍼링: 메모리에 로그를 모아두는 이유"
description: "로그 레코드 버퍼링: 메모리에 로그를 모아두는 이유에 대해 초보자도 쉽게 이해할 수 있도록 설명합니다."
slug: "/advanced-recovery-techniques/4-log-record-buffering"
sidebar_label: "로그 버퍼링"
date: "2026-02-21"
---

## 🎯 이 문서에서 배울 내용

데이터베이스를 운영하다 보면 언제든 **예상치 못한 장애**가 발생할 수 있습니다. 정전, 하드웨어 고장, 소프트웨어 버그 등 다양한 원인으로 데이터가 손상될 수 있죠. 이때 데이터를 원래대로 되돌리는 작업을 **회복(Recovery)**이라고 합니다.

이전에 우리는 **덤프(백업)**와 **로그 파일**을 이용해 회복하는 기본 개념, 그리고 **지연 갱신 기법**과 **즉시 갱신 기법**을 배웠습니다. 이번 문서에서는 그 다음 단계로, 로그를 **효율적으로 관리하는 고급 기법**들을 다룹니다.

이 문서에서 다루는 핵심 주제는 다음과 같습니다:

- **로그 레코드 버퍼링** — 로그를 매번 저장하지 않고 메모리에 모아두는 이유
- **로그 우선 기록 규약(WAL)** — 데이터보다 로그를 먼저 저장해야 하는 이유
- **체크포인트(Checkpoint)** — 불필요한 복구 작업을 줄이는 기법
- **그림자 페이징(Shadow Paging)** — 로그 없이 복구하는 기법
- **ARIES** — 복구 중 장애가 또 발생해도 대처하는 기법
- **백업 센터 운영** — 미러 사이트, 핫 사이트, 웜 사이트, 콜드 사이트

> 마치 자동차 정비사가 엔진 오일 교체부터 사고 복구까지 다양한 기술을 알아야 하듯이, 데이터베이스 관리자도 여러 회복 기법을 상황에 맞게 선택할 줄 알아야 합니다.

---

## 📝 로그 레코드 버퍼링이란?

### 왜 로그를 매번 저장하면 안 될까?

먼저 기본 상황을 떠올려 봅시다. 트랜잭션(작업 묶음)이 실행되면, 각 작업마다 **로그 레코드(작업 기록)**가 하나씩 생성됩니다.

예를 들어, 어떤 값 `X`를 100에서 200으로 변경하면 로그가 한 줄 만들어지고, 다시 `Y`를 200에서 300으로 변경하면 또 한 줄 만들어집니다. 만약 처리해야 할 데이터가 **1만 건**이라면, 로그 레코드도 **1만 줄**이 생기는 것이죠.

그렇다면 이 로그를 **하나 생길 때마다 바로 하드디스크에 저장**하면 어떻게 될까요?

```
작업 1 처리 → 로그 저장 → 작업 2 처리 → 로그 저장 → ... → 작업 10,000 처리 → 로그 저장
```

이렇게 하면 하드디스크에 **1만 번 저장(Output) 연산**을 해야 합니다. 하드디스크 입출력(I/O)은 컴퓨터에서 **가장 느린 작업** 중 하나입니다. 매번 저장할 때마다 디스크가 회전하고, 헤드가 이동하고, 데이터를 기록해야 하기 때문이죠.

:::info 실생활 비유로 이해하기
엑셀에서 숫자 1만 개를 하나씩 더하는 작업을 한다고 상상해 보세요. **하나 더할 때마다 Ctrl+S를 눌러 저장**한다면 얼마나 답답할까요? 실제로는 1만 개를 **다 처리한 후 마지막에 한 번만 저장**하죠. 그 동안 데이터는 **메모리(RAM)에 임시로 보관**됩니다. 이것이 바로 버퍼링의 핵심 개념입니다.
:::

### 로그 레코드 버퍼링의 동작 원리

**로그 레코드 버퍼링(Log Record Buffering)**이란, 로그 레코드를 생성할 때마다 바로 하드디스크에 저장하지 않고, **메모리(로그 버퍼)에 모아두었다가 한꺼번에 저장**하는 기법입니다.

컴퓨터의 데이터 처리 흐름을 먼저 정리해 봅시다:

| 연산 | 방향 | 설명 |
|------|------|------|
| **Input** | 하드디스크 → 메모리 | 디스크에서 메모리로 데이터를 읽어옴 |
| **Read** | 메모리 → CPU | 메모리의 데이터를 CPU가 읽음 |
| **Write** | CPU → 메모리 | CPU가 처리한 결과를 메모리에 기록 |
| **Output** | 메모리 → 하드디스크 | 메모리의 데이터를 디스크에 최종 저장 |

이 흐름에서 **Output(아웃풋)**이 바로 하드디스크에 실제로 기록하는 연산입니다. 이 Output 연산이 **I/O 작업**이고, 이것이 반복될수록 시스템 성능이 크게 떨어집니다.

> **핵심**: 로그 레코드 버퍼링은 Output 횟수를 줄여서 **데이터베이스 성능을 향상**시키는 기법입니다. 로그를 메모리에 모아놓고, 커밋(Commit) 시점이나 특정 시점에 한꺼번에 디스크로 내보냅니다.

### 원래 방식 vs 버퍼링 방식 비교

❌ **버퍼링 없이 매번 저장하는 방식:**

```
Input → Read → Write → Output (로그 1줄 저장)
Input → Read → Write → Output (로그 2줄 저장)
Input → Read → Write → Output (로그 3줄 저장)
...
(1만 번 반복 → Output이 1만 번 발생!)
```

✅ **버퍼링을 사용하는 방식:**

```
Input → Read → Write (메모리에 로그 보관)
Input → Read → Write (메모리에 로그 보관)
Input → Read → Write (메모리에 로그 보관)
...
커밋 시점 → Output 한 번에 모든 로그 저장!
```

이렇게 하면 Output 연산 횟수가 **1만 번에서 1번(또는 소수 횟수)**으로 극적으로 줄어듭니다.

### 버퍼링의 위험성

하지만 버퍼링에는 중요한 **위험**이 존재합니다. 메모리는 **휘발성 저장장치**이기 때문에, 전원이 꺼지거나 시스템이 붕괴(Crash)되면 메모리에 있던 데이터는 **모두 사라집니다**.

로그 레코드가 메모리에만 있고 아직 하드디스크에 저장되지 않은 상태에서 시스템이 다운되면, **로그 레코드가 통째로 손실**됩니다. 로그가 없으면 복구 자체가 불가능해지죠.

:::warning 메모리의 휘발성 주의
메모리(RAM)는 전원이 꺼지면 저장된 데이터가 모두 사라지는 **휘발성 저장장치**입니다. 마치 칠판에 분필로 적은 내용이 지우개로 한 번에 지워지는 것과 같습니다. 반면 하드디스크는 전원이 꺼져도 데이터가 유지되는 **비휘발성 저장장치**입니다.
:::

이 위험성을 해결하기 위한 규칙이 바로 다음에 설명할 **로그 우선 기록 규약(WAL)**입니다.

---

## 🔒 로그 우선 기록 규약 (Write-Ahead Logging, WAL)

### 무엇을 먼저 저장해야 할까?

로그 레코드 버퍼링 때문에 메모리에는 두 종류의 데이터가 함께 머물고 있습니다:

1. **일반 데이터** — 실제 트랜잭션이 처리한 결과 데이터
2. **로그 데이터** — 트랜잭션의 작업 기록

하드디스크는 하나이기 때문에, 이 두 데이터를 **동시에 저장할 수 없습니다**. 반드시 순서를 정해야 합니다. 그렇다면 어떤 것을 먼저 저장해야 할까요?

### 시나리오 분석: 왜 로그를 먼저 저장해야 하는가

두 가지 시나리오를 비교해 봅시다.

**시나리오 1: 일반 데이터를 먼저 저장 ❌**

```
1단계: 일반 데이터 저장 ✅ (성공)
2단계: 로그 데이터 저장 ❌ (이 시점에서 에러 발생!)

결과: 데이터는 저장됐지만, 로그가 없음!
→ 나중에 문제가 생겨도 로그가 없어서 복구 불가능! 💀
```

이 상황은 치명적입니다. 데이터가 잘못된 상태로 저장되었을 수 있는데, 복구에 필요한 로그가 없기 때문에 **되돌릴 방법이 전혀 없습니다**.

**시나리오 2: 로그 데이터를 먼저 저장 ✅**

```
케이스 A:
1단계: 로그 데이터 저장 ❌ (이 시점에서 에러 발생!)

결과: 로그도 없고 데이터도 저장 안 됨
→ 아무 작업도 안 한 것과 같음. 복구할 필요 없음! ✅
```

```
케이스 B:
1단계: 로그 데이터 저장 ✅ (성공)
2단계: 일반 데이터 저장 ❌ (이 시점에서 에러 발생!)

결과: 로그는 있지만 데이터가 저장 안 됨
→ 로그가 있으니 덤프(백업)에서 복원 후 로그로 복구 가능! ✅
```

:::tip 핵심 포인트
어떤 경우든 **로그를 먼저 저장하면 안전**합니다. 로그 저장이 실패하면 아무 일도 일어나지 않은 것과 같고, 로그 저장이 성공하면 데이터가 손실되어도 로그를 이용해 복구할 수 있습니다.
:::

### WAL의 정의와 원칙

이 원칙을 **로그 우선 기록 규약**, 영어로는 **Write-Ahead Logging(WAL)**이라고 합니다. 줄여서 **WAL**이라고도 부릅니다.

> **WAL 원칙**: 일반 데이터 버퍼 블록을 하드디스크로 저장(Output)하기 **전에**, 반드시 해당 데이터와 관련된 **로그 레코드를 먼저** 안전한 저장장치(하드디스크)에 저장해야 한다.

한 마디로 정리하면:

| 순서 | 저장 대상 | 설명 |
|------|-----------|------|
| **1번** (먼저) | 로그 레코드 | 복구를 위한 작업 기록을 먼저 안전하게 저장 |
| **2번** (나중) | 일반 데이터 | 실제 처리 결과 데이터를 저장 |

마치 **일기장을 먼저 쓰고 나서 실제 행동을 하는 것**과 비슷합니다. "오늘 방 청소를 할 거야"라고 일기장에 먼저 적어두면, 나중에 청소를 하다 말았더라도 일기장을 보고 "아, 청소를 마저 해야겠구나"라고 알 수 있죠. 하지만 일기장 없이 청소를 시작했다가 중간에 멈추면, 어디까지 했는지 기억할 방법이 없습니다.

```sql
-- WAL 원칙을 코드로 표현하면 이런 순서입니다 (개념적 의사코드)

-- ✅ 올바른 순서: 로그 먼저, 데이터 나중
BEGIN TRANSACTION;

UPDATE account SET balance = 200 WHERE id = 1;  -- 메모리에서 데이터 변경
-- 로그 기록: "account.id=1의 balance를 100에서 200으로 변경"

-- 1단계: 로그를 하드디스크에 먼저 저장 (FLUSH LOG)
-- 2단계: 데이터를 하드디스크에 저장 (OUTPUT)

COMMIT;
```

```sql
-- ❌ 잘못된 순서: 데이터 먼저, 로그 나중
BEGIN TRANSACTION;

UPDATE account SET balance = 200 WHERE id = 1;

-- 1단계: 데이터를 하드디스크에 먼저 저장 (OUTPUT)
-- ⚡ 여기서 시스템 장애 발생!
-- 2단계: 로그 저장 시도 → 실패!
-- 결과: 데이터는 변경됐지만 로그가 없어서 복구 불가능!
```

:::danger 절대 하면 안 되는 것
일반 데이터를 로그보다 먼저 하드디스크에 저장하면 안 됩니다. 데이터는 저장됐는데 로그가 없으면, 나중에 문제가 발생했을 때 **복구 자체가 불가능**해집니다. 이는 데이터베이스의 **원자성(Atomicity)**을 보장할 수 없게 만듭니다.
:::

---

## ✅ 체크포인트 (Checkpoint)

### 왜 체크포인트가 필요한가?

로그를 이용한 회복에는 큰 문제가 하나 있습니다. 로그 파일의 크기가 **어마어마하게 커질 수 있다**는 것입니다.

예를 들어, 100만 개의 레코드를 처리했다면 로그 파일에는 **최소 100만 줄**이 생깁니다. 장애가 발생해서 복구를 해야 할 때, 이 100만 줄짜리 로그 파일을 **처음부터 끝까지 전부 읽어야** 합니다.

그런데 여기서 불합리한 상황이 발생합니다. 이미 **안전하게 하드디스크에 저장이 완료된 트랜잭션**도 있을 텐데, 이런 트랜잭션까지 다시 Redo(재실행)를 해야 할까요? 이미 저장된 데이터를 또 다시 복구하는 것은 **시간 낭비**입니다.

:::info 실생활 비유
게임을 하다가 중간중간 **세이브 포인트**를 만들어 둔다고 생각해 보세요. 게임 캐릭터가 죽으면 처음부터 다시 시작하는 것이 아니라, **가장 최근 세이브 포인트부터 다시 시작**합니다. 체크포인트는 데이터베이스의 "세이브 포인트"와 같은 개념입니다.
:::

**체크포인트(Checkpoint)**는 일정한 시간 간격으로 자동으로 설정되어, 그 시점까지의 데이터를 하드디스크에 저장해 두는 기법입니다. 복구 시 체크포인트 **이전에 이미 완료된 트랜잭션은 다시 Redo할 필요가 없으므로**, 복구 시간을 대폭 줄일 수 있습니다.

### 체크포인트의 동작 순서

체크포인트 시점이 되면, 다음 세 단계가 **이 순서대로** 수행됩니다:

| 순서 | 작업 | 설명 |
|------|------|------|
| **1단계** | 로그 레코드 저장 | 메모리의 로그 버퍼를 하드디스크에 먼저 저장 (WAL 원칙) |
| **2단계** | 데이터 버퍼 저장 | 메모리의 데이터 버퍼를 하드디스크에 저장 |
| **3단계** | 체크포인트 정보 저장 | 체크포인트에 대한 로그 레코드를 하드디스크에 저장 |

이 순서가 중요합니다. **1단계에서 WAL 원칙에 따라 로그를 먼저 저장**하고, 그 다음 데이터를, 마지막으로 체크포인트 정보를 저장합니다.

:::warning 체크포인트 간격 설정 주의
체크포인트 작업이 수행되는 동안에는 **다른 트랜잭션 작업이 중단**됩니다. 마치 아래한글에서 자동 저장이 되는 동안 잠시 입력이 멈추는 것과 같습니다. 따라서 간격이 **너무 짧으면** 작업이 자주 중단되어 성능이 떨어지고, **너무 길면** 장애 발생 시 복구해야 할 범위가 넓어집니다. 적절한 간격을 설정하는 것이 중요합니다.
:::

### 체크포인트 복구 알고리즘

체크포인트를 이용한 복구는 다음 순서로 진행됩니다:

1. **빈 Undo 리스트와 Redo 리스트를 생성**합니다.
2. **체크포인트 설정 당시 활동 중인 트랜잭션**을 모두 Undo 리스트에 넣습니다.
3. **체크포인트 이후에 새로 시작(Start)된 트랜잭션**도 모두 Undo 리스트에 넣습니다.
4. 로그를 검사하면서 **Commit(커밋)을 만난 트랜잭션**은 Undo 리스트에서 빼서 **Redo 리스트로 이동**합니다.
5. 회복 시: Undo 리스트의 트랜잭션은 **역방향으로 Undo 연산**을, Redo 리스트의 트랜잭션은 **순방향으로 Redo 연산**을 수행합니다.

### 구체적인 예시로 이해하기

다음과 같은 상황을 가정해 봅시다. 5개의 트랜잭션이 있고, 중간에 체크포인트가 설정되었으며, 이후에 에러가 발생했습니다.

```
시간 ─────────────────────────────────────────────────────────▶

T1: |----Start----Commit----|
T2:       |----Start-----------|---------Commit--|
T3:             |----Start------|-------------------------| (Commit 없음)
T4:                              |----Start----Commit----|
T5:                                   |----Start---------| (Commit 없음)

                              ▲                          ▲
                          체크포인트                    에러 발생
```

- **T1**: 체크포인트 이전에 이미 Commit 완료
- **T2**: 체크포인트 당시 활동 중, 이후에 Commit
- **T3**: 체크포인트 당시 활동 중, Commit 없음
- **T4**: 체크포인트 이후 시작, Commit 있음
- **T5**: 체크포인트 이후 시작, Commit 없음

알고리즘을 단계별로 적용해 봅시다:

**1단계: 빈 리스트 생성**

```
Undo 리스트: [ ]
Redo 리스트: [ ]
```

**2단계: 체크포인트 당시 활동 중인 트랜잭션 → Undo에 추가**

체크포인트 시점에서 아직 끝나지 않고 실행 중인 트랜잭션은 T2와 T3입니다.

```
Undo 리스트: [T2, T3]
Redo 리스트: [ ]
```

**3단계: 체크포인트 이후 시작된 트랜잭션 → Undo에 추가**

체크포인트 이후에 새로 시작된 트랜잭션은 T4와 T5입니다.

```
Undo 리스트: [T2, T3, T4, T5]
Redo 리스트: [ ]
```

**4단계: Commit을 만난 트랜잭션 → Undo에서 Redo로 이동**

로그를 검사하면서 Commit이 있는 T2와 T4를 발견합니다.

```
Undo 리스트: [T3, T5]       ← Commit이 없는 트랜잭션
Redo 리스트: [T2, T4]       ← Commit이 있는 트랜잭션
```

**그런데 T1은 어디에 있나요?** T1은 체크포인트 **이전에 이미 Commit이 완료**되었기 때문에, Undo에도 Redo에도 들어가지 않습니다. **아무 작업도 수행하지 않습니다.**

> 🔑 **체크포인트의 핵심 가치**: 체크포인트 이전에 커밋된 트랜잭션(T1)은 이미 안전하게 저장되었으므로 **Redo도 Undo도 하지 않습니다**. 만약 체크포인트가 없었다면 T1도 Redo 대상이 되어 불필요한 복구 작업을 해야 했을 것입니다.

**5단계: 복구 수행**

| 트랜잭션 | 작업 | 범위 | 설명 |
|----------|------|------|------|
| T1 | **아무것도 안 함** | - | 체크포인트 이전에 이미 Commit 완료 |
| T2 | **Redo** | 체크포인트 이후 부분만 | 이미 체크포인트에서 저장된 부분은 건너뜀 |
| T3 | **Undo** | 전체 | Commit이 없으므로 전체 취소 |
| T4 | **Redo** | 전체 | 체크포인트 이후에 시작되어 전체가 Redo 대상 |
| T5 | **Undo** | 전체 | Commit이 없으므로 전체 취소 |

```python
# 체크포인트 복구 알고리즘 의사코드

# 1단계: 빈 리스트 생성
undo_list = []  # 취소해야 할 트랜잭션 리스트
redo_list = []  # 재실행해야 할 트랜잭션 리스트

# 2단계: 체크포인트 당시 활동 중인 트랜잭션을 undo에 추가
for txn in active_at_checkpoint:  # 체크포인트 시점에 실행 중이던 트랜잭션
    undo_list.append(txn)         # 일단 모두 undo 리스트에 넣음

# 3단계: 체크포인트 이후 시작된 트랜잭션도 undo에 추가
for txn in started_after_checkpoint:  # 체크포인트 이후에 시작된 트랜잭션
    undo_list.append(txn)              # 이것도 undo 리스트에 넣음

# 4단계: 로그를 검색하며 커밋된 트랜잭션을 redo로 이동
for log_record in log_file:           # 로그 파일을 순차적으로 읽음
    if log_record.type == "COMMIT":   # 커밋 레코드를 발견하면
        txn = log_record.transaction
        undo_list.remove(txn)         # undo 리스트에서 제거
        redo_list.append(txn)         # redo 리스트에 추가

# 5단계: 복구 수행
for txn in undo_list:                 # undo 리스트의 트랜잭션은
    perform_undo(txn)                 # 역방향으로 undo 연산 수행 (전체 취소)

for txn in redo_list:                 # redo 리스트의 트랜잭션은
    perform_redo(txn)                 # 순방향으로 redo 연산 수행 (재실행)

# ※ 체크포인트 이전에 이미 커밋된 트랜잭션은 아예 처리 대상에 포함되지 않음!
```

### 아래한글의 자동 저장과 체크포인트

체크포인트는 우리가 일상에서 이미 사용하고 있는 개념이기도 합니다. 아래한글이나 MS Word의 **자동 저장 기능**이 바로 체크포인트와 동일한 원리입니다.

- 자동 저장 간격을 **1분**으로 설정하면: 너무 자주 저장해서 문서 작업 중 **멈추는 현상**이 자주 발생 → 성능 저하
- 자동 저장 간격을 **60분**으로 설정하면: 저장 빈도는 낮지만, 장애 발생 시 **최대 60분치 작업을 잃을 수 있음**

적절한 간격(예: 10~20분)을 설정하는 것이 중요하며, 데이터베이스에서도 시스템의 특성과 데이터의 중요도에 따라 **최적의 체크포인트 간격**을 설정합니다.

---

## 👻 그림자 페이징 (Shadow Paging)

### 로그 없이 복구하는 방법

지금까지 살펴본 기법들은 모두 **로그 파일**을 이용한 복구 방법이었습니다. 하지만 **그림자 페이징(Shadow Paging)**은 로그를 전혀 사용하지 않는 기법입니다.

로그를 사용하지 않기 때문에 Undo도 하지 않고 Redo도 하지 않습니다. 그래서 이 기법을 **No-Undo / No-Redo 기법**이라고 부릅니다.

### 두 개의 페이지: 현재 페이지와 그림자 페이지

그림자 페이징에서는 **페이지 테이블(Page Table)**을 **두 개** 유지합니다:

| 페이지 종류 | 저장 위치 | 역할 |
|-------------|-----------|------|
| **현재 페이지 (Current Page)** | 메모리(RAM) | 실제 작업이 이루어지는 페이지. 데이터가 변경됨 |
| **그림자 페이지 (Shadow Page)** | 하드디스크 | 작업 전 원본을 보관하는 페이지. 변경되지 않음 |

:::info 실생활 비유
시험지를 풀 때, 원본 시험지를 **복사본**으로 하나 더 만들어 놓는다고 상상해 보세요. 복사본에 풀이를 하다가 잘못 풀었으면 원본을 다시 복사하면 됩니다. 잘 풀었으면 원본도 복사본과 동일하게 업데이트합니다. 여기서 복사본이 "현재 페이지", 원본이 "그림자 페이지"입니다.
:::

### 동작 원리

**1. 트랜잭션 시작 시:**

트랜잭션이 시작되면 현재 페이지와 동일한 **그림자 페이지를 생성**합니다.

```
데이터: 100
현재 페이지 (메모리): 100
그림자 페이지 (디스크): 100    ← 복사본 생성
```

**2. 작업 수행 중:**

갱신 작업은 **현재 페이지에서만** 수행됩니다. 그림자 페이지는 절대 변경하지 않습니다.

```
데이터: 100 → 200 (변경 중)
현재 페이지 (메모리): 200     ← 변경됨
그림자 페이지 (디스크): 100   ← 원본 그대로 유지
```

**3-A. 장애 발생 시 (실패):**

장애가 발생하면 현재 페이지를 버리고, **그림자 페이지의 내용을 가져와 덮어씁니다**.

```
⚡ 장애 발생!
현재 페이지: 버림 (200은 잘못된 상태일 수 있음)
그림자 페이지: 100 → 현재 페이지로 복사

결과: 데이터가 원래 값 100으로 복구됨 ✅
```

**3-B. 트랜잭션 성공 시:**

트랜잭션이 성공적으로 완료되면, **그림자 페이지도 현재 페이지와 동일하게 업데이트**합니다.

```
✅ 트랜잭션 성공!
현재 페이지: 200
그림자 페이지: 100 → 200으로 업데이트

결과: 두 페이지 모두 200으로 동기화 ✅
```

```python
# 그림자 페이징 동작 원리 의사코드

# 트랜잭션 시작: 그림자 페이지 생성
shadow_page = copy(current_page)  # 현재 페이지를 복사하여 그림자 페이지 생성
# shadow_page는 하드디스크에, current_page는 메모리에 존재

# 작업 수행: 현재 페이지에서만 데이터 변경
current_page["balance"] = 200  # 현재 페이지의 데이터만 변경
# shadow_page["balance"]는 여전히 100 (원본 유지!)

# 장애 발생 시: 그림자 페이지로 복구
if system_crash:
    current_page = copy(shadow_page)  # 그림자 → 현재로 덮어쓰기
    # 로그 없이도 원본 상태로 즉시 복구 가능!

# 트랜잭션 성공 시: 그림자 페이지 업데이트
if transaction_success:
    shadow_page = copy(current_page)  # 현재 → 그림자로 동기화
    # 다음 트랜잭션을 위해 두 페이지를 일치시킴
```

### 그림자 페이징의 장단점

**장점:**
- 로그를 사용하지 않으므로 **로그 관리 비용이 없습니다**
- 복구 시 그림자 페이지를 그냥 가져와 덮어쓰면 되므로 **복구 속도가 매우 빠릅니다**
- Undo/Redo 연산 없이 즉시 복구 가능

**단점:**

| 단점 | 설명 |
|------|------|
| **추가 저장 공간 필요** | 그림자 페이지를 별도로 보관해야 하므로 디스크 공간이 더 필요 |
| **쓰레기 데이터 발생** | 페이지가 다른 위치에 갱신되면 기존 페이지가 쓸모없는 쓰레기가 됨 |
| **데이터 단편화** | 페이지가 여기저기 흩어져서 물리적으로 연속되지 않아 성능 저하 |
| **병행 처리 불가 ⚠️** | 동시에 여러 사용자가 접근하는 **병행 처리(Concurrency)를 지원하지 못함** |

:::danger 가장 치명적인 단점: 병행 처리 불가
실제 데이터베이스는 수백~수천 명의 사용자가 **동시에** 접근합니다. 그림자 페이징은 **순차 처리만 가능**하기 때문에, 병행 처리가 필수인 실무 환경에서는 단독으로 사용하기 어렵습니다. 이 문제를 해결하기 위해 **로그 기반 기법과 그림자 페이징을 함께 조합**해서 사용하기도 합니다.
:::

---

## 🔄 ARIES (복구 중 장애 대처 기법)

### 복구 중에 또 장애가 발생하면?

데이터베이스를 사용하다가 장애가 발생하면 로그를 이용해 복구를 수행합니다. 그런데 만약 **복구하는 도중에 또 장애가 발생**하면 어떻게 될까요?

예를 들어, 100만 줄의 로그를 이용해 복구 작업을 하고 있었습니다. 전체의 90%를 복구했는데, 나머지 10%를 처리하는 도중 **다시 시스템이 다운**되었습니다.

기존 방식이라면 **처음부터 다시 100% 복구 작업을 반복**해야 합니다. 이미 90%나 완료한 작업을 다시 처음부터 해야 하는 것은 엄청난 비효율이죠.

:::info 실생활 비유
1000페이지짜리 소설을 타이핑하고 있는데, 900페이지까지 타이핑한 시점에서 컴퓨터가 다운됐다고 상상해 보세요. **자동 저장이 없었다면** 1페이지부터 다시 시작해야 합니다. 하지만 타이핑하면서 **중간중간 어디까지 했는지 기록해 두었다면**, 901페이지부터 이어서 할 수 있겠죠. ARIES가 바로 이런 역할을 합니다.
:::

### ARIES의 핵심 개념

**ARIES(Algorithm for Recovery and Isolation Exploiting Semantics)**는 복구 작업 중에도 **로그를 기록**하여, 다시 장애가 발생했을 때 **이미 완료된 복구 작업은 건너뛰고 나머지만 수행**할 수 있도록 하는 기법입니다.

ARIES의 핵심 원리는 **Repeating History(역사 반복)**입니다:

- **Redo 연산을 수행할 때**: 어디까지 Redo했는지 로그에 기록
- **Undo 연산을 수행할 때**: 어디까지 Undo했는지 로그에 기록
- 복구 중 장애 발생 시: 기록된 정보를 보고 **이미 완료된 부분은 건너뛰고** 나머지만 처리

```python
# ARIES 기법의 핵심 원리 의사코드

# 기존 방식: 복구 중 장애 시 처음부터 다시 시작
def old_recovery():
    for record in all_log_records:  # 100만 줄의 로그를 처음부터
        process_recovery(record)    # 한 줄씩 복구
        # ⚡ 90% 시점에서 장애 발생 → 다시 처음부터!

# ARIES 방식: 복구 진행 상황을 기록하며 복구
def aries_recovery():
    last_completed = read_recovery_log()  # 이전에 어디까지 복구했는지 확인
    
    for record in log_records[last_completed:]:  # 마지막 완료 지점부터 이어서
        process_recovery(record)                  # 복구 수행
        write_recovery_log(record)                # 복구 진행 상황을 로그에 기록
        # ⚡ 장애 발생 시 → 기록된 지점부터 이어서 복구 가능!
```

### ARIES의 3단계

ARIES는 다음 **3단계**로 복구를 수행합니다:

| 단계 | 이름 | 설명 |
|------|------|------|
| **1단계** | 분석 (Analysis) | 로그를 읽어서 어떤 트랜잭션이 Redo/Undo 대상인지 파악 |
| **2단계** | Redo (재실행) | Commit이 있는 트랜잭션을 재실행하면서 **로그에 진행 상황 기록** |
| **3단계** | Undo (취소) | Commit이 없는 트랜잭션을 취소하면서 **로그에 진행 상황 기록** |

핵심은 2단계와 3단계에서 복구 작업을 하면서도 **계속 로그를 기록한다**는 점입니다. 이렇게 하면 복구 중에 장애가 또 발생해도, 이미 완료된 Redo나 Undo 작업을 **반복하지 않아도** 됩니다.

> ARIES의 모든 단계에서는 WAL(Write-Ahead Logging) 원칙이 적용됩니다. 복구 작업을 수행하기 전에도 **반드시 로그를 먼저 기록**합니다.

---

## 🏢 백업 센터 운영 (재해 복구)

### 왜 백업 센터가 필요한가?

지금까지 다룬 내용은 데이터베이스 내부에서 로그와 체크포인트를 이용한 복구 기법이었습니다. 하지만 실제 운영 환경에서는 **물리적인 재해**(화재, 지진, 홍수 등)로 서버 자체가 파괴될 수도 있습니다.

이런 상황에 대비하기 위해, 메인 서버와 **별도의 장소에 백업 센터**를 운영합니다. 백업 센터는 데이터의 중요도와 복구 시간 요구사항, 그리고 **비용**에 따라 4가지 유형으로 나뉩니다.

### 4가지 백업 센터 유형

| 유형 | 복구 시간 | 비용 | 특징 |
|------|-----------|------|------|
| **미러 사이트 (Mirror Site)** | **즉시** | 가장 높음 | 운영 센터와 100% 동일한 장비, 실시간 동기화 |
| **핫 사이트 (Hot Site)** | **수 시간** | 높음 | 유사한 수준의 장비, 거의 실시간에 가까운 백업 |
| **웜 사이트 (Warm Site)** | **수 일** | 중간 | 기본 장비 구비, 데이터를 별도로 가져와야 함 |
| **콜드 사이트 (Cold Site)** | **약 1개월** | 가장 낮음 | 최소한의 기본 시설만 구비 |

### 각 유형 상세 설명

**🪞 미러 사이트 (Mirror Site)**

운영 센터와 **100% 동일한 장비와 데이터**를 갖춘 백업 센터입니다. 데이터가 처리되면 **실시간으로 동시에** 백업 센터에도 반영됩니다. 마치 거울(Mirror)처럼 똑같은 모습을 유지하는 것이죠.

은행, 증권사, 주식 거래 시스템 등 **1초도 다운되면 안 되는** 핵심 서비스에서 사용합니다. 장애 발생 시 **즉각적인 대처**가 가능하며, **핫 스와핑(Hot Swapping)** 기술을 통해 사용자가 눈치채지 못하게 자동으로 전환됩니다.

**🔥 핫 사이트 (Hot Site)**

미러 사이트처럼 100% 동기화되지는 않지만, **거의 유사한 수준**으로 갖추어져 있습니다. 장애 발생 시 **몇 시간 이내에** 복구할 수 있습니다.

웹 서비스 서버가 다운되었을 때 "몇 시간 만에 복구되었습니다"라는 공지를 본 적이 있다면, 그 서비스가 핫 사이트를 운영하고 있을 가능성이 높습니다.

**♨️ 웜 사이트 (Warm Site)**

기본적인 장비는 갖추어져 있지만, 데이터를 **별도로 가져와서 복원**해야 합니다. 복구에 **며칠 정도** 소요됩니다. "며칠 정도 서비스가 중단되어도 괜찮다"는 수준의 서비스에 적합합니다.

**❄️ 콜드 사이트 (Cold Site)**

가장 기본적인 시설(전원, 네트워크, 냉방 등)만 갖추고 있으며, 서버 장비부터 데이터까지 모두 새로 설치해야 합니다. 복구에 **약 1개월** 정도 소요되지만, **비용이 가장 적게** 듭니다.

> **백업 센터 선택 기준**: 데이터의 비즈니스 가치와 비용을 종합적으로 고려해야 합니다. 실시간으로 중요한 금융 데이터라면 미러 사이트가 필수이고, 상대적으로 덜 중요한 데이터라면 웜 사이트나 콜드 사이트로 비용을 절약할 수 있습니다.

---

## 🗂️ 데이터베이스 복구 알고리즘 총정리

지금까지 배운 모든 복구 기법을 한 표로 정리하겠습니다.

| 기법 | Undo | Redo | 로그 사용 | 설명 |
|------|------|------|-----------|------|
| **지연 갱신 기법** | ❌ No-Undo | ✅ Redo | 사용 | 커밋 전에는 디스크에 저장하지 않으므로 Undo 불필요. 커밋된 것만 Redo |
| **즉시 갱신 기법 (100% 저장 보장)** | ✅ Undo | ❌ No-Redo | 사용 | 무조건 저장되므로 커밋된 것은 Redo 불필요. 미커밋 건만 Undo |
| **즉시 갱신 기법 (일반)** | ✅ Undo | ✅ Redo | 사용 | 커밋 없는 건 Undo, 커밋된 건 Redo |
| **그림자 페이징** | ❌ No-Undo | ❌ No-Redo | **미사용** | 그림자 페이지로 즉시 복구. 병행 처리 불가 단점 |

```python
# 각 기법의 복구 로직을 간단히 비교하는 의사코드

# ✅ 지연 갱신 기법 (No-Undo, Redo)
def deferred_update_recovery(log):
    for txn in log:
        if txn.has_commit:          # 커밋이 있으면
            redo(txn)               # Redo 수행 (재실행)
        # 커밋이 없으면 아무것도 안 함 (디스크에 저장된 적 없으므로)

# ✅ 즉시 갱신 기법 - 일반 (Undo, Redo)
def immediate_update_recovery(log):
    for txn in log:
        if txn.has_commit:          # 커밋이 있으면
            redo(txn)               # Redo 수행 (재실행)
        else:                       # 커밋이 없으면
            undo(txn)               # Undo 수행 (취소)

# ✅ 그림자 페이징 (No-Undo, No-Redo)
def shadow_paging_recovery():
    current_page = shadow_page      # 그림자 페이지로 덮어쓰기
    # 끝! 로그도 없고, Undo/Redo도 없음
```

:::note 기법 선택 기준
- **성능이 중요하고 병행 처리가 필요**: 로그 기반 기법 (지연/즉시 갱신) + 체크포인트 + ARIES
- **빠른 복구가 필요하고 단일 사용자**: 그림자 페이징
- **복잡한 실무 환경**: 로그 기반 + 그림자 페이징을 조합하여 사용
:::

---

## ⚠️ 주의사항과 실무 팁

### 로그 버퍼링 관련 주의사항

1. **버퍼 크기를 적절히 설정하세요.** 로그 버퍼가 너무 크면 시스템 장애 시 손실되는 로그의 양이 많아지고, 너무 작으면 자주 디스크에 기록해야 해서 성능이 떨어집니다.

2. **커밋 시점에는 반드시 로그를 디스크에 저장하세요.** 트랜잭션이 커밋되기 전에, 해당 트랜잭션과 관련된 모든 로그 레코드가 안전한 저장장치에 기록되어야 합니다. 이것이 WAL 원칙의 핵심입니다.

3. **메모리는 휘발성이라는 것을 항상 기억하세요.** 버퍼링은 성능을 위한 것이지, 안전성을 위한 것이 아닙니다. 중요한 시점(커밋, 체크포인트)에서는 반드시 디스크에 저장해야 합니다.

### 체크포인트 관련 팁

1. **체크포인트 간격은 시스템 특성에 맞게 조정하세요.** 트랜잭션이 많고 빈번한 시스템이라면 간격을 짧게, 상대적으로 한가한 시스템이라면 길게 설정합니다.

2. **체크포인트 실행 중에는 다른 트랜잭션이 대기해야 합니다.** 이 점을 고려하여, 사용자가 적은 시간대에 체크포인트를 설정하는 것도 좋은 전략입니다.

### 백업 센터 관련 팁

1. **비용과 데이터 가치를 균형 있게 고려하세요.** 무조건 미러 사이트가 좋은 것이 아닙니다. 비즈니스 요구사항에 맞는 적절한 수준을 선택해야 합니다.

2. **복구 시간 목표(RTO)를 먼저 설정하세요.** "장애 발생 후 몇 시간/몇 일 이내에 서비스를 재개해야 하는가?"를 결정하면, 적합한 백업 센터 유형이 자연스럽게 결정됩니다.

---

## 📌 핵심 정리

- **로그 레코드 버퍼링**은 로그를 매번 디스크에 저장하지 않고 메모리에 모아두었다가 한꺼번에 저장하여 **I/O 횟수를 줄이고 성능을 향상**시키는 기법이다
- **로그 우선 기록 규약(WAL)**은 일반 데이터보다 **로그를 먼저 디스크에 저장**해야 한다는 원칙이며, 이를 통해 어떤 장애 상황에서도 복구 가능성을 보장한다
- **체크포인트**는 일정 간격으로 데이터를 디스크에 저장하여, 복구 시 체크포인트 이전에 커밋된 트랜잭션은 **Redo하지 않아 복구 시간을 단축**한다
- 체크포인트 복구 시: 체크포인트 이전 커밋 완료 → **아무 작업 안 함**, 이후 커밋 있음 → **Redo**, 커밋 없음 → **Undo**
- **그림자 페이징**은 로그 없이 현재 페이지와 그림자 페이지 두 개를 이용해 복구하는 **No-Undo / No-Redo 기법**이며, 빠르지만 **병행 처리를 지원하지 못하는** 단점이 있다
- **ARIES**는 복구 작업 중에도 로그를 기록하여, 복구 중 장애가 발생해도 **이미 완료된 복구 작업을 반복하지 않는** 기법이다
- 백업 센터는 **미러 사이트(즉시)** > **핫 사이트(수 시간)** > **웜 사이트(수 일)** > **콜드 사이트(1개월)** 순으로 복구 속도가 빠르고, 비용도 그에 비례한다
- 백업 센터 유형은 **데이터의 비즈니스 가치**와 **비용**을 균형 있게 고려하여 선택해야 한다

---

작성일: 2026-02-21