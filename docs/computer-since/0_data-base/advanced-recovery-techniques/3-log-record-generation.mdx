---
title: "트랜잭션 수행 시 로그 레코드의 생성 과정"
description: "트랜잭션 수행 시 로그 레코드의 생성 과정에 대해 초보자도 쉽게 이해할 수 있도록 설명합니다."
slug: "/advanced-recovery-techniques/3-log-record-generation"
sidebar_label: "로그 레코드 생성"
date: "2026-02-21"
---

## 🎯 이 문서에서 다루는 내용

이 문서에서는 데이터베이스의 **고급 회복(Recovery) 기법**에 대해 알아봅니다. 트랜잭션(작업 묶음)이 수행될 때 로그 레코드가 어떻게 생성되는지, 왜 로그를 먼저 기록해야 하는지, 그리고 복구 성능을 높이기 위한 다양한 기법들을 초보자도 이해할 수 있도록 자세히 설명합니다.

> **핵심 질문:** 트랜잭션이 수행되면서 만들어지는 로그 레코드를 어떻게 효율적으로 관리하고, 장애가 발생했을 때 빠르게 복구할 수 있을까?

지난 시간에 우리는 데이터베이스 회복의 기본 원리를 배웠습니다. **덤프(백업)**를 해놓고, **로그(변경 기록)**를 이용해서 복구한다는 것이었죠. 또한 **지연 갱신 기법**과 **즉시 갱신 기법**이라는 두 가지 방식을 살펴보았고, 커밋(확정)이 있는 트랜잭션은 **리두(Redo, 다시 실행)** 연산을, 커밋이 없는 트랜잭션은 **언두(Undo, 되돌리기)** 연산을 수행한다는 것을 배웠습니다. 이번 시간에는 여기서 한 걸음 더 나아가, 로그 레코드를 효율적으로 다루는 방법과 복구 성능을 극대화하는 고급 기법들을 깊이 있게 다뤄보겠습니다.

---

## 📝 로그 레코드의 생성 과정

### 트랜잭션이 수행되면 로그가 만들어진다

트랜잭션(Transaction)이란 데이터베이스에서 하나의 논리적인 작업 단위를 말합니다. 예를 들어 "A 계좌에서 B 계좌로 10만 원을 이체한다"는 것이 하나의 트랜잭션이 될 수 있습니다. 이 트랜잭션이 수행되는 동안, **데이터가 변경될 때마다 로그 레코드(변경 기록)가 한 줄씩 생성**됩니다.

마치 여러분이 일기장을 쓰듯이, 데이터베이스도 "오늘 무슨 작업을 했는지"를 하나하나 기록하는 것입니다. 이 기록이 바로 **로그 파일(Log File)**입니다.

구체적으로 살펴보면, 만약 처리해야 할 데이터가 **1만 개**라면 어떻게 될까요?

- 데이터 하나를 변경할 때마다 로그 레코드가 **한 줄씩** 생성됩니다
- 1만 개의 데이터를 처리하면, 로그 파일에도 **최소 1만 줄**의 기록이 만들어집니다
- 100만 개의 레코드를 처리한다면? 로그 파일은 **100만 줄 이상**이 됩니다

```sql
-- 예시: x 값을 100에서 200으로 변경하는 작업
UPDATE account SET balance = 200 WHERE id = 'x';  -- 이 작업 하나가 수행되면

-- 로그 레코드가 한 줄 생성됨:
-- [T1, x, 이전값=100, 이후값=200]

-- 다시 어떤 값을 200에서 300으로 변경하면
UPDATE account SET balance = 300 WHERE id = 'y';

-- 또 로그 레코드가 한 줄 생성됨:
-- [T1, y, 이전값=200, 이후값=300]
```

> 💡 **핵심 포인트:** 라이트(Write, 쓰기) 연산이 발생할 때마다 로그 레코드가 하나씩 생성되고, 이 로그 레코드들은 나중에 복구할 때 사용됩니다.

### 매번 저장하면 성능이 떨어진다

여기서 중요한 문제가 하나 생깁니다. 로그 레코드가 한 줄 생성될 때마다 **매번 하드디스크에 저장**한다면 어떻게 될까요?

- 하나 처리 → 하드디스크에 저장
- 하나 처리 → 하드디스크에 저장
- 하나 처리 → 하드디스크에 저장
- ... 이것을 **1만 번** 반복!

이것은 마치 여러분이 **엑셀에서 숫자 1만 개를 더하는 작업**을 하는데, 셀 하나를 입력할 때마다 매번 Ctrl+S로 저장하는 것과 같습니다. 상상만 해도 끔찍하게 느리겠죠? 실제로는 1만 개를 다 입력한 다음에 **마지막에 한 번만 저장**하는 것이 훨씬 효율적입니다.

:::info I/O 연산이 느린 이유
컴퓨터에서 데이터가 처리되는 과정은 다음과 같습니다:
1. **인풋(Input)**: 하드디스크 → 메모리로 데이터를 가져옴
2. **리드(Read)**: 메모리 → CPU로 데이터를 읽어옴
3. **라이트(Write)**: CPU → 메모리로 처리 결과를 기록
4. **아웃풋(Output)**: 메모리 → 하드디스크로 최종 저장

이 중에서 **하드디스크와 관련된 인풋/아웃풋(I/O) 연산**은 메모리나 CPU 연산에 비해 **수백~수천 배 느립니다**. 따라서 I/O 횟수를 줄이는 것이 데이터베이스 성능 향상의 핵심입니다.
:::

---

## 💾 로그 레코드 버퍼링 — 모아서 한꺼번에 저장하자

### 왜 버퍼링이 필요한가?

위에서 설명했듯이, 매번 로그 레코드를 하드디스크에 저장하면 **아웃풋(Output) 연산**이 너무 많아져서 시스템 성능이 심각하게 떨어집니다. 하나 처리하고 저장하고, 하나 처리하고 저장하고... 이런 방식은 현실적으로 불가능합니다.

그래서 등장한 개념이 바로 **로그 레코드 버퍼링(Log Record Buffering)**입니다.

> **로그 레코드 버퍼링이란?** 로그 레코드를 매번 하드디스크에 저장하지 않고, **메모리(버퍼)에 모아놨다가 한꺼번에 저장**하는 방식입니다.

이것은 마치 편지를 쓸 때마다 매번 우체국에 가는 것이 아니라, **편지를 여러 통 모아놨다가 한 번에 우체국에 가는 것**과 같습니다. 왕복 시간을 아낄 수 있으니까요.

### 버퍼링의 동작 원리

```
[기존 방식 - 매우 비효율적] ❌
작업1 → 로그 저장(하드디스크) → 작업2 → 로그 저장(하드디스크) → 작업3 → 로그 저장(하드디스크) → ...
    ↑ 매번 I/O 발생! 엄청 느림!

[버퍼링 방식 - 효율적] ✅
작업1 → 로그를 메모리에 저장
작업2 → 로그를 메모리에 저장
작업3 → 로그를 메모리에 저장
...
작업N → 로그를 메모리에 저장
                ↓
    한꺼번에 하드디스크로 저장! (I/O 1번만 발생)
```

이렇게 하면 메모리에는 두 가지 종류의 데이터가 함께 존재하게 됩니다:

| 메모리에 있는 데이터 | 설명 |
|---|---|
| **일반 데이터 버퍼** | 처리해야 할 실제 데이터 (계좌 잔액, 고객 정보 등) |
| **로그 레코드 버퍼** | 트랜잭션 수행 중 생성된 변경 기록들 |

두 종류의 데이터가 모두 메모리에 있고, 둘 다 **언젠가는 하드디스크에 저장(아웃풋)되어야** 합니다. 그렇다면 여기서 매우 중요한 질문이 생깁니다:

> ❓ **"일반 데이터와 로그 데이터, 둘 중에 어떤 것을 먼저 하드디스크에 저장해야 할까?"**

이 질문에 대한 답이 바로 다음에 설명할 **로그 우선 기록 규약(WAL)**입니다.

---

## 🔒 로그 우선 기록 규약(WAL) — 반드시 로그를 먼저 저장하라

### 왜 저장 순서가 중요한가?

로그 레코드 버퍼링 덕분에 로그 레코드들이 하드디스크에 저장되기 전에 **오랜 시간 메모리에 머물러** 있게 됩니다. 그런데 메모리는 **휘발성 저장 장치**입니다. 전원이 꺼지거나 시스템이 붕괴되면 메모리에 있는 데이터는 **모두 사라져 버립니다**.

만약 시스템이 실패하면 **로그 버퍼 내에 있는 로그 레코드가 전부 손실될 위험**이 있습니다. 그래서 로그 레코드를 안전하게 저장할 수 있는 규칙이 필요합니다.

하드디스크는 하나이기 때문에 **동시에 두 가지를 저장할 수 없습니다**. 반드시 순서를 정해서, 하나를 먼저 저장하고 다른 하나를 나중에 저장해야 합니다.

### 시나리오 비교: 어떤 순서가 안전한가?

#### ❌ 시나리오 1: 일반 데이터를 먼저 저장하는 경우

```
[순서]
1단계: 일반 데이터 → 하드디스크에 저장 ✅ (성공)
2단계: 로그 데이터 → 하드디스크에 저장 ❌ (에러 발생!)

[결과]
- 일반 데이터: 저장됨 ✅
- 로그 데이터: 저장 안 됨 ❌
- 문제: 나중에 복구하려고 할 때 로그가 없어서 복구 불가능! 😱
```

일반 데이터를 먼저 저장하면, 데이터는 저장되었지만 **로그가 없어서 복구할 방법이 사라집니다**. 이것은 마치 중요한 계약서는 보관했는데, **계약서의 사본(백업 기록)을 잃어버린 것**과 같습니다. 나중에 문제가 생겼을 때 원본이 훼손되면 어떤 내용이었는지 확인할 방법이 없습니다.

#### ✅ 시나리오 2: 로그 데이터를 먼저 저장하는 경우

```
[경우 A: 로그 저장 중 에러 발생]
1단계: 로그 데이터 → 하드디스크에 저장 ❌ (에러 발생!)
2단계: 일반 데이터 → 저장 시도조차 안 함

[결과]
- 로그 데이터: 저장 안 됨 ❌
- 일반 데이터: 저장 안 됨 ❌
- 아무 작업도 안 한 것과 같음 → 복구에 전혀 문제 없음! 👍
```

```
[경우 B: 로그는 저장 성공, 데이터 저장 중 에러 발생]
1단계: 로그 데이터 → 하드디스크에 저장 ✅ (성공)
2단계: 일반 데이터 → 하드디스크에 저장 ❌ (에러 발생!)

[결과]
- 로그 데이터: 저장됨 ✅
- 일반 데이터: 저장 안 됨 ❌
- 로그가 있으므로 덤프(백업) + 로그를 이용해서 복구 가능! 👍
```

:::warning 핵심 원칙
**어떤 경우든 로그를 먼저 저장하면 복구에 문제가 생기지 않습니다.** 로그 저장이 실패하면 데이터도 저장되지 않아서 아무 일도 안 한 것과 같고, 로그 저장이 성공하면 데이터가 실패해도 로그로 복구할 수 있기 때문입니다.
:::

### WAL의 정의

이 원칙을 **로그 우선 기록 규약**이라고 하며, 영어로는 **WAL(Write-Ahead Logging)**이라고 합니다. "Write-Ahead"는 "먼저 쓴다"는 뜻이고, "Logging"은 "로그를 기록한다"는 뜻입니다. 즉, **"로그를 먼저 기록하라!"**는 규약입니다.

| 항목 | 설명 |
|---|---|
| **한국어 명칭** | 로그 우선 기록 규약 |
| **영어 명칭** | Write-Ahead Logging |
| **약자** | WAL |
| **핵심 원칙** | 일반 데이터를 하드디스크에 저장하기 전에, 반드시 해당 데이터와 관련된 로그 레코드를 먼저 안전한 저장 장치에 저장해야 한다 |
| **목적** | 트랜잭션의 원자성(Atomicity)을 보장하고, 장애 발생 시 복구 가능성을 확보 |

> 💡 **한 줄 요약:** 데이터 블록과 로그 파일이 있으면, **로그 파일을 먼저 저장하고 데이터를 나중에 저장한다.** 이것이 WAL의 전부입니다.

---

## ⏱️ 체크포인트(Checkpoint) — 불필요한 리두 연산을 줄이자

### 왜 체크포인트가 필요한가?

로그를 이용한 복구 방식에는 심각한 **성능 문제**가 하나 있습니다. 로그 파일은 처음부터 끝까지 **순차적으로 읽어야** 하는 특성이 있습니다. 100만 개의 레코드를 처리했다면 로그 파일은 100만 줄이 넘습니다. 복구할 때 이 100만 줄을 **처음부터 끝까지** 전부 읽으면서 리두 또는 언두 연산을 수행해야 합니다.

그런데 생각해 보세요. 이미 **안전하게 하드디스크에 저장이 완료된 트랜잭션**도 있을 것입니다. 이미 커밋되고 하드디스크에 안전하게 저장된 데이터를 **굳이 다시 리두할 필요가 있을까요?** 전혀 없습니다! 하지만 로그 파일의 특성상 처음부터 읽기 때문에, 이미 완료된 것도 다시 리두하게 되는 비효율이 발생합니다.

> **체크포인트(Checkpoint)란?** 일정한 시간 간격으로 메모리에 있는 데이터와 로그를 한꺼번에 하드디스크에 저장하는 시점을 말합니다. 체크포인트를 설정하면, **체크포인트 이전에 완료된 트랜잭션은 복구 시 다시 처리할 필요가 없습니다.**

### 체크포인트 = 자동 저장과 같은 개념

여러분이 실생활에서 이미 체크포인트를 사용하고 있다는 사실, 알고 계셨나요?

**아래한글(HWP)**이나 **MS Word** 같은 문서 편집기를 사용할 때, 설정에 가보면 **"자동 저장"** 기능이 있습니다. "10분마다 자동 저장"으로 설정해 놓으면, 10분에 한 번씩 프로그램이 알아서 하드디스크에 저장합니다. 이것이 바로 체크포인트의 개념과 동일합니다!

| 비교 항목 | 문서 편집기의 자동 저장 | 데이터베이스의 체크포인트 |
|---|---|---|
| **무엇을 저장?** | 현재까지 작성한 문서 내용 | 메모리에 있는 로그와 데이터 |
| **언제 저장?** | 설정된 시간 간격마다 (예: 10분) | 설정된 시간 간격마다 |
| **저장 중 다른 작업 가능?** | 저장 중에는 잠시 멈춤 | 체크포인트 수행 중 다른 트랜잭션 일시 중단 |
| **간격이 너무 짧으면?** | 자주 멈추어서 작업 불편 | 성능 저하 |
| **간격이 너무 길면?** | 장애 시 많은 내용 손실 | 복구할 양이 많아짐 |

:::tip 실제 사례: 자동 저장 간격의 중요성
한 사용자가 아래한글만 실행하면 컴퓨터가 극도로 느려지는 문제를 겪었습니다. 다른 프로그램은 전혀 문제가 없었는데 말이죠. 원인을 찾아보니, **자동 저장 간격이 1분도 안 되게** 설정되어 있었습니다. 조금만 작업하면 바로 저장이 시작되고, 저장하는 동안 다른 작업을 할 수 없으니 체감 성능이 심각하게 떨어졌던 것입니다. **간격을 20~30분으로 늘렸더니** 문제가 해결되었습니다. 데이터베이스의 체크포인트도 마찬가지로, 시스템에 맞는 **최적의 간격**을 설정하는 것이 중요합니다.
:::

### 체크포인트의 수행 순서

체크포인트 시점이 되면, 다음의 순서로 작업이 수행됩니다. 이 **순서가 매우 중요**합니다:

```
[체크포인트 수행 순서]

1단계: 로그 레코드를 먼저 안전한 저장 장치(하드디스크)에 저장
       → WAL(로그 우선 기록 규약)에 따라 로그가 항상 먼저!

2단계: 일반 데이터 버퍼 블록을 하드디스크에 저장
       → 실제 변경된 데이터를 안전하게 저장

3단계: 체크포인트에 대한 정보(체크포인트 로그 레코드)를 하드디스크에 저장
       → "이 시점에 체크포인트가 수행되었다"는 기록을 남김
```

> ⚠️ **순서 정리:** 로그 레코드 → 데이터 버퍼 블록 → 체크포인트 정보. 이 순서를 반드시 기억하세요!

### 체크포인트 회복 알고리즘

체크포인트를 이용한 회복은 다음과 같은 단계로 수행됩니다:

**1단계:** 빈 **언두 리스트(Undo List)**와 **리두 리스트(Redo List)**를 만듭니다.

**2단계:** 체크포인트 설정 당시에 **활동 중인(아직 완료되지 않은) 트랜잭션**을 모두 언두 리스트에 넣습니다.

**3단계:** 체크포인트 이후에 **새로 시작(Start)된 트랜잭션**도 모두 언두 리스트에 넣습니다.

**4단계:** 로그를 검사하면서, **커밋(Commit)이 있는 트랜잭션**을 발견하면 언두 리스트에서 빼서 리두 리스트로 옮깁니다.

**5단계:** 회복 수행 — 언두 리스트에 있는 트랜잭션은 **역방향(뒤에서 앞으로)**으로 언두 연산을 수행하고, 리두 리스트에 있는 트랜잭션은 **순방향(앞에서 뒤로)**으로 리두 연산을 수행합니다.

### 🔍 실제 예시로 이해하기

다음과 같은 상황을 가정해 봅시다. 5개의 트랜잭션이 있고, 중간에 체크포인트가 설정되었으며, 이후 특정 시점에서 에러(장애)가 발생했습니다.

```
시간 ──────────────────────────────────────────────────────►

T1: |===Start===|===Commit===|
T2:        |===Start==========|==========Commit===|
T3:               |===Start============================| (커밋 없음)
T4:                              |===Start===|==Commit=|
T5:                                    |===Start============| (커밋 없음)
                         ↑                            ↑
                    체크포인트                       에러 발생!
```

이 그림을 해석해 보겠습니다:

- **T1**: 체크포인트 **이전에** 시작하고, 체크포인트 **이전에** 커밋 완료
- **T2**: 체크포인트 **이전에** 시작하고, 체크포인트 **이후에** 커밋 완료
- **T3**: 체크포인트 **이전에** 시작했지만, 에러 발생 시점까지 **커밋 없음**
- **T4**: 체크포인트 **이후에** 시작하고, 에러 발생 전에 **커밋 완료**
- **T5**: 체크포인트 **이후에** 시작했지만, 에러 발생 시점까지 **커밋 없음**

이제 알고리즘을 단계별로 적용해 봅시다:

```
[1단계] 빈 리스트 생성
  Undo 리스트: [ ]
  Redo 리스트: [ ]

[2단계] 체크포인트 당시 활동 중인 트랜잭션 → Undo에 넣기
  - T2: 체크포인트 시점에 아직 실행 중 → Undo에 추가
  - T3: 체크포인트 시점에 아직 실행 중 → Undo에 추가
  Undo 리스트: [T2, T3]
  Redo 리스트: [ ]

[3단계] 체크포인트 이후 새로 시작된 트랜잭션 → Undo에 넣기
  - T4: 체크포인트 이후 시작 → Undo에 추가
  - T5: 체크포인트 이후 시작 → Undo에 추가
  Undo 리스트: [T2, T3, T4, T5]
  Redo 리스트: [ ]

[4단계] 커밋이 있는 트랜잭션 → Undo에서 빼서 Redo로 이동
  - T2: 커밋 있음! → Undo에서 삭제, Redo로 이동
  - T4: 커밋 있음! → Undo에서 삭제, Redo로 이동
  Undo 리스트: [T3, T5]     ← 커밋이 없는 트랜잭션
  Redo 리스트: [T2, T4]     ← 커밋이 있는 트랜잭션
```

:::note T1은 어디에 있나요?
여기서 **T1이 어느 리스트에도 없다**는 것을 눈치채셨나요? T1은 체크포인트 **이전에 이미 커밋이 완료**되었습니다. 체크포인트 시점에 활동 중이지도 않고, 체크포인트 이후에 시작되지도 않았습니다. 따라서 T1은 **Undo도 하지 않고, Redo도 하지 않습니다**. 이것이 바로 체크포인트의 핵심 장점입니다!
:::

최종적으로 수행되는 작업을 정리하면:

| 트랜잭션 | 수행할 작업 | 범위 | 이유 |
|---|---|---|---|
| **T1** | **아무 작업 없음** ✨ | - | 체크포인트 이전에 이미 커밋 완료 |
| **T2** | Redo (다시 실행) | 체크포인트 이후 부분만 | 체크포인트 이후에 커밋됨 |
| **T3** | Undo (되돌리기) | 전체 | 커밋 없음 (실패한 트랜잭션) |
| **T4** | Redo (다시 실행) | 전체 (체크포인트 이후 시작) | 체크포인트 이후에 시작되어 커밋됨 |
| **T5** | Undo (되돌리기) | 전체 | 커밋 없음 (실패한 트랜잭션) |

:::danger 체크포인트가 없었다면?
만약 체크포인트가 없었다면, 커밋이 있는 **T1, T2, T4** 모두 Redo 연산을 수행해야 하고, 커밋이 없는 **T3, T5**는 Undo 연산을 수행해야 합니다. 체크포인트 덕분에 **T1의 불필요한 Redo 연산을 생략**할 수 있었고, T2도 체크포인트 이후 부분만 Redo하면 됩니다. 이렇게 체크포인트는 **불필요한 Redo 연산의 횟수를 줄여서** 회복 작업의 속도를 빠르게 만들어 줍니다.
:::

---

## 👻 그림자 페이징(Shadow Paging) — 로그 없이 복구하는 기법

### 왜 로그를 사용하지 않는 기법이 필요한가?

지금까지 살펴본 복구 기법들은 모두 **로그 파일**을 이용했습니다. 하지만 로그를 만들고 관리하는 데에도 비용이 들어갑니다. 로그 레코드를 생성하고, 버퍼에 모으고, 하드디스크에 저장하는 모든 과정에 시간과 자원이 소모됩니다.

**그림자 페이징(Shadow Paging)**은 로그를 사용하지 않는 복구 기법입니다. 로그 대신 **두 개의 페이지(page)**를 이용합니다. 로그를 사용하지 않기 때문에 **No-Undo/No-Redo 기법**이라고도 합니다. 즉, 언두 연산도 리두 연산도 필요 없습니다.

### 그림자 페이징의 핵심 구조

그림자 페이징에서는 **두 개의 페이지**가 존재합니다:

| 페이지 종류 | 저장 위치 | 역할 |
|---|---|---|
| **현재 페이지(Current Page)** | 메모리 | 실제 작업(갱신)이 이루어지는 곳 |
| **그림자 페이지(Shadow Page)** | 하드디스크 | 원본 데이터의 복사본을 보관하는 곳 |

트랜잭션이 시작되면, 현재 페이지와 **동일한 내용의 그림자 페이지**를 만들어 놓습니다. 이후 갱신 작업이 수행되면 **현재 페이지의 내용만 변경**하고, 그림자 페이지는 **변경하지 않고 그대로** 둡니다.

### 동작 원리를 그림으로 이해하기

마치 시험지를 풀 때, 원본 시험지는 깨끗하게 보관하고 **복사본에만 답을 적는 것**과 같습니다. 답을 잘못 적었으면 복사본을 버리고 원본에서 다시 복사하면 됩니다.

```
[초기 상태]
실제 데이터:    100
현재 페이지:    100  (메모리)
그림자 페이지:  100  (하드디스크)

[작업 수행: 100 → 200으로 변경]
실제 데이터:    200  ← 변경됨
현재 페이지:    200  ← 변경됨
그림자 페이지:  100  ← 변경하지 않음! (원본 보관)
```

#### ❌ 장애가 발생한 경우 (복구 필요)

```
변경 작업 중 장애 발생! (커밋 안 됨)

[복구 방법]
그림자 페이지(100)의 값을 가져와서 덮어쓰기!
  그림자 페이지(100) → 현재 페이지(100)
  그림자 페이지(100) → 실제 데이터(100)

결과: 원래 값(100)으로 복구 완료! ✅
```

#### ✅ 성공적으로 완료된 경우 (커밋)

```
변경 작업이 성공적으로 완료됨! (커밋됨)

[반영 방법]
현재 페이지의 새 값(200)을 그림자 페이지에도 반영!
  현재 페이지(200) → 그림자 페이지(200)

결과: 그림자 페이지도 새 값(200)으로 업데이트! ✅
```

### 그림자 페이징의 장단점

**장점:**
- 로그를 사용하지 않으므로 **로그 관련 비용이 절약**됩니다
- 그림자 페이지를 가져다가 덮어쓰기만 하면 되므로 **처리 속도가 매우 빠릅니다**
- 장애 발생 시 **회복 작업이 매우 신속**합니다

**단점:**

| 단점 | 설명 |
|---|---|
| **추가 저장 공간 필요** | 그림자 페이지를 별도로 저장해야 하므로 저장 공간이 더 필요합니다 |
| **쓰레기 데이터 발생** | 페이지가 갱신되면서 기존 페이지가 더 이상 필요 없어지면 쓰레기(Garbage)가 됩니다. 이를 정리하는 **쓰레기 수집(Garbage Collection)**이 필요합니다 |
| **데이터 단편화** | 페이지가 여기저기 흩어져 저장되면서 데이터 조각(단편화, Fragmentation)이 많아져 전체 시스템 성능이 떨어질 수 있습니다 |
| **병행 처리 불가** 🚨 | 가장 치명적인 단점! 동시에 여러 사용자가 사용하는 **병행 처리(Concurrency)를 지원할 수 없습니다**. 순차 처리만 가능합니다 |

:::danger 병행 처리 불가 — 가장 치명적인 단점
실제 데이터베이스는 동시에 수많은 사용자가 접속하여 **병행으로 처리**해야 합니다. 그림자 페이징은 순차 처리만 가능하기 때문에, 병행 환경에서 단독으로 사용하기 어렵습니다. 이 문제를 해결하기 위해, 기존의 **로그 기법과 그림자 페이지 기법을 합쳐서** 병행 처리를 지원하는 방법을 사용하기도 합니다.
:::

---

## 🔄 ARIES 기법 — 복구 중 에러가 발생하면?

### 왜 ARIES가 필요한가?

데이터베이스를 사용하다가 에러가 발생하면 로그를 이용해서 복구합니다. 그런데 **복구하는 도중에 또 에러가 발생**하면 어떻게 될까요?

예를 들어, 100개의 트랜잭션을 복구해야 하는데, 90개까지 복구한 상태에서 또 에러가 발생했다고 가정해 봅시다. 남은 10개만 복구하면 되는데, 기존 방식으로는 **처음부터 다시 100개를 전부 복구**해야 합니다. 이미 90%나 완료한 작업을 처음부터 다시 해야 하는 것은 엄청난 낭비입니다.

이것은 마치 1,000피스 퍼즐을 900개까지 맞춰놓았는데, 누군가 와서 다 흩어뜨리고 "처음부터 다시 하세요"라고 하는 것과 같습니다. 900개는 이미 맞춘 거니까, **나머지 100개만 맞추면 되지 않겠습니까?**

> **ARIES(Algorithm for Recovery and Isolation Exploiting Semantics)란?** 복구 작업을 수행하는 중에 에러가 발생했을 때, 이미 완료된 복구 작업은 반복하지 않고 **나머지 부분만 처리**할 수 있도록 하는 고급 복구 기법입니다.

### ARIES의 핵심 원리

ARIES의 핵심은 **복구 작업 자체도 로그에 기록**한다는 것입니다.

```
[기존 방식] ❌
복구 시작 → 90% 복구 완료 → 에러 발생! → 처음부터 다시 100% 복구 시작 😭

[ARIES 방식] ✅
복구 시작 → 10% 복구(로그 기록) → 20% 복구(로그 기록) → ... → 90% 복구(로그 기록)
→ 에러 발생! → 로그 확인 → "90%까지 했네!" → 나머지 10%만 복구! 😊
```

| 특징 | 설명 |
|---|---|
| **WAL 준수** | 로그를 항상 먼저 기록하는 WAL 원칙을 당연히 따릅니다 |
| **Repeating History** | 리두(복구) 작업을 수행할 때 그 작업 내역을 다시 로깅(기록)합니다. "역사 반복 정보"라고도 합니다 |
| **리두 중 로깅** | 커밋이 있는 트랜잭션의 리두 연산을 수행할 때도 로그를 기록합니다 |
| **언두 중 로깅** | 커밋이 없는 트랜잭션의 언두 연산을 수행할 때도 로그를 기록합니다 |

:::tip ARIES의 핵심 효과
이미 **언두 작업이 완료된 연산은 다시 언두하지 않고**, 이미 **리두 작업이 완료된 연산은 다시 리두하지 않습니다**. 이를 통해 복구 작업의 반복을 막아서 **복구 시간을 대폭 단축**시킬 수 있습니다.
:::

### ARIES의 3단계 수행 과정

```
[ARIES 복구의 3단계]

1단계: 분석(Analysis) 📊
  - 로그를 검사하여 각 트랜잭션의 상태를 파악
  - 활동 중인 건지? 커밋이 있는 건지? 없는 건지?
  - 무엇을 리두해야 하고 무엇을 언두해야 하는지 결정

2단계: 리두(Redo) 🔄
  - 커밋이 있는 트랜잭션에 대해 리두 연산 수행
  - 리두 작업 자체도 로그에 기록!

3단계: 언두(Undo) ↩️
  - 커밋이 없는 트랜잭션에 대해 언두 연산 수행
  - 언두 작업 자체도 로그에 기록!
  - 이미 언두된 것은 다시 언두하지 않음
```

---

## 🏢 백업 센터의 유형 — 복구 속도와 비용의 균형

### 왜 백업 센터가 필요한가?

데이터베이스 복구의 기본은 **덤프(Dump)**, 즉 **백업(Backup)**입니다. 메모리에 있는 데이터를 안전한 저장 장치에 미리 복사해 놓는 것이죠. 여러분도 집에 있는 컴퓨터의 중요한 파일을 USB나 클라우드에 백업해 본 경험이 있을 것입니다.

기업 환경에서는 이 백업을 전문적으로 관리하는 **백업 센터**를 운영합니다. 백업 센터의 수준은 **데이터의 중요도와 투자 가능한 비용**에 따라 달라집니다.

### 백업 센터의 4가지 유형

| 유형 | 복구 시간 | 비용 | 특징 | 적합한 서비스 예시 |
|---|---|---|---|---|
| **미러 사이트(Mirror Site)** | 즉시 | 매우 높음 | 주 센터와 100% 동일한 장비로 실시간 동기화 | 은행, 증권, 주식 거래 |
| **핫 사이트(Hot Site)** | 수 시간 이내 | 높음 | 주 센터와 유사한 수준이지만 100% 동일하지는 않음 | 대형 포털, 전자상거래 |
| **웜 사이트(Warm Site)** | 수일 | 중간 | 별도의 백업 센터에 데이터를 따로 보관 | 일반 기업 서비스 |
| **콜드 사이트(Cold Site)** | 수 주 ~ 1개월 | 낮음 | 최소한의 기본 시설만 갖춘 백업 센터 | 중요도가 낮은 서비스 |

### 각 유형 상세 설명

**🪞 미러 사이트(Mirror Site)**

"미러(Mirror)"는 거울이라는 뜻입니다. 주 전산 센터(운영 센터)와 **거울처럼 100% 똑같은 백업 센터**를 운영합니다. 운영 센터에서 데이터가 처리되면 **실시간으로 동시에** 백업 센터에도 반영됩니다. 이를 **실시간 이중화** 또는 **핫 스와핑(Hot Swapping)**이라고 합니다. 장애가 발생하면 즉각적으로 백업 센터로 전환할 수 있어서, 서비스 중단 없이 운영이 가능합니다. 은행이나 증권사처럼 **1초도 서비스가 중단되면 안 되는** 곳에서 사용합니다.

**🔥 핫 사이트(Hot Site)**

미러 사이트처럼 100% 동기화되지는 않지만, **어느 정도 동일한 수준**으로 갖춰놓은 백업 센터입니다. 장애 발생 시 **수 시간 이내에 복구**가 가능합니다. 여러분이 사용하는 웹 서비스가 서버 다운 후 몇 시간 만에 복구되는 경우, 핫 사이트로 운영되고 있을 가능성이 높습니다.

**🌡️ 웜 사이트(Warm Site)**

별도의 백업 센터에 데이터를 **따로따로 옮겨 놓는** 방식입니다. 실시간 동기화가 아니기 때문에, 복구 시 데이터를 가져와야 하므로 **며칠 정도** 복구에 시간이 걸립니다. 복구에 며칠 걸려도 괜찮은 서비스에 적합합니다.

**❄️ 콜드 사이트(Cold Site)**

가장 차가운(Cold), 즉 **최소한의 기본 시설만** 갖춘 백업 센터입니다. 장애 발생 시 **1개월 정도** 복구에 시간이 걸릴 수 있습니다. 비용이 가장 적게 들지만, 복구 시간도 가장 깁니다.

:::warning 비용과 가치의 균형
백업 센터의 유형을 결정할 때는 **비용**과 **비즈니스 가치**를 함께 고려해야 합니다.
- 실시간으로 매우 중요한 데이터라면? → **미러 사이트**
- 수 시간 정도 중단이 허용된다면? → **핫 사이트**
- 며칠 정도 복구 시간이 괜찮다면? → **웜 사이트**
- 비용 절감이 최우선이고, 긴 복구 시간이 허용된다면? → **콜드 사이트**

**비용 대비 가장 효율이 좋은 백업 센터를 선택하는 것이 핵심입니다.**
:::

---

## 📊 데이터베이스 복구 알고리즘 종합 비교

지금까지 배운 모든 복구 기법을 정리해 봅시다:

| 기법 명칭 | Undo | Redo | 설명 | 특징 |
|---|---|---|---|---|
| **No-Undo/Redo** (지연 갱신 기법) | ❌ 안 함 | ✅ 수행 | 아웃풋이 지연되어 있어서, 커밋 없는 것은 아무 작업 불필요. 커밋된 것만 Redo | 커밋 전에는 하드디스크에 저장하지 않음 |
| **Undo/No-Redo** (즉시 갱신 기법 - 100% 저장 보장) | ✅ 수행 | ❌ 안 함 | 100% 저장이 보장되므로 커밋된 것은 이미 안전. 커밋 없는 것만 Undo | 즉시 갱신의 한 종류 |
| **Undo/Redo** (즉시 갱신 기법 - 일반) | ✅ 수행 | ✅ 수행 | 커밋 없는 것은 Undo, 커밋 있는 것은 Redo | 가장 일반적인 로그 기반 복구 |
| **No-Undo/No-Redo** (그림자 페이징) | ❌ 안 함 | ❌ 안 함 | 로그를 사용하지 않고, 그림자 페이지로 복구 | 병행 처리 불가 단점 |

:::note 복구 기법 선택 기준
- **로그를 사용하는 기법**: No-Undo/Redo, Undo/No-Redo, Undo/Redo
- **로그를 사용하지 않는 기법**: No-Undo/No-Redo (그림자 페이징)
- **성능 최적화 기법**: 체크포인트(불필요한 Redo 감소), ARIES(복구 중 반복 작업 감소)

각각의 기법은 장단점이 있으며, 실제 데이터베이스 시스템에서는 상황에 맞게 적절히 조합하여 사용합니다.
:::

---

## 📌 핵심 정리

- **로그 레코드**는 트랜잭션의 라이트(Write) 연산이 발생할 때마다 한 줄씩 생성되며, 나중에 복구 시 사용된다
- **로그 레코드 버퍼링**은 로그를 매번 하드디스크에 저장하지 않고 메모리에 모아놨다가 한꺼번에 저장하는 기법으로, I/O 횟수를 줄여 성능을 향상시킨다
- **로그 우선 기록 규약(WAL: Write-Ahead Logging)**은 일반 데이터보다 로그 레코드를 반드시 먼저 하드디스크에 저장해야 한다는 원칙이다
- WAL을 지키는 이유는 로그가 없으면 복구 자체가 불가능해지기 때문이다
- **체크포인트(Checkpoint)**는 일정 간격으로 데이터를 저장하는 시점으로, 체크포인트 이전에 커밋된 트랜잭션은 복구 시 아무 작업도 하지 않아 불필요한 Redo 연산을 줄여준다
- 체크포인트 수행 순서: 로그 레코드 저장 → 데이터 버퍼 블록 저장 → 체크포인트 정보 저장
- **그림자 페이징(Shadow Paging)**은 로그 없이 현재 페이지와 그림자 페이지 두 개를 이용해 복구하는 No-Undo/No-Redo 기법이지만, 병행 처리를 지원하지 못하는 치명적 단점이 있다
- **ARIES**는 복구 작업 중에도 로그를 기록하여, 복구 중 에러가 발생해도 이미 완료된 복구 작업을 반복하지 않도록 하는 기법이다
- 백업 센터는 미러 사이트(즉시) → 핫 사이트(수 시간) → 웜 사이트(수일) → 콜드 사이트(수 주) 순으로 복구 속도와 비용이 다르며, 비즈니스 가치와 비용을 고려하여 선택해야 한다

작성일: 2026-02-21