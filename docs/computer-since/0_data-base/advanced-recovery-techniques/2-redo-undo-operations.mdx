---
title: "리두(Redo)와 언두(Undo) 연산의 수행 원리"
description: "리두(Redo)와 언두(Undo) 연산의 수행 원리에 대해 초보자도 쉽게 이해할 수 있도록 설명합니다."
slug: "/advanced-recovery-techniques/2-redo-undo-operations"
sidebar_label: "리두와 언두"
date: "2026-02-21"
---

## 🎯 이 문서에서 배울 내용

데이터베이스를 운영하다 보면 예상치 못한 장애가 발생할 수 있습니다. 정전이 나거나, 서버가 갑자기 꺼지거나, 프로그램에 오류가 생기는 등 다양한 문제가 생길 수 있죠. 이때 데이터를 원래대로 되돌리거나, 완료된 작업을 다시 적용하는 것이 바로 **회복(Recovery)** 입니다.

이번 문서에서는 데이터베이스 회복의 핵심인 **리두(Redo)와 언두(Undo) 연산**이 실제로 어떻게 수행되는지, 그리고 이 과정에서 성능을 높이기 위해 어떤 기법들이 사용되는지를 초보자도 이해할 수 있도록 자세히 살펴봅니다.

> 이 문서는 지연 갱신 기법과 즉시 갱신 기법의 기본 개념을 이미 알고 있다는 전제하에, 그 **다음 단계인 고급 회복 기법**을 다룹니다.

---

## 📝 로그 레코드 버퍼링이란?

### 왜 로그를 한 줄씩 저장하면 안 될까?

데이터베이스에서 트랜잭션(작업 묶음)이 수행되면, 각 작업마다 **로그 레코드(작업 기록)**가 하나씩 생성됩니다. 예를 들어, 어떤 값 `x`를 100에서 200으로 변경하면 로그 레코드가 한 줄 만들어지고, 다시 다른 값을 200에서 300으로 변경하면 또 한 줄이 만들어집니다.

만약 처리해야 할 데이터가 **1만 건**이라면, 로그 레코드도 **1만 줄**이 생성됩니다. 그런데 여기서 중요한 문제가 생깁니다. 로그 레코드가 한 줄 만들어질 때마다 매번 하드디스크에 저장한다면 어떻게 될까요?

이것은 마치 **엑셀에서 셀 하나를 입력할 때마다 매번 저장 버튼을 누르는 것**과 같습니다. 1만 개의 숫자를 더해야 하는데, 하나 입력하고 저장, 하나 입력하고 저장... 이렇게 하면 작업이 끝나질 않겠죠? 실제로는 1만 개를 한꺼번에 다 처리한 다음에 **마지막에 한 번만 저장**하는 것이 훨씬 효율적입니다.

### 컴퓨터의 데이터 처리 흐름

컴퓨터에서 데이터가 처리되는 흐름을 이해하면 왜 매번 저장이 문제인지 명확해집니다.

| 연산 | 방향 | 설명 |
|------|------|------|
| **인풋(Input)** | 하드디스크 → 메모리 | 하드디스크에서 데이터를 메모리로 가져오기 |
| **리드(Read)** | 메모리 → CPU | 메모리에서 CPU로 데이터 읽어오기 |
| **라이트(Write)** | CPU → 메모리 | CPU에서 처리한 결과를 메모리에 기록 |
| **아웃풋(Output)** | 메모리 → 하드디스크 | 메모리의 데이터를 하드디스크에 저장 |

여기서 핵심은 **아웃풋(Output)** 연산입니다. 하드디스크에 직접 데이터를 읽고 쓰는 **I/O(입출력) 연산**은 메모리 내부 연산에 비해 **엄청나게 시간이 오래 걸리는 작업**입니다. 마치 집 안에서 물건을 옮기는 것(메모리 내부 연산)과 택배를 보내고 받는 것(I/O 연산)의 차이라고 생각하면 됩니다.

### 로그 레코드 버퍼링의 개념

그래서 데이터베이스는 매번 아웃풋을 하지 않고, **로그 레코드를 메모리에 모아놨다가 한꺼번에 하드디스크로 저장**하는 방식을 사용합니다. 이것이 바로 **로그 레코드 버퍼링(Log Record Buffering)** 입니다.

> **로그 레코드 버퍼링**이란, 로그 레코드가 생성될 때마다 즉시 하드디스크에 저장하지 않고, **메모리(버퍼)에 모아놨다가 적절한 시점에 한꺼번에 저장**하는 기법입니다.

원래대로라면 하나의 라이트 연산이 발생할 때마다 인풋 → 리드 → 라이트 → 아웃풋 과정이 반복되어야 합니다. 하지만 로그 레코드 버퍼링을 사용하면, 라이트까지는 메모리에서 계속 처리하고 **아웃풋은 마지막에 한 번만** 수행하므로 I/O 횟수를 획기적으로 줄일 수 있습니다.

:::info 성능 향상의 핵심
데이터베이스 성능을 향상시키려면 **아웃풋(Output) 연산의 횟수를 줄여야** 합니다. 아웃풋 연산을 줄이기 위해 메모리에 작업 결과를 모아놓고, 나중에 한꺼번에 처리하는 것이 로그 레코드 버퍼링의 핵심 원리입니다.
:::

---

## 🔒 로그 우선 기록 규약 (WAL)

### 메모리에 두 가지가 함께 있는 상황

로그 레코드 버퍼링을 사용하면, 메모리에는 두 종류의 데이터가 동시에 존재하게 됩니다.

1. **일반 데이터** — 실제로 처리해야 하는 업무 데이터
2. **로그 데이터** — 작업 기록을 담고 있는 로그 레코드

이 두 가지 모두 결국에는 하드디스크로 아웃풋되어야 합니다. 그런데 여기서 중요한 질문이 생깁니다. **둘 중에 무엇을 먼저 저장해야 할까요?**

하드디스크는 하나이기 때문에 동시에 두 가지를 저장할 수 없습니다. 반드시 순서를 정해야 하죠.

### 일반 데이터를 먼저 저장하면 어떻게 될까? ❌

시나리오를 한번 그려봅시다:

1. 일반 데이터를 먼저 하드디스크에 저장합니다 → **저장 완료** ✅
2. 그 다음 로그 데이터를 저장하려는 중에 **에러가 발생**합니다 → **저장 실패** ❌

이 경우 어떤 문제가 생길까요? 일반 데이터는 저장됐지만, **로그 파일이 없습니다**. 나중에 장애가 발생해서 복구를 하려고 해도 로그 레코드가 없기 때문에 **복구 자체가 불가능**해집니다. 이것은 마치 **집을 지었는데 설계도면을 잃어버린 것**과 같습니다. 문제가 생겨도 원래 어떤 구조였는지 알 수 없으니 고칠 방법이 없는 것이죠.

### 로그 데이터를 먼저 저장하면 어떻게 될까? ✅

반대 시나리오를 살펴봅시다:

**시나리오 A — 로그 저장 중 에러 발생:**
1. 로그 데이터를 먼저 저장하려는 중에 **에러 발생** → 로그 없음, 데이터도 저장 안 됨
2. 결과: **아무 작업도 수행되지 않은 것**과 같으므로 복구에 전혀 문제 없음 ✅

**시나리오 B — 로그 저장 성공 후 데이터 저장 중 에러 발생:**
1. 로그 데이터를 먼저 저장 → **저장 완료** ✅
2. 일반 데이터를 저장하려는 중에 **에러 발생** → 데이터 저장 실패 ❌
3. 결과: 로그 파일이 있으므로, 마지막에 덤프(백업)해 놓은 데이터에 로그를 적용하여 **복구 가능** ✅

### WAL의 정의

이처럼 **반드시 로그 레코드를 먼저 저장하고, 그 다음에 일반 데이터를 저장해야 한다**는 규칙을 **로그 우선 기록 규약**이라고 합니다.

> **로그 우선 기록 규약 (Write-Ahead Logging, WAL)** 이란, 일반 데이터 버퍼 블록을 하드디스크로 아웃풋하기 전에, 반드시 해당 데이터와 관련된 **모든 로그 레코드를 먼저 안전한 저장 장치에 저장**해야 한다는 규약입니다.

:::warning WAL을 지키지 않으면?
로그 우선 기록 규약을 지키지 않으면, 장애 발생 시 복구에 필요한 로그가 없어서 **데이터를 영영 되돌릴 수 없는** 치명적인 상황이 발생할 수 있습니다. 트랜잭션의 **원자성(Atomicity)** — 작업은 전부 수행되거나 전부 취소되어야 한다는 원칙 — 을 지키기 위해 WAL은 반드시 준수해야 합니다.
:::

한마디로 정리하면 이렇습니다:

```
데이터 블록 + 로그 파일 → 로그 파일을 먼저 저장 → 데이터를 나중에 저장
```

이것이 WAL(Write-Ahead Logging)의 전부입니다.

---

## ⏱️ 체크포인트 (Checkpoint)

### 왜 체크포인트가 필요한가?

WAL 규약에 따라 로그를 먼저 기록하면 안전하게 복구할 수 있습니다. 하지만 여기에도 **성능 문제**가 있습니다.

100만 개의 레코드를 처리했다면 로그 파일도 **최소 100만 줄 이상**이 됩니다. 장애가 발생하면 덤프 파일을 가져온 뒤, 이 100만 줄의 로그 파일을 **처음부터 끝까지** 읽으면서 커밋이 있는 트랜잭션은 리두(Redo), 커밋이 없는 트랜잭션은 언두(Undo)를 수행해야 합니다.

그런데 이미 **안전하게 하드디스크에 저장이 완료된 트랜잭션**도 있을 수 있습니다. 이미 커밋이 되어서 하드디스크에 정상적으로 기록된 데이터는 **다시 리두할 필요가 없는데**, 로그 파일의 특성상 처음부터 읽어야 하니까 불필요한 리두 연산이 발생하는 것이죠.

> **이미 리두할 필요가 없는 트랜잭션까지 다시 리두하는 낭비를 줄이기 위해** 등장한 것이 바로 **체크포인트(Checkpoint)** 입니다.

### 체크포인트란 무엇인가?

체크포인트는 여러분이 **아래아 한글(HWP)**이나 **MS 워드**에서 사용하는 **자동 저장** 기능과 매우 비슷합니다.

문서 작업을 할 때 설정에 가보면 "자동 저장 간격: 10분"처럼 설정할 수 있습니다. 10분마다 프로그램이 알아서 하드디스크에 저장을 해주는 것이죠. 내가 직접 `Ctrl+S`를 누르는 것이 커밋이라면, 프로그램이 알아서 해주는 자동 저장이 바로 **체크포인트**입니다.

체크포인트가 설정되면, 그 시점까지 메모리에 있던 데이터와 로그를 **일괄적으로 하드디스크에 저장**합니다. 따라서 체크포인트 이전에 이미 커밋된 트랜잭션은 안전하게 저장된 상태이므로, **복구 시 다시 리두할 필요가 없어집니다**.

### 체크포인트 간격의 중요성

:::warning 체크포인트 간격 설정 주의
- **간격이 너무 짧으면**: 체크포인트 작업 중에는 다른 트랜잭션이 수행될 수 없으므로, 너무 자주 체크포인트를 수행하면 오히려 **시스템 성능이 크게 떨어집니다**. 마치 한글 프로그램에서 자동 저장 간격을 1분으로 설정하면 뭔가 하려고 할 때마다 저장이 걸려서 작업이 느려지는 것과 같습니다.
- **간격이 너무 길면**: 체크포인트 사이에 장애가 발생하면 그 사이의 모든 작업을 복구해야 하므로, **복구 시간이 길어집니다**.

따라서 시스템의 특성에 맞게 **최적의 간격**을 설정하는 것이 중요합니다.
:::

### 체크포인트의 수행 순서

체크포인트가 실행되면 다음 순서로 작업이 이루어집니다:

| 순서 | 작업 | 설명 |
|------|------|------|
| 1️⃣ | **로그 레코드 저장** | 메모리에 있는 로그 레코드를 먼저 하드디스크에 저장 (WAL 원칙) |
| 2️⃣ | **데이터 버퍼 블록 저장** | 일반 데이터를 하드디스크에 저장 |
| 3️⃣ | **체크포인트 정보 저장** | 체크포인트에 대한 로그 레코드를 마지막으로 저장 |

이 순서가 매우 중요합니다. 가장 먼저 로그 레코드를 저장하는 것은 앞서 배운 **WAL(로그 우선 기록 규약)** 을 따르는 것이고, 마지막에 체크포인트 정보를 저장하는 것은 "여기까지는 안전하게 저장됐다"라는 표시를 남기는 것입니다.

### 체크포인트 회복 알고리즘

체크포인트를 이용한 회복 알고리즘은 다음과 같이 동작합니다:

**1단계:** 빈 **언두(Undo) 리스트**와 **리두(Redo) 리스트**를 만듭니다.

**2단계:** 체크포인트 설정 당시에 **활동 중인(아직 완료되지 않은)** 트랜잭션을 모두 **언두 리스트**에 넣습니다.

**3단계:** 체크포인트 이후에 **새로 시작된(Start)** 트랜잭션도 모두 **언두 리스트**에 넣습니다.

**4단계:** 로그를 검색하면서, **커밋이 있는 트랜잭션**을 발견하면 언두 리스트에서 **삭제**하고 **리두 리스트**로 옮깁니다.

**5단계:** 회복 수행 — 언두 리스트의 트랜잭션은 **역방향(뒤에서 앞으로)** 으로 언두 연산을, 리두 리스트의 트랜잭션은 **순방향(앞에서 뒤로)** 으로 리두 연산을 수행합니다.

### 실전 예시로 이해하기

다음과 같은 5개의 트랜잭션이 있다고 가정합시다:

```
시간 흐름 →

T1: |----시작-------커밋----|
T2:      |----시작-----------|---------커밋----|
T3:            |----시작-----|----------------------------| (커밋 없음)
T4:                          |----시작-------커밋----|
T5:                          |--------시작----------------| (커밋 없음)
                             ↑                       ↑
                         체크포인트                에러 발생
```

**상황 정리:**
- `T1`: 체크포인트 **이전에** 커밋 완료
- `T2`: 체크포인트 이전에 시작, 체크포인트 **이후에** 커밋 완료
- `T3`: 체크포인트 이전에 시작, 커밋 **없음**
- `T4`: 체크포인트 이후에 시작, 체크포인트 **이후에** 커밋 완료
- `T5`: 체크포인트 이후에 시작, 커밋 **없음**

**알고리즘 적용 과정:**

**1단계 — 빈 리스트 생성:**
```
Undo 리스트: [ ]
Redo 리스트: [ ]
```

**2단계 — 체크포인트 당시 활동 중인 트랜잭션을 Undo에 추가:**

체크포인트 시점에 아직 완료되지 않고 활동 중인 트랜잭션은 `T2`와 `T3`입니다. (`T1`은 이미 커밋 완료)

```
Undo 리스트: [T2, T3]
Redo 리스트: [ ]
```

**3단계 — 체크포인트 이후 시작된 트랜잭션을 Undo에 추가:**

체크포인트 이후에 새로 시작된 트랜잭션은 `T4`와 `T5`입니다.

```
Undo 리스트: [T2, T3, T4, T5]
Redo 리스트: [ ]
```

**4단계 — 커밋이 있는 트랜잭션을 Redo로 이동:**

로그를 검색해보니 `T2`와 `T4`에 커밋이 있습니다. 이 둘을 Undo에서 빼서 Redo로 옮깁니다.

```
Undo 리스트: [T3, T5]       ← 커밋이 없는 트랜잭션
Redo 리스트: [T2, T4]       ← 커밋이 있는 트랜잭션
```

:::tip T1은 어디에도 없다!
여기서 주목할 점은 **T1이 Undo에도 Redo에도 없다**는 것입니다. T1은 체크포인트 **이전에** 이미 커밋이 완료되었기 때문에, 체크포인트 시점에 활동 중인 트랜잭션이 아닙니다. 따라서 **T1은 아무런 복구 작업도 수행할 필요가 없습니다**. 이것이 바로 체크포인트의 핵심 장점입니다!
:::

**최종 회복 결과:**

| 트랜잭션 | 처리 방법 | 범위 | 이유 |
|----------|-----------|------|------|
| **T1** | **아무 작업 없음** | - | 체크포인트 이전에 커밋 완료 |
| **T2** | **Redo** | 체크포인트 이후 부분만 | 체크포인트 이후에 커밋됨 |
| **T3** | **Undo** | 전체 | 커밋 없음, 전부 취소 |
| **T4** | **Redo** | 전체 | 체크포인트 이후 시작 & 커밋됨 |
| **T5** | **Undo** | 전체 | 커밋 없음, 전부 취소 |

> **체크포인트의 핵심**: 체크포인트가 없었다면 T1, T2, T4 모두 리두해야 했지만, 체크포인트 덕분에 **T1의 리두를 생략**할 수 있습니다. 데이터가 많을수록 이 효과는 더 커집니다.

:::note Undo와 Redo의 범위 차이
- **Undo 연산**: 체크포인트와 상관없이 트랜잭션 **전체**를 취소합니다. 왜냐하면 취소는 처음부터 없었던 것처럼 만들어야 하기 때문입니다.
- **Redo 연산**: 체크포인트 **이후 부분에 대해서만** 다시 실행합니다. 체크포인트 이전 부분은 이미 안전하게 저장되어 있으므로 다시 할 필요가 없기 때문입니다.
:::

---

## 🌑 그림자 페이징 (Shadow Paging) 기법

### 로그 없이 복구하는 방법

지금까지 배운 기법들은 모두 **로그(Log)** 를 이용해서 복구하는 방법이었습니다. 하지만 로그를 사용하지 않고도 복구할 수 있는 방법이 있는데, 그것이 바로 **그림자 페이징(Shadow Paging)** 기법입니다.

그림자 페이징은 **No-Undo / No-Redo 기법**입니다. 즉, 언두도 리두도 하지 않습니다. 로그를 이용하지 않기 때문에 로그를 만들고 관리하는 데 드는 비용을 절약할 수 있습니다.

### 두 개의 페이지 테이블

그림자 페이징에서는 **두 개의 페이지 테이블**이 필요합니다:

| 페이지 | 저장 위치 | 역할 |
|--------|-----------|------|
| **현재 페이지(Current Page)** | 메모리 | 실제 작업이 이루어지는 곳. 데이터가 변경됨 |
| **그림자 페이지(Shadow Page)** | 하드디스크 | 원본의 복사본. 변경되지 않고 그대로 유지 |

트랜잭션이 시작되면, 현재 페이지와 **동일한 내용의 그림자 페이지**를 만들어 놓습니다. 이후 모든 갱신 작업은 **현재 페이지에서만** 이루어지고, 그림자 페이지는 **절대 변경하지 않습니다**.

이것은 마치 **시험지를 복사해두고 원본에만 답을 적는 것**과 같습니다. 답을 잘못 적었으면 복사본을 꺼내서 다시 시작하면 되고, 잘 적었으면 복사본을 버리면 됩니다.

### 장애 발생 시 복구

구체적인 예시로 살펴보겠습니다:

```
데이터 원래 값: 100

현재 페이지 (메모리): 100
그림자 페이지 (하드디스크): 100
```

**시나리오 1 — 작업 중 장애 발생 (❌ 실패):**

```
# 100을 200으로 변경하는 작업 수행
현재 페이지: 100 → 200  (변경됨)
실제 데이터: 100 → 200  (변경 중)

# 💥 장애 발생! 커밋되지 않음

# 복구: 그림자 페이지의 값(100)을 가져와서 덮어쓰기
현재 페이지: 200 → 100  (복구됨)
실제 데이터: 200 → 100  (복구됨)
```

그림자 페이지에 원래 값 `100`이 그대로 남아 있으므로, 이것을 가져와서 덮어쓰면 간단하게 복구됩니다!

**시나리오 2 — 작업 성공 (✅ 커밋):**

```
# 100을 200으로 변경하는 작업 수행
현재 페이지: 100 → 200  (변경됨)
실제 데이터: 100 → 200  (변경됨)

# ✅ 커밋 성공!

# 그림자 페이지도 새 값으로 업데이트
그림자 페이지: 100 → 200  (동기화)
```

작업이 성공하면 그림자 페이지의 내용도 성공한 값으로 변경해줍니다.

### 그림자 페이징의 장단점

**장점:**
- **처리 속도가 매우 빠릅니다** — 로그를 기록하고 분석하는 과정이 없으므로 복구가 신속합니다
- **회복 작업이 매우 간단합니다** — 그림자 페이지를 가져와서 덮어쓰기만 하면 됩니다

**단점:**

| 단점 | 설명 |
|------|------|
| **저장 공간 필요** | 그림자 페이지를 위한 별도의 저장 공간이 필요합니다 |
| **쓰레기 데이터 발생** | 변경이 다른 위치에 기록되면 기존 페이지가 쓸모없는 쓰레기가 되어 **쓰레기 수집(Garbage Collection)** 이 필요합니다 |
| **데이터 단편화** | 페이지가 여기저기 흩어져 저장되면서 **단편화(Fragmentation)** 가 발생하여 전체 시스템 성능이 떨어질 수 있습니다 |
| **병행 처리 불가** ⚠️ | 가장 치명적인 단점입니다. 동시에 여러 사용자가 사용하는 **병행 처리(Concurrent Processing)를 지원할 수 없고**, 순차 처리만 가능합니다 |

:::danger 그림자 페이징의 치명적 한계
실제 데이터베이스는 동시에 수많은 사용자가 접속하여 병행으로 처리해야 합니다. 그림자 페이징은 **병행 처리를 지원하지 못하므로**, 실무에서 단독으로 사용되기 어렵습니다. 이 문제를 해결하기 위해 **로그 기반 기법과 그림자 페이징을 결합**하여 사용하는 방법도 있습니다.
:::

---

## 🔄 ARIES 기법

### 복구 중에 또 장애가 발생하면?

데이터베이스를 사용하다가 에러가 발생하면 로그를 이용해서 복구합니다. 그런데 **복구하는 도중에 또다시 에러가 발생**하면 어떻게 될까요?

예를 들어, 100만 줄의 로그를 처리해야 하는데 **90%를 복구한 시점**에서 또 에러가 나버렸다고 해봅시다. 남은 10%만 처리하면 되는데, 기존 방식으로는 **처음부터 다시 100%를 복구**해야 합니다. 이미 완료한 90%의 작업이 완전히 낭비되는 것이죠.

이것은 마치 **1000페이지짜리 책을 복사하다가 900페이지째에서 복사기가 고장났는데, 수리 후 1페이지부터 다시 복사해야 하는 것**과 같습니다. 매우 비효율적이죠.

### ARIES란?

**ARIES(Algorithm for Recovery and Isolation Exploiting Semantics)** 는 이런 문제를 해결하기 위해 만들어진 기법입니다. 핵심 아이디어는 간단합니다:

> **복구 작업을 수행하면서도 로그를 기록하여**, 복구 중에 다시 에러가 발생하면 **이미 복구된 부분은 건너뛰고 나머지만 처리**할 수 있게 하는 것입니다.

### ARIES의 핵심 원리

ARIES는 **반복 이력(Repeating History)** 이라는 개념을 사용합니다. 리두 연산이나 언두 연산을 수행할 때마다 그 작업 내역을 다시 로그에 기록하는 것입니다.

```
[기존 방식]
복구 90% 완료 → 에러 발생 → 처음부터 100% 다시 복구 😱

[ARIES 방식]
복구 90% 완료 (+ 복구 로그 기록) → 에러 발생 → 나머지 10%만 복구 😊
```

구체적으로 살펴보면:

- **리두 작업 중 로깅**: 커밋이 있는 트랜잭션을 리두할 때, "이 트랜잭션은 리두를 완료했다"는 기록을 남깁니다. 나중에 다시 복구할 때 이미 리두된 것은 건너뜁니다.
- **언두 작업 중 로깅**: 커밋이 없는 트랜잭션을 언두할 때도, "여기까지 취소했다"는 기록을 남깁니다. 예를 들어 90%를 취소한 상태에서 에러가 나면, 나머지 10%에 대해서만 언두를 수행하면 됩니다.

:::tip WAL은 여전히 기본 원칙
ARIES에서도 **WAL(Write-Ahead Logging)** 은 기본 원칙으로 적용됩니다. 로그를 먼저 기록하는 것은 어떤 경우에도 변하지 않는 원칙입니다.
:::

### ARIES의 3단계

ARIES 회복은 다음 **3단계**로 진행됩니다:

| 단계 | 이름 | 설명 |
|------|------|------|
| 1️⃣ | **분석(Analysis)** | 로그를 검사하여 어떤 트랜잭션이 활동 중인지, 커밋이 있는지 없는지, 무엇을 리두하고 무엇을 언두해야 하는지 파악 |
| 2️⃣ | **리두(Redo)** | 커밋이 있는 트랜잭션에 대해 리두 연산 수행 (이미 리두된 것은 건너뜀) |
| 3️⃣ | **언두(Undo)** | 커밋이 없는 트랜잭션에 대해 언두 연산 수행 (이미 언두된 것은 건너뜀) |

ARIES의 가장 큰 장점은 **복구 작업의 반복을 방지**하여 복구 시간을 크게 단축시킬 수 있다는 점입니다.

---

## 📊 데이터베이스 복구 알고리즘 비교

지금까지 배운 복구 기법들을 한눈에 정리해보겠습니다:

| 기법 | 언두(Undo) | 리두(Redo) | 기반 기법 | 특징 |
|------|:----------:|:----------:|-----------|------|
| **No-Undo / Redo** | ❌ 안 함 | ✅ 수행 | 지연 갱신 기법 | 아웃풋이 지연되어 있으므로 커밋 없는 건 취소할 필요 없음. 커밋된 것만 리두 |
| **Undo / No-Redo** | ✅ 수행 | ❌ 안 함 | 즉시 갱신 기법 (100% 저장 보장) | 100% 저장이 보장되므로 커밋된 것은 리두 불필요. 커밋 없는 것만 언두 |
| **Undo / Redo** | ✅ 수행 | ✅ 수행 | 즉시 갱신 기법 (일반) | 커밋 없는 건 언두, 커밋 있는 건 리두 |
| **No-Undo / No-Redo** | ❌ 안 함 | ❌ 안 함 | 그림자 페이징 기법 | 로그를 이용하지 않음. 그림자 페이지로 복구 |

```python
# 복구 알고리즘 의사 코드 (개념 이해용)

def recover_database(log_records, checkpoint):
    """
    데이터베이스 복구 알고리즘의 기본 흐름을 보여주는 의사 코드입니다.
    실제 구현은 DBMS마다 다르지만, 핵심 원리는 동일합니다.
    """

    undo_list = []  # 언두(취소)해야 할 트랜잭션 목록
    redo_list = []  # 리두(재실행)해야 할 트랜잭션 목록

    # 1단계: 체크포인트 당시 활동 중인 트랜잭션을 undo_list에 추가
    for txn in checkpoint.active_transactions:
        undo_list.append(txn)  # 활동 중이었으므로 일단 언두 대상

    # 2단계: 체크포인트 이후 시작된 트랜잭션도 undo_list에 추가
    for txn in get_started_after(checkpoint):
        undo_list.append(txn)  # 새로 시작된 것도 일단 언두 대상

    # 3단계: 로그를 검색하며 커밋된 트랜잭션을 redo_list로 이동
    for record in log_records:
        if record.type == "COMMIT":  # 커밋이 있으면
            undo_list.remove(record.txn)  # 언두 목록에서 제거
            redo_list.append(record.txn)  # 리두 목록에 추가

    # 4단계: 언두 수행 (역방향 - 뒤에서 앞으로)
    for txn in reversed(undo_list):
        perform_undo(txn)  # 트랜잭션의 작업을 취소

    # 5단계: 리두 수행 (순방향 - 앞에서 뒤로)
    for txn in redo_list:
        perform_redo(txn)  # 트랜잭션의 작업을 재실행
```

위 코드는 실제 구현이 아닌 **개념 이해를 위한 의사 코드(pseudocode)** 입니다. 각 줄의 의미를 자세히 살펴보겠습니다:

- `undo_list = []` — 빈 언두 리스트를 생성합니다. 여기에는 커밋이 없어서 취소해야 할 트랜잭션이 들어갑니다.
- `redo_list = []` — 빈 리두 리스트를 생성합니다. 여기에는 커밋이 있어서 다시 실행해야 할 트랜잭션이 들어갑니다.
- `checkpoint.active_transactions` — 체크포인트 시점에 아직 완료되지 않고 활동 중이던 트랜잭션들입니다.
- `get_started_after(checkpoint)` — 체크포인트 이후에 새로 시작된 트랜잭션들을 가져옵니다.
- `record.type == "COMMIT"` — 로그 레코드를 하나씩 읽으면서 커밋 기록이 있는지 확인합니다.
- `reversed(undo_list)` — 언두는 역방향(최근 작업부터 과거로)으로 수행합니다.
- `perform_redo(txn)` — 리두는 순방향(과거에서 최근으로)으로 수행합니다.

---

## 🏢 백업 센터의 종류

### 왜 백업 센터가 필요한가?

지금까지 배운 모든 복구 기법은 **덤프(백업)** 가 있어야 동작합니다. 덤프를 기반으로 로그를 적용하여 복구하는 것이죠. 그렇다면 이 백업을 **어떤 주기로, 어떤 수준으로** 관리할 것인가도 중요한 문제입니다.

여러분의 개인 컴퓨터를 생각해보세요. 정말 중요한 논문이나 프로젝트 파일이라면 매일매일 USB나 클라우드에 백업하겠지만, 단순 메모 파일이라면 6개월에 한 번 정도만 백업해도 되겠죠. **데이터의 가치와 비용을 고려하여** 백업 전략을 결정해야 합니다.

기업 수준에서는 백업 센터를 운영하는데, 그 수준에 따라 네 가지로 분류합니다:

### 네 가지 백업 센터 유형

| 유형 | 복구 시간 | 비용 | 특징 |
|------|-----------|------|------|
| **미러 사이트 (Mirror Site)** | **즉시** | 💰💰💰💰 가장 높음 | 운영 센터와 동일한 장비로 실시간 동기화. 장애 발생 시 즉각 대처 |
| **핫 사이트 (Hot Site)** | **수 시간 이내** | 💰💰💰 높음 | 운영 센터와 유사한 수준. 100% 동일하진 않지만 빠른 복구 가능 |
| **웜 사이트 (Warm Site)** | **수 일** | 💰💰 보통 | 별도 백업 센터에 데이터를 따로 보관. 데이터를 가져와야 하므로 시간 소요 |
| **콜드 사이트 (Cold Site)** | **수 주 ~ 한 달** | 💰 가장 낮음 | 최소한의 기본 시설만 갖춤. 가장 저렴하지만 복구 시간이 가장 김 |

**미러 사이트**는 이름 그대로 **거울(Mirror)** 처럼 운영 센터와 완벽히 동일한 상태를 실시간으로 유지합니다. 은행, 증권사, 주식 거래 시스템 등 **1초의 데이터 손실도 허용할 수 없는** 곳에서 사용합니다. 이중화(Redundancy)와 핫 스와핑(Hot Swapping) 기술을 통해 장애가 발생해도 사용자가 느끼지 못할 정도로 빠르게 전환됩니다.

**핫 사이트**는 미러 사이트처럼 100% 실시간 동기화는 아니지만, 상당히 높은 수준으로 준비되어 있어 **몇 시간 이내에 복구**가 가능합니다. 웹 서비스 서버가 다운됐다가 몇 시간 만에 복구되는 경우가 이에 해당합니다.

**웜 사이트**는 별도의 백업 센터에 데이터를 정기적으로 옮겨놓는 방식입니다. 데이터를 물리적으로 가져와야 하므로 **며칠** 정도 복구 시간이 걸립니다. "우리 서비스는 며칠 정도 중단돼도 괜찮다"라는 판단이 가능한 경우에 선택합니다.

**콜드 사이트**는 최소한의 기본 시설만 갖춰놓은 것으로, 장비를 새로 설치하고 데이터를 복원해야 하므로 **한 달 정도** 걸릴 수 있습니다. 비용은 가장 적게 들지만 복구 시간이 가장 깁니다.

:::tip 어떤 백업 센터를 선택할 것인가?
백업 센터의 선택은 **비용(Cost)과 비즈니스 가치(Business Value)의 균형**에 달려 있습니다. 실시간으로 중요한 금융 데이터라면 미러 사이트가 필수이고, 개인 블로그 수준이라면 콜드 사이트로도 충분합니다. 핵심은 **"우리 서비스가 중단되면 얼마나 큰 손해가 발생하는가?"** 를 기준으로 판단하는 것입니다.
:::

---

## 📌 핵심 정리

- **로그 레코드 버퍼링**: 로그를 매번 저장하지 않고 메모리에 모아놨다가 한꺼번에 저장하여 I/O 횟수를 줄이고 성능을 향상시키는 기법
- **WAL(Write-Ahead Logging, 로그 우선 기록 규약)**: 일반 데이터보다 **로그를 반드시 먼저** 하드디스크에 저장해야 한다는 규약. 복구 가능성을 보장
- **체크포인트(Checkpoint)**: 일정 간격으로 데이터를 저장하여, 체크포인트 이전에 커밋된 트랜잭션은 **리두를 생략**할 수 있게 하는 기법
- **체크포인트 수행 순서**: 로그 레코드 저장 → 데이터 버퍼 블록 저장 → 체크포인트 정보 저장
- **체크포인트 회복**: 체크포인트 이전 커밋된 트랜잭션은 아무 작업 없음, 이후 커밋된 것은 리두, 커밋 없는 것은 언두
- **그림자 페이징(Shadow Paging)**: 로그 없이 현재 페이지와 그림자 페이지 두 개를 이용하여 복구하는 No-Undo/No-Redo 기법. 빠르지만 **병행 처리 불가**
- **ARIES**: 복구 중 재장애 발생 시 이미 완료된 복구 작업을 반복하지 않도록 로깅하여 복구 시간을 단축하는 기법 (분석 → 리두 → 언두 3단계)
- **복구 알고리즘 4가지**: No-Undo/Redo(지연 갱신), Undo/No-Redo(즉시 갱신-완전 보장), Undo/Redo(즉시 갱신-일반), No-Undo/No-Redo(그림자 페이징)
- **백업 센터**: 미러 사이트(즉시) > 핫 사이트(수 시간) > 웜 사이트(수 일) > 콜드 사이트(수 주) 순으로 복구 속도와 비용이 비례

작성일: 2026-02-21