---
title: "회복 기법 기본 개념 복습: 덤프, 로그, 지연갱신과 즉시갱신"
description: "회복 기법 기본 개념 복습: 덤프, 로그, 지연갱신과 즉시갱신에 대해 초보자도 쉽게 이해할 수 있도록 설명합니다."
slug: "/advanced-recovery-techniques/1-recovery-basics-review"
sidebar_label: "회복 기본 복습"
date: "2026-02-21"
---

## 🎯 이 문서에서 다루는 내용

데이터베이스를 운영하다 보면 예기치 못한 장애(정전, 시스템 충돌, 디스크 고장 등)가 발생할 수 있습니다. 이럴 때 데이터를 **원래 상태로 되돌리는 작업**을 **회복(Recovery)**이라고 합니다. 이번 문서에서는 데이터베이스 고급 회복 기법의 핵심 개념들을 초보자도 이해할 수 있도록 하나하나 풀어서 설명합니다.

이전 시간에 배웠던 **덤프(백업)**, **로그**, **지연갱신 기법**, **즉시갱신 기법**의 기본 복습부터 시작하여, **로그 레코드 버퍼링**, **로그 우선 기록 규약(WAL)**, **체크포인트**, **그림자 페이징**, **ARIES 기법**, 그리고 **백업 센터 운영 방식**까지 폭넓게 다룹니다.

> **핵심 한 줄 요약:** 데이터베이스는 덤프(백업)를 기본으로 두고, 로그를 이용해 복구하며, 성능을 높이기 위해 버퍼링·체크포인트·그림자 페이징 같은 고급 기법을 활용합니다.

---

## 📚 기본 개념 복습: 덤프, 로그, 리두와 언두

### 덤프(Dump)란?

**덤프**는 쉽게 말해 **데이터베이스 전체를 통째로 복사해 두는 것**입니다. 마치 여러분이 중요한 문서를 USB에 백업해 두는 것과 같습니다. 특정 시점의 데이터베이스 상태를 안전한 저장 장치에 그대로 저장해 놓으면, 나중에 문제가 생겼을 때 이 덤프 파일을 기반으로 복구를 시작할 수 있습니다.

### 로그(Log)란?

**로그**는 데이터베이스에서 일어나는 **모든 변경 작업을 기록한 일지**입니다. 마치 은행에서 모든 입출금 내역을 장부에 기록하는 것과 같습니다. 트랜잭션(작업 묶음)이 수행될 때마다, "어떤 데이터를", "이전 값에서", "새로운 값으로" 변경했는지를 한 줄씩 기록합니다.

예를 들어, 변수 X의 값을 100에서 200으로 변경하면 로그에 다음과 같이 기록됩니다:

```
[T1, X, 100, 200]  ← 트랜잭션 T1이 X를 100에서 200으로 변경
```

만약 처리해야 할 데이터가 **1만 개**라면, 로그 파일에도 **최소 1만 줄**이 생성됩니다. 하나의 작업마다 한 줄씩 쌓이기 때문입니다.

### 리두(Redo)와 언두(Undo)

로그를 이용한 복구에서 핵심이 되는 두 가지 연산입니다.

| 연산 | 의미 | 적용 조건 | 비유 |
|------|------|-----------|------|
| **리두(Redo)** | 작업을 **다시 수행**하는 것 | 커밋(완료)이 있는 트랜잭션 | 시험 답안지를 다시 깨끗하게 베끼는 것 |
| **언두(Undo)** | 작업을 **취소**하는 것 | 커밋이 없는 트랜잭션 | 잘못 쓴 답안을 지우개로 지우는 것 |

> **커밋(Commit)**이란 "이 작업은 성공적으로 완료되었습니다"라고 확정 짓는 것입니다. 커밋이 있으면 → 리두(다시 반영), 커밋이 없으면 → 언두(원래대로 되돌림).

### 지연갱신 기법과 즉시갱신 기법

이전 시간에 배운 두 가지 로그 활용 방법을 간단히 복습합니다.

| 기법 | 핵심 아이디어 | 복구 방식 |
|------|--------------|-----------|
| **지연갱신 기법** | 커밋 전까지 실제 디스크에 저장하지 않고 **미룸** | 커밋 없는 건 아무 작업 불필요, 커밋 있는 건 리두만 수행 (**No-Undo/Redo**) |
| **즉시갱신 기법** | 작업 중간에도 실제 디스크에 **바로 반영** | 커밋 없는 건 언두, 커밋 있는 건 리두 수행 (**Undo/Redo**) |

:::info 지연갱신 vs 즉시갱신, 쉬운 비유
**지연갱신**은 마치 시험지에 연필로 먼저 다 풀어보고, 확실할 때 볼펜으로 정서하는 방식입니다. 연필로 쓴 건 틀려도 지우면 그만이니까요.
**즉시갱신**은 처음부터 볼펜으로 바로 쓰는 방식입니다. 틀리면 수정 테이프로 힘들게 지워야 합니다.
:::

---

## 🧠 로그 레코드 버퍼링: 왜 매번 저장하면 안 되는가

### 문제 상황: 매번 저장하면 성능이 무너진다

로그 파일은 트랜잭션이 작업을 수행할 때마다 한 줄씩 생성됩니다. 그런데 매번 로그가 한 줄 생길 때마다 바로 하드디스크에 저장한다면 어떻게 될까요?

처리해야 할 데이터가 1만 개라면, 로그도 1만 줄이 생기고, **하드디스크에 1만 번 저장(아웃풋)**을 해야 합니다. 하나 처리하고 저장, 하나 처리하고 저장, 하나 처리하고 저장... 이것은 엄청난 성능 저하를 가져옵니다.

:::warning 왜 I/O가 느린가?
컴퓨터에서 **하드디스크에 데이터를 읽고 쓰는 작업(I/O 연산)**은 메모리에서 처리하는 것보다 **수백~수천 배** 느립니다. 마치 집 앞 편의점에서 물건을 사는 것(메모리)과 해외에서 직구하는 것(하드디스크 I/O)의 속도 차이와 비슷합니다.
:::

### 엑셀로 이해하는 버퍼링

여러분이 엑셀에서 1만 개의 숫자를 더하는 작업을 한다고 상상해 보세요.

```
❌ 잘못된 방식:
숫자 하나 더하고 → 파일 저장
숫자 하나 더하고 → 파일 저장
숫자 하나 더하고 → 파일 저장
... (1만 번 반복)
```

```
✅ 올바른 방식:
숫자 1만 개를 한꺼번에 다 더한 다음 → 마지막에 한 번만 파일 저장
```

당연히 후자가 훨씬 빠르죠? 1만 번 저장하는 대신 **1번만 저장**하면 되니까요. 이 원리가 바로 **로그 레코드 버퍼링(Log Record Buffering)**입니다.

### 로그 레코드 버퍼링의 원리

**로그 레코드 버퍼링**이란, 로그 레코드를 생성할 때마다 바로 하드디스크에 저장하지 않고, **메모리(버퍼)에 모아두었다가 나중에 한꺼번에 저장**하는 방식입니다.

컴퓨터의 데이터 처리 흐름을 정리하면 다음과 같습니다:

```
하드디스크 → [인풋(Input)] → 메모리 → [리드(Read)] → CPU
CPU → [라이트(Write)] → 메모리 → [아웃풋(Output)] → 하드디스크
```

- **인풋(Input):** 하드디스크에서 메모리로 데이터를 가져오는 것
- **리드(Read):** 메모리에서 CPU로 데이터를 읽어오는 것
- **라이트(Write):** CPU에서 처리한 결과를 메모리에 쓰는 것
- **아웃풋(Output):** 메모리에서 하드디스크로 데이터를 최종 저장하는 것

로그 레코드 버퍼링에서는 라이트(Write)까지는 계속 수행하되, **아웃풋(Output)은 마지막에 한꺼번에** 처리합니다. 이렇게 하면 I/O 횟수를 대폭 줄일 수 있어서 **데이터베이스 성능이 크게 향상**됩니다.

```
[메모리]
├── 처리해야 할 일반 데이터 (버퍼에 쌓여 있음)
└── 로그 레코드 (버퍼에 쌓여 있음)

→ 나중에 한꺼번에 하드디스크로 아웃풋!
```

:::note 핵심 정리
로그 레코드 버퍼링 = 로그를 메모리에 모아두었다가 한꺼번에 저장하는 방식. **I/O 횟수를 줄여서 성능을 높이는 것**이 목적입니다.
:::

---

## 📝 로그 우선 기록 규약(WAL): 무엇을 먼저 저장해야 하는가

### 문제의 핵심: 데이터와 로그, 누가 먼저?

로그 레코드 버퍼링 덕분에 메모리에는 두 종류의 데이터가 함께 머물고 있습니다:

1. **일반 데이터** (실제 처리 결과)
2. **로그 데이터** (변경 이력)

이 둘을 하드디스크로 저장(아웃풋)해야 하는데, **동시에 저장할 수는 없습니다**. 하드디스크는 하나이기 때문에 동시에 두 가지를 저장하면 충돌이 생깁니다. 따라서 **순서를 정해야** 합니다.

### 시나리오 분석: 왜 로그를 먼저 저장해야 하는가

#### ❌ 시나리오 1: 일반 데이터를 먼저 저장하는 경우

```
1단계: 일반 데이터 저장 ✅ (성공)
2단계: 로그 저장 ❌ (도중에 에러 발생!)

결과: 데이터는 저장됐지만 로그가 없음
→ 나중에 복구하려 해도 로그가 없어서 복구 불가능! 😱
```

일반 데이터를 먼저 저장하면, 로그 저장 중 에러가 발생했을 때 **로그가 없기 때문에 복구 자체가 불가능**해지는 치명적인 문제가 생깁니다.

#### ✅ 시나리오 2: 로그를 먼저 저장하는 경우

**경우 A:** 로그 저장 중 에러 발생

```
1단계: 로그 저장 ❌ (도중에 에러 발생!)
2단계: 데이터 저장 (실행 안 됨)

결과: 로그도 없고, 데이터도 저장 안 됨
→ 아무 작업도 안 한 것과 같음. 복구에 문제 없음! ✅
```

**경우 B:** 로그 저장 성공, 데이터 저장 중 에러 발생

```
1단계: 로그 저장 ✅ (성공)
2단계: 데이터 저장 ❌ (도중에 에러 발생!)

결과: 로그는 있고, 데이터는 저장 안 됨
→ 마지막 덤프 + 로그를 이용해서 복구 가능! ✅
```

**경우 C:** 둘 다 성공

```
1단계: 로그 저장 ✅ (성공)
2단계: 데이터 저장 ✅ (성공)

결과: 모든 것이 정상. 문제 없음! ✅
```

### WAL(Write-Ahead Logging) 규약

이 원리를 공식적으로 **WAL(Write-Ahead Logging)**, 한국어로 **로그 우선 기록 규약**이라고 합니다.

> **WAL 규약:** 일반 데이터와 로그 데이터가 모두 메모리에 있을 때, **반드시 로그를 먼저 하드디스크에 저장**하고, 그 다음에 일반 데이터를 저장해야 한다.

이것은 마치 건물을 지을 때 **설계도(로그)를 먼저 안전하게 보관**한 다음 실제 건축(데이터 저장)을 시작하는 것과 같습니다. 설계도가 있으면 건물이 무너져도 다시 지을 수 있지만, 설계도 없이 건물만 짓다가 무너지면 처음부터 다시 해야 합니다.

```sql
-- WAL 규약을 의사 코드로 표현하면:

-- 1단계: 로그 레코드를 먼저 안전한 저장 장치에 저장
FLUSH log_buffer TO disk;  -- 로그를 하드디스크로 먼저 아웃풋

-- 2단계: 그 다음에 일반 데이터를 저장
FLUSH data_buffer TO disk; -- 데이터를 하드디스크로 아웃풋
```

:::tip WAL을 한 마디로
"**로그 먼저, 데이터 나중!**" — 이것이 데이터베이스가 **원자성(Atomicity)**을 지키기 위한 기본 원칙입니다.
:::

---

## ✅ 체크포인트(Checkpoint): 불필요한 리두를 줄이는 기술

### 왜 체크포인트가 필요한가?

로그를 이용한 복구에는 치명적인 **성능 문제**가 있습니다. 로그 파일은 **처음부터 끝까지 순차적으로 읽어야** 합니다. 만약 100만 개의 레코드를 처리했다면 로그 파일은 100만 줄이 되고, 복구할 때 이 100만 줄을 **처음부터 끝까지 전부 읽으면서** 리두와 언두를 수행해야 합니다.

그런데 여기서 문제가 있습니다. **이미 안전하게 하드디스크에 저장이 완료된 트랜잭션**도 다시 리두를 해야 한다는 것입니다. 이미 저장 끝난 데이터를 또 처리하는 것은 명백한 시간 낭비입니다.

> 마치 시험이 끝나고 이미 제출한 답안지를 다시 꺼내서 한 번 더 베끼는 것처럼, 아무 의미 없는 반복 작업이 됩니다.

이 문제를 해결하기 위한 것이 바로 **체크포인트(Checkpoint, 검사점)**입니다.

### 체크포인트 = 자동 저장 기능

체크포인트는 여러분이 이미 실생활에서 사용하고 있는 개념입니다. **아래아 한글(HWP)이나 워드프로세서의 "자동 저장" 기능**이 바로 체크포인트와 같은 원리입니다.

아래아 한글 설정에 가면 "자동 저장 간격"을 설정할 수 있죠? 예를 들어 10분으로 설정하면, 10분마다 알아서 하드디스크에 저장합니다. 이것이 체크포인트입니다.

:::warning 체크포인트 간격 설정 주의
- **간격이 너무 짧으면:** 수시로 저장이 일어나서 작업 중 컴퓨터가 느려집니다. 실제로 아래아 한글의 자동 저장 간격을 1분으로 설정했더니 문서 작업이 불가능할 정도로 성능이 떨어진 사례가 있습니다.
- **간격이 너무 길면:** 저장 사이에 에러가 발생하면 그 긴 시간 동안의 작업을 전부 복구해야 합니다.
- **적절한 간격을 찾는 것이 중요합니다.** (예: 20분, 30분 등 시스템에 맞게 설정)
:::

### 체크포인트의 동작 순서

체크포인트 시점이 되면, 다음 **세 단계**가 순서대로 수행됩니다. 이 순서는 매우 중요합니다:

| 순서 | 작업 | 이유 |
|------|------|------|
| **1단계** | 메모리의 **로그 레코드**를 하드디스크로 저장 | WAL 규약에 따라 로그가 항상 먼저 |
| **2단계** | 메모리의 **일반 데이터(버퍼 블록)**를 하드디스크로 저장 | 로그 다음에 데이터 저장 |
| **3단계** | **체크포인트 정보**(체크포인트 로그 레코드)를 하드디스크로 저장 | 어디까지 저장했는지 표시 |

:::note 왜 체크포인트 정보를 마지막에 저장하나요?
체크포인트 정보는 "여기까지는 안전하게 저장 완료"라는 **도장**과 같습니다. 로그와 데이터가 모두 안전하게 저장된 후에야 비로소 이 도장을 찍을 수 있습니다. 만약 데이터가 저장되기 전에 도장을 먼저 찍어버리면, 실제로는 저장이 안 됐는데 저장된 것으로 착각하는 문제가 생깁니다.
:::

### 체크포인트 회복 알고리즘 상세 설명

체크포인트를 이용한 회복은 다음과 같은 절차를 따릅니다:

```
1. 빈 Undo 리스트와 빈 Redo 리스트를 만든다
2. 체크포인트 설정 당시에 활동 중인 트랜잭션을 → Undo 리스트에 넣는다
3. 체크포인트 이후에 새로 시작(Start)된 트랜잭션도 → Undo 리스트에 넣는다
4. 로그를 검색하면서, 커밋이 있는 트랜잭션은 → Undo에서 빼서 Redo로 옮긴다
5. 회복 수행: Undo 리스트는 역방향으로 언두, Redo 리스트는 순방향으로 리두
```

핵심은 이것입니다: **체크포인트 이전에 이미 커밋된 트랜잭션은 Undo에도 Redo에도 들어가지 않습니다.** 즉, **아무 작업도 하지 않습니다!** 이것이 체크포인트의 가장 큰 장점입니다.

### 🔍 구체적 예시로 완전 이해하기

다음과 같이 5개의 트랜잭션이 있다고 가정합니다:

```
시간 흐름 →→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→

T1: |---Start---Commit---|
T2:       |---Start-----------Commit---|
T3:            |---Start------------------------| (커밋 없음)
T4:                          |---Start---Commit---|
T5:                               |---Start-----------| (커밋 없음)

                    ↑                          ↑
               체크포인트                     에러 발생
```

**상황 정리:**
- **T1:** 체크포인트 **이전에** 이미 커밋 완료
- **T2:** 체크포인트 당시 활동 중, 체크포인트 **이후에** 커밋
- **T3:** 체크포인트 당시 활동 중, 커밋 **없음**
- **T4:** 체크포인트 **이후에** 시작, 체크포인트 이후에 커밋
- **T5:** 체크포인트 **이후에** 시작, 커밋 **없음**

**알고리즘 적용 과정:**

**1단계:** 빈 Undo 리스트와 Redo 리스트 생성

```
Undo: [ ]
Redo: [ ]
```

**2단계:** 체크포인트 당시 활동 중인 트랜잭션 → Undo에 넣기
- T2 (활동 중), T3 (활동 중)

```
Undo: [T2, T3]
Redo: [ ]
```

**3단계:** 체크포인트 이후 새로 시작된 트랜잭션 → Undo에 넣기
- T4 (새로 시작), T5 (새로 시작)

```
Undo: [T2, T3, T4, T5]
Redo: [ ]
```

**4단계:** 로그를 검색하며 커밋이 있는 것 → Undo에서 빼서 Redo로 옮기기
- T2 (커밋 있음) → Redo로 이동
- T4 (커밋 있음) → Redo로 이동

```
Undo: [T3, T5]       ← 커밋이 없는 트랜잭션
Redo: [T2, T4]       ← 커밋이 있는 트랜잭션
```

**그런데 T1은 어디에도 없습니다!**

T1은 체크포인트 이전에 이미 커밋되었기 때문에, 2단계에서 "활동 중"이 아니었고, 3단계에서 "새로 시작"도 아니었습니다. 따라서 **T1은 Undo도 Redo도 수행하지 않습니다.**

:::tip 체크포인트의 핵심 가치
만약 체크포인트가 없었다면? T1, T2, T4 모두 리두 대상이 됩니다(총 3개). 하지만 체크포인트 덕분에 T1은 리두하지 않아도 되므로 리두 대상이 T2, T4(총 2개)로 줄어듭니다. 실제 운영 환경에서는 이런 **불필요한 리두 연산이 수만~수십만 건** 줄어들 수 있어서 복구 시간이 획기적으로 단축됩니다.
:::

**5단계:** 회복 수행

| 트랜잭션 | 수행할 연산 | 범위 |
|----------|------------|------|
| **T1** | **아무것도 안 함** | - (체크포인트 이전에 커밋 완료) |
| **T2** | **Redo** | 체크포인트 이후 부분만 |
| **T3** | **Undo** | 전체 (커밋이 없으므로 전부 취소) |
| **T4** | **Redo** | 전체 (체크포인트 이후에 시작되었으므로 전체가 리두 대상) |
| **T5** | **Undo** | 전체 (커밋이 없으므로 전부 취소) |

> **기억하세요:** 체크포인트 이전에 커밋된 트랜잭션은 아무 작업도 수행하지 않는다! 이것이 체크포인트의 **가장 중요한 특징**입니다.

---

## 🌓 그림자 페이징(Shadow Paging): 로그 없이 복구하기

### 왜 그림자 페이징이 필요한가?

지금까지 살펴본 모든 회복 기법은 **로그를 이용**합니다. 로그 기록, 로그 저장, 로그 검색... 이 모든 과정에는 비용(시간과 저장 공간)이 들어갑니다. 그렇다면 **로그를 아예 사용하지 않고도** 복구할 수 있는 방법은 없을까요?

그것이 바로 **그림자 페이징(Shadow Paging)** 기법입니다. 그림자 페이징은 **No-Undo/No-Redo** 기법으로, 언두도 리두도 필요 없습니다.

### 그림자 페이징의 원리

그림자 페이징은 **두 개의 페이지**를 사용합니다:

| 페이지 | 저장 위치 | 역할 |
|--------|----------|------|
| **현재 페이지(Current Page)** | **메모리** | 실제 작업이 이루어지는 곳 |
| **그림자 페이지(Shadow Page)** | **하드디스크** | 원본 데이터의 사본(백업) |

마치 **원본 문서는 금고(하드디스크)에 보관하고, 복사본(메모리)으로 작업하는 것**과 같습니다.

### 동작 과정 상세 설명

**초기 상태:**

```
실제 데이터: 100
현재 페이지 (메모리): 100
그림자 페이지 (하드디스크): 100   ← 둘 다 동일한 값
```

트랜잭션이 시작되면, 현재 페이지와 동일한 그림자 페이지를 먼저 만들어 놓습니다.

**작업 수행 중:**

```
데이터를 100 → 200으로 변경하는 작업 수행

실제 데이터: 200 (변경됨)
현재 페이지 (메모리): 200 (변경됨)
그림자 페이지 (하드디스크): 100  ← 변경하지 않음! 원본 그대로!
```

핵심은 **그림자 페이지는 절대 변경하지 않는다**는 것입니다. 모든 작업은 현재 페이지에서만 이루어집니다.

#### ❌ 장애 발생 시 (커밋 전에 에러)

```
현재 페이지 (메모리): 200 ← 이건 날아감 (메모리는 휘발성)
그림자 페이지 (하드디스크): 100 ← 이게 살아있음!

복구 방법: 그림자 페이지(100)를 가져와서 덮어쓰면 끝!
결과: 데이터가 원래 값 100으로 복구됨 ✅
```

#### ✅ 성공적으로 완료 시 (커밋 성공)

```
현재 페이지 (메모리): 200 ← 성공적으로 완료
그림자 페이지 (하드디스크): 100 → 200으로 업데이트

결과: 그림자 페이지도 새로운 값(200)으로 갱신 ✅
```

:::info 그림자 페이징을 실생활로 비유하면
원본 서류는 금고에 넣어두고, **복사본으로 작업**합니다. 작업하다가 실수하면? 금고에서 원본을 꺼내면 됩니다. 작업이 성공하면? 작업 결과를 새로운 원본으로 금고에 넣습니다.
:::

### 그림자 페이징의 장점과 단점

**장점:**
- 로그를 사용하지 않으므로 **로그 관련 비용이 없음**
- 복구가 매우 **빠름** (그림자 페이지를 그냥 덮어쓰면 끝)
- 취소(Undo)도 간단 (그림자를 가져와서 덮어쓰면 됨)

**단점:**

| 단점 | 설명 |
|------|------|
| **추가 저장 공간 필요** | 그림자 페이지를 별도로 저장해야 하므로 디스크 공간이 더 필요합니다 |
| **쓰레기 데이터 발생** | 페이지가 다른 곳에 갱신되면 기존 페이지가 쓰레기가 되어 가비지 컬렉션이 필요합니다 |
| **데이터 단편화** | 페이지를 이곳저곳에 쓰다 보면 데이터가 조각나서 전체 시스템 성능이 떨어질 수 있습니다 |
| **🚨 병행 처리 불가** | **가장 치명적인 단점!** 동시에 여러 사용자가 사용하는 병행 처리를 지원할 수 없고, 순차 처리만 가능합니다 |

:::danger 그림자 페이징의 가장 큰 한계
실제 데이터베이스는 동시에 수많은 사용자가 접속하여 병행 처리를 합니다. 그림자 페이징은 **병행 처리를 지원하지 못하기 때문에**, 단독으로 사용하기 어렵습니다. 실무에서는 로그 기법과 그림자 페이징을 **조합하여** 사용하기도 합니다.
:::

---

## 🔄 ARIES 기법: 복구 중 또 에러가 나면?

### 복구 중에 또 장애가 발생하는 시나리오

데이터베이스에 에러가 발생하면 로그를 이용해 복구합니다. 그런데 만약 **복구하는 도중에 또 에러가 발생**하면 어떻게 될까요?

예를 들어 볼게요:

```
1. 데이터베이스 운영 중 에러 발생!
2. 복구 시작: 100만 줄의 로그를 처리해야 함
3. 90만 줄 처리 완료 (90% 복구 완료)
4. 💥 복구 중에 또 에러 발생!
5. 기존 방식: 처음부터 다시 100만 줄 전부 처리해야 함 😢
```

90%나 복구했는데, 나머지 10%만 하면 되는 상황에서 **처음부터 다시 100%를 해야 한다**니, 엄청나게 비효율적이지 않나요? 마치 게임에서 보스 방 앞까지 갔는데 세이브를 안 해서 처음부터 다시 하는 것과 같습니다.

### ARIES가 해결하는 문제

**ARIES(Algorithm for Recovery and Isolation Exploiting Semantics)**는 이 문제를 해결합니다. 핵심 아이디어는 간단합니다:

> **복구 작업 자체도 로그로 기록하자!** 그래서 복구 중 에러가 발생하면, 이미 완료된 복구 작업은 건너뛰고 **나머지만 수행**하자.

이것을 **반복 이력(Repeating History)**이라고 합니다.

### ARIES의 동작 원리

```
복구 작업 수행 중:
├── 리두(Redo) 작업 수행 시 → 리두했다는 것을 로그로 기록
├── 언두(Undo) 작업 수행 시 → 언두했다는 것을 로그로 기록
└── 복구 중 에러 발생 시 → 이미 기록된 로그를 참고하여 나머지만 수행
```

**구체적 예시:**

```
❌ ARIES 없이 (기존 방식):
1. 100만 줄 중 90만 줄 언두 완료
2. 에러 발생!
3. 다시 100만 줄 처음부터 언두 시작... (90만 줄 반복 낭비)

✅ ARIES 적용:
1. 100만 줄 중 90만 줄 언두 완료 (매번 "여기까지 했다"고 로그 기록)
2. 에러 발생!
3. 로그를 확인: "아, 90만 줄까지 완료했구나"
4. 나머지 10만 줄만 언두 수행! (90만 줄 절약 🎉)
```

### ARIES의 3단계

ARIES는 크게 **3단계**로 동작합니다:

| 단계 | 이름 | 설명 |
|------|------|------|
| **1단계** | **분석(Analysis)** | 로그를 검색하여 어떤 트랜잭션이 활동 중이었는지, 커밋이 있는지 없는지, 무엇을 리두/언두해야 하는지 파악합니다 |
| **2단계** | **리두(Redo)** | 커밋이 있는 트랜잭션에 대해 리두 연산을 수행합니다. 이때 리두 작업도 로그로 기록합니다 |
| **3단계** | **언두(Undo)** | 커밋이 없는 트랜잭션에 대해 언두 연산을 수행합니다. 이때 언두 작업도 로그로 기록합니다 |

:::tip ARIES의 핵심 원칙들
1. **WAL(Write-Ahead Logging):** 로그를 항상 먼저 기록합니다 (기본 원칙)
2. **리두 시에도 로깅:** 리두 작업을 수행할 때도 로그를 기록합니다
3. **언두 시에도 로깅:** 언두 작업을 수행할 때도 로그를 기록합니다
4. **이미 완료된 작업은 반복하지 않음:** 복구 중 에러가 발생해도 처음부터 다시 하지 않습니다
:::

---

## 🏢 백업 센터 운영 방식: 미러 사이트부터 콜드 사이트까지

### 덤프의 본질 = 백업(Backup)

지금까지 배운 덤프(Dump)는 한마디로 **백업**입니다. 그런데 이 백업을 **얼마나 자주, 어떤 수준으로** 할 것인가에 따라 복구 능력과 비용이 크게 달라집니다.

여러분의 개인 컴퓨터를 생각해 보세요. 매일 백업하시나요? 한 달에 한 번? 1년에 한 번? 아니면 컴퓨터를 교체할 때만? 데이터의 **중요도**와 **비용**에 따라 백업 전략이 달라지는 것처럼, 기업의 데이터베이스도 마찬가지입니다.

### 4가지 백업 센터 유형

기업에서 데이터베이스를 운영할 때, 장애에 대비하여 **백업 센터**를 운영합니다. 백업 센터의 수준은 다음 4가지로 구분됩니다:

| 유형 | 복구 시간 | 장비 수준 | 비용 | 특징 |
|------|----------|----------|------|------|
| 🔴 **미러 사이트(Mirror Site)** | **즉시** | 운영 센터와 100% 동일 | 💰💰💰💰 가장 비쌈 | 실시간 동기식 백업, 핫 스와핑 가능 |
| 🟠 **핫 사이트(Hot Site)** | **수 시간 이내** | 운영 센터와 유사 수준 | 💰💰💰 비쌈 | 준실시간 백업, 빠른 복구 |
| 🟡 **웜 사이트(Warm Site)** | **수일** | 기본 장비 + 일부 데이터 | 💰💰 보통 | 별도 센터에 데이터를 주기적으로 전송 |
| 🔵 **콜드 사이트(Cold Site)** | **수 주~한 달** | 최소한의 기본 시설만 | 💰 가장 저렴 | 기본 인프라만 갖추고, 장애 시 장비 도입부터 시작 |

### 각 유형 상세 설명

#### 🔴 미러 사이트(Mirror Site)

**운영 센터와 완전히 동일한 장비**를 갖추고, 데이터도 **실시간으로 동기화**합니다. 운영 센터에서 데이터가 처리되면 백업 센터에도 **즉시 동일하게 반영**됩니다. 거울(Mirror)처럼 똑같이 복제되기 때문에 미러 사이트라고 합니다.

> 마치 쌍둥이 형제가 같은 옷을 입고, 같은 행동을 동시에 하는 것과 같습니다. 한 명이 쓰러져도 다른 한 명이 바로 대신할 수 있죠.

**적합한 서비스:** 은행, 증권사, 주식 거래소 등 **실시간 데이터가 생명**인 곳

#### 🟠 핫 사이트(Hot Site)

미러 사이트처럼 100% 동일하지는 않지만, **어느 정도 동일한 수준**으로 갖추어져 있습니다. 완전한 실시간 동기화는 아니지만, 장애 발생 시 **수 시간 이내에 복구**할 수 있습니다.

> 웹 서비스가 다운되었을 때 "몇 시간 만에 복구"가 가능한 것은 핫 사이트로 백업 센터를 운영하고 있기 때문입니다.

#### 🟡 웜 사이트(Warm Site)

데이터를 **별도의 백업 센터에 주기적으로 전송**해두는 방식입니다. 실시간은 아니기 때문에, 장애 발생 시 데이터를 가져와야 하므로 **며칠 정도** 복구에 시간이 걸립니다.

> "우리 서비스는 며칠 정도 다운되어도 괜찮다"고 판단되면 웜 사이트로 운영합니다.

#### 🔵 콜드 사이트(Cold Site)

**가장 최소한의 기본 시설만** 갖추어 놓은 백업 센터입니다. 장비도 기본적인 것만 있고, 장애가 발생하면 장비 도입부터 시작해야 하므로 **한 달 정도** 걸릴 수 있습니다. 비용은 가장 적게 들지만 복구 시간은 가장 깁니다.

### 어떤 유형을 선택해야 하는가?

백업 센터 유형을 결정할 때는 두 가지를 고려해야 합니다:

1. **데이터의 비즈니스 가치:** 데이터가 실시간으로 중요하다면 미러 사이트, 그렇지 않다면 더 낮은 수준도 괜찮습니다.
2. **비용:** 미러 사이트는 운영 센터와 동일한 장비를 갖춰야 하므로 비용이 2배 가까이 듭니다. 가성비를 고려해야 합니다.

> **비용 대비 효율이 가장 좋은 백업 센터를 선택하는 것이 핵심입니다.**

---

## 🗂️ 복구 알고리즘 전체 비교 정리

지금까지 배운 모든 복구 기법을 한 표로 정리합니다:

| 기법 | 갱신 방식 | Undo | Redo | 로그 사용 | 비고 |
|------|----------|------|------|----------|------|
| **지연갱신 기법** | 비동기식 (커밋 후 저장) | ❌ No-Undo | ✅ Redo | ✅ 사용 | 커밋 없는 건 아무 작업 불필요 |
| **즉시갱신 기법 (유형 1)** | 동기식 (100% 즉시 저장) | ✅ Undo | ❌ No-Redo | ✅ 사용 | 커밋 있는 건 이미 저장 완료 |
| **즉시갱신 기법 (유형 2)** | 동기식 (일반적) | ✅ Undo | ✅ Redo | ✅ 사용 | 가장 일반적인 방식 |
| **그림자 페이징** | 페이지 복사 방식 | ❌ No-Undo | ❌ No-Redo | ❌ 미사용 | 병행 처리 불가능이 단점 |

```
복구 기법 분류 체계:

No-Undo / Redo       → 지연갱신 기법
Undo / No-Redo       → 즉시갱신 기법 (100% 저장 보장)
Undo / Redo          → 즉시갱신 기법 (일반적)
No-Undo / No-Redo    → 그림자 페이징 기법
```

:::info 추가 고급 기법 요약
- **체크포인트(Checkpoint):** 불필요한 리두 연산을 줄여 복구 시간 단축
- **ARIES:** 복구 중 에러 발생 시 이미 완료된 복구 작업을 반복하지 않도록 하여 복구 시간 추가 단축
- **WAL(Write-Ahead Logging):** 로그를 항상 데이터보다 먼저 저장하는 기본 원칙
:::

---

## 📌 핵심 정리

- **덤프(백업)**는 데이터베이스 전체를 특정 시점에 복사해 두는 것이며, 복구의 출발점이 된다
- **로그**는 모든 변경 작업을 기록한 일지이며, 덤프와 함께 사용하여 복구를 수행한다
- **리두(Redo)**는 커밋이 있는 트랜잭션을 다시 수행하는 것, **언두(Undo)**는 커밋이 없는 트랜잭션을 취소하는 것이다
- **로그 레코드 버퍼링**은 로그를 메모리에 모아두었다가 한꺼번에 저장하여 I/O 성능을 높이는 기법이다
- **WAL(로그 우선 기록 규약)**은 반드시 로그를 먼저, 데이터를 나중에 저장해야 한다는 원칙이다
- **체크포인트**는 일정 간격으로 자동 저장하여, 이전에 커밋된 트랜잭션의 불필요한 리두를 없애준다
- **체크포인트 이전에 커밋된 트랜잭션은 아무 작업도 수행하지 않는다** — 체크포인트의 가장 중요한 특징
- **그림자 페이징**은 로그 없이 현재 페이지와 그림자 페이지를 이용해 복구하며, 빠르지만 병행 처리가 불가능하다
- **ARIES**는 복구 중 에러 발생 시 이미 완료된 복구 작업을 반복하지 않도록 하는 기법이다 (분석 → 리두 → 언두 3단계)
- **백업 센터**는 미러 사이트(즉시) > 핫 사이트(수 시간) > 웜 사이트(수일) > 콜드 사이트(수 주) 순으로, 비용과 데이터 가치를 고려하여 선택한다

작성일: 2026-02-21