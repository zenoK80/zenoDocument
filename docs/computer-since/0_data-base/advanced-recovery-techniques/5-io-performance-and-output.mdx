---
title: "I/O 횟수 절감과 아웃풋(Output) 연산 최소화를 통한 성능 향상"
description: "I/O 횟수 절감과 아웃풋(Output) 연산 최소화를 통한 성능 향상에 대해 초보자도 쉽게 이해할 수 있도록 설명합니다."
slug: "/advanced-recovery-techniques/5-io-performance-and-output"
sidebar_label: "I/O 성능 향상"
date: "2026-02-21"
---

## 🎯 이 문서에서 배울 내용

데이터베이스 회복(복구)을 위해 로그(작업 기록)를 사용한다는 것은 이전 시간에 배웠습니다. 하지만 로그를 매번 하드디스크에 저장하면 **성능이 심각하게 떨어집니다**. 이번 시간에는 이 문제를 해결하기 위한 다양한 고급 회복 기법들을 알아봅니다.

> 핵심 질문: "로그 파일과 일반 데이터, 둘 다 저장해야 하는데 **누구를 먼저** 저장해야 할까?"

이 문서에서는 다음 내용을 다룹니다:

- **로그 레코드 버퍼링** — 왜 로그를 모아서 한꺼번에 저장하는가
- **로그 우선 기록 규약(WAL)** — 왜 로그를 데이터보다 먼저 저장해야 하는가
- **체크포인트(Checkpoint)** — 불필요한 리두 연산을 줄이는 방법
- **그림자 페이징(Shadow Paging)** — 로그 없이 복구하는 기법
- **ARIES** — 복구 중 에러가 발생해도 처음부터 다시 하지 않는 기법
- **백업 센터 운영 방식** — 미러 사이트부터 콜드 사이트까지

---

## 📖 지난 시간 복습: 로그 기반 회복의 기본 개념

본격적인 내용에 들어가기 전에, 지난 시간에 배운 핵심 개념을 간단히 되짚어 보겠습니다.

데이터베이스 회복(Recovery, 장애 발생 시 데이터를 원래 상태로 되돌리는 것)을 위해서는 크게 두 가지가 필요합니다:

1. **덤프(Dump)** — 데이터베이스를 통째로 복사해 놓은 백업 파일
2. **로그(Log)** — 트랜잭션(작업 묶음)이 수행되는 동안 "무엇이 어떻게 변경되었는지"를 기록한 파일

이 로그를 이용하는 방법에는 두 가지가 있었습니다:

| 기법 | 설명 | 특징 |
|------|------|------|
| **지연 갱신 기법** | 커밋(완료) 전까지 실제 디스크에 저장하지 않음 | 커밋 없으면 아무 작업 불필요 |
| **즉시 갱신 기법** | 작업 도중에도 디스크에 저장할 수 있음 | 커밋 없으면 언두, 커밋 있으면 리두 |

그리고 로그를 이용한 복구의 핵심 원칙은 다음과 같습니다:

- **커밋이 있는 트랜잭션** → **리두(Redo, 다시 실행)** 연산 수행
- **커밋이 없는 트랜잭션** → **언두(Undo, 취소)** 연산 수행

:::info 용어 정리
- **트랜잭션(Transaction)**: 데이터베이스에서 하나의 논리적 작업 단위. 예를 들어 "A 계좌에서 B 계좌로 1만 원 이체"는 하나의 트랜잭션입니다.
- **커밋(Commit)**: 트랜잭션이 성공적으로 완료되었음을 확정하는 명령
- **리두(Redo)**: 이미 커밋된 작업을 다시 수행하는 것
- **언두(Undo)**: 완료되지 않은 작업을 취소하고 원래 상태로 되돌리는 것
:::

자, 이제 본격적으로 "왜 로그를 매번 저장하면 안 되는지"부터 알아보겠습니다.

---

## 🔄 로그 레코드 버퍼링 — 왜 모아서 한꺼번에 저장하는가

### 문제의 시작: 매번 저장하면 너무 느리다

트랜잭션이 수행되면 작업 하나하나마다 로그 레코드(기록 한 줄)가 만들어집니다. 예를 들어 볼까요?

```
작업 1: x 값을 100에서 200으로 변경 → 로그 레코드 1줄 생성
작업 2: y 값을 200에서 300으로 변경 → 로그 레코드 1줄 생성
작업 3: z 값을 300에서 400으로 변경 → 로그 레코드 1줄 생성
...
```

만약 처리해야 할 데이터가 **1만 개**라면, 로그 레코드도 **최소 1만 줄**이 생성됩니다. 여기서 문제가 발생합니다.

> 만약 로그 레코드가 1줄 생성될 때마다 하드디스크에 저장한다면? → 1만 번의 저장(I/O) 작업이 발생합니다!

이것이 왜 문제인지, 컴퓨터의 데이터 처리 흐름을 먼저 이해해야 합니다.

### 컴퓨터의 데이터 처리 흐름: 인풋 → 리드 → 라이트 → 아웃풋

컴퓨터에서 데이터가 처리되는 과정은 다음과 같습니다:

```
하드디스크 ──[인풋(Input)]──▶ 메모리 ──[리드(Read)]──▶ CPU
                                                          │
하드디스크 ◀──[아웃풋(Output)]── 메모리 ◀──[라이트(Write)]──┘
```

| 단계 | 방향 | 설명 |
|------|------|------|
| **인풋(Input)** | 하드디스크 → 메모리 | 하드디스크에서 데이터를 메모리로 가져오기 |
| **리드(Read)** | 메모리 → CPU | 메모리에 있는 데이터를 CPU가 읽어오기 |
| **라이트(Write)** | CPU → 메모리 | CPU가 처리한 결과를 메모리에 기록하기 |
| **아웃풋(Output)** | 메모리 → 하드디스크 | 메모리의 데이터를 하드디스크에 저장하기 |

여기서 핵심은 **인풋과 아웃풋** 단계입니다. 이 두 단계는 하드디스크와 직접 데이터를 주고받는 **I/O(Input/Output) 연산**인데, 이것이 컴퓨터에서 **가장 시간이 오래 걸리는 작업**입니다.

:::warning I/O 연산이 느린 이유
하드디스크는 물리적인 장치입니다. 데이터를 읽고 쓰려면 디스크가 회전하고, 읽기/쓰기 헤드가 이동해야 합니다. 반면 메모리와 CPU 사이의 데이터 이동은 전기 신호로 이루어지기 때문에 훨씬 빠릅니다. 따라서 **I/O 횟수를 줄이는 것이 성능 향상의 핵심**입니다.
:::

### 엑셀 비유로 이해하기

여러분이 엑셀에서 작업한다고 상상해 보세요. 셀(Cell)에 숫자가 **1만 개** 있고, 이것을 하나씩 더해야 합니다.

❌ **비효율적인 방법:**
```
숫자 1개 더하기 → 파일 저장 → 숫자 1개 더하기 → 파일 저장 → ... (1만 번 반복)
```

✅ **효율적인 방법:**
```
숫자 1만 개 모두 더하기 → 마지막에 한 번만 파일 저장
```

당연히 두 번째 방법이 훨씬 빠르겠죠? **로그 레코드 버퍼링**도 정확히 같은 원리입니다.

### 로그 레코드 버퍼링이란?

**로그 레코드 버퍼링(Log Record Buffering)**이란, 로그 레코드를 생성할 때마다 바로 하드디스크에 저장하지 않고 **메모리(버퍼)에 모아 두었다가 나중에 한꺼번에 저장하는 방식**입니다.

```
[기존 방식 - 매번 저장] ❌
작업1 → 로그 생성 → 디스크 저장 → 작업2 → 로그 생성 → 디스크 저장 → ...
(I/O 1만 번 발생!)

[버퍼링 방식 - 모아서 저장] ✅
작업1 → 로그 생성(메모리) → 작업2 → 로그 생성(메모리) → ... → 한꺼번에 디스크 저장
(I/O 1번 발생!)
```

마치 **택배를 보낼 때** 물건 하나 생길 때마다 우체국에 가는 게 아니라, 물건을 여러 개 모아 두었다가 한 번에 우체국에 가는 것과 같습니다.

> **핵심 원리**: 데이터베이스의 성능을 향상하려면 **아웃풋(Output) 연산의 횟수를 줄여야** 하고, 아웃풋 연산을 줄이려면 **메모리에 작업 결과를 모아 두었다가 나중에 한꺼번에 저장**하는 방식을 사용해야 합니다.

---

## 📝 로그 우선 기록 규약(WAL) — 누구를 먼저 저장할 것인가

### 새로운 문제: 메모리에 두 종류의 데이터가 있다

로그 레코드 버퍼링 덕분에 로그 레코드는 메모리에 모여 있습니다. 그런데 잠깐, 메모리에는 로그 레코드만 있는 것이 아닙니다:

- **일반 데이터** — 실제 처리된 결과 데이터 (예: 계좌 잔액이 변경된 데이터)
- **로그 레코드** — 작업 기록 데이터 (예: "x를 100에서 200으로 변경했다")

이 두 가지 모두 **결국 하드디스크에 저장(아웃풋)되어야** 합니다. 그런데 하드디스크는 하나이기 때문에 **동시에 두 가지를 저장할 수 없습니다**. 반드시 순서를 정해야 합니다.

> 핵심 질문: **일반 데이터를 먼저 저장할까? 로그 레코드를 먼저 저장할까?**

### 시나리오 분석: 왜 로그를 먼저 저장해야 하는가

#### ❌ 시나리오 1: 일반 데이터를 먼저 저장하는 경우

```
1단계: 일반 데이터 저장 ✅ (성공)
2단계: 로그 레코드 저장 ❌ (이 과정에서 에러 발생!)
```

**결과**: 일반 데이터는 저장되었지만, **로그 레코드가 없습니다**. 나중에 장애가 발생하면? 덤프 파일은 있지만 **로그가 없기 때문에 복구가 불가능**합니다! 이것은 치명적인 문제입니다.

마치 이사를 하면서 짐은 새 집에 옮겼는데, **새 집 주소를 적어둔 메모를 잃어버린 것**과 같습니다. 짐이 어디 있는지 알 수 없게 됩니다.

#### ✅ 시나리오 2: 로그 레코드를 먼저 저장하는 경우

**경우 A**: 로그 저장 중 에러 발생

```
1단계: 로그 레코드 저장 ❌ (에러 발생!)
→ 로그도 없고, 데이터도 저장 안 됨
→ 아무 작업도 안 한 것과 같음 → 복구할 필요 자체가 없음!
```

**경우 B**: 로그 저장 성공, 데이터 저장 중 에러 발생

```
1단계: 로그 레코드 저장 ✅ (성공)
2단계: 일반 데이터 저장 ❌ (에러 발생!)
→ 로그가 있으니까, 덤프 파일 + 로그로 얼마든지 복구 가능!
```

어떤 경우든 **로그를 먼저 저장하면 복구에 문제가 생기지 않습니다**.

### WAL(Write-Ahead Logging) 규약

이렇게 **로그를 일반 데이터보다 먼저 저장해야 한다**는 원칙을 **로그 우선 기록 규약**, 영어로 **WAL(Write-Ahead Logging)**이라고 합니다.

> **WAL 규약**: 트랜잭션이 커밋(완료 확정) 상태로 들어가기 위해서는, 해당 트랜잭션과 관련된 **모든 로그 레코드를 안전한 저장 장치(하드디스크)에 먼저 저장**해야 합니다. 그 후에야 일반 데이터를 저장할 수 있습니다.

```
[WAL 규약에 따른 저장 순서]

① 로그 레코드를 하드디스크에 저장 (먼저!)
② 일반 데이터를 하드디스크에 저장 (나중에!)
```

:::tip WAL을 쉽게 기억하는 방법
WAL = **W**rite-**A**head **L**ogging = "로깅(기록)을 앞서서(먼저) 쓰기(기록)하라"

마치 시험 답안을 쓰기 전에 **연습장에 풀이 과정을 먼저 적어두는 것**과 같습니다. 답안지(일반 데이터)에 문제가 생겨도, 연습장(로그)이 있으면 다시 옮겨 쓸 수 있으니까요.
:::

### 왜 이것이 원자성을 지켜주는가

데이터베이스의 트랜잭션은 **원자성(Atomicity)**을 보장해야 합니다. 원자성이란 "트랜잭션은 **전부 실행되거나, 전혀 실행되지 않거나** 둘 중 하나여야 한다"는 원칙입니다.

WAL 규약을 지키면:
- 로그가 먼저 저장되어 있으므로, 데이터 저장 중 문제가 생겨도 **로그를 이용해 완벽하게 복구**할 수 있습니다.
- 로그 저장 자체가 실패하면 데이터도 저장되지 않으므로, **아무 일도 없었던 것처럼** 됩니다.

이렇게 WAL 규약은 트랜잭션의 원자성을 지켜주는 핵심 메커니즘입니다.

---

## ⏱️ 체크포인트(Checkpoint) — 불필요한 리두 연산 줄이기

### 새로운 문제: 로그 파일이 너무 크다

WAL 규약 덕분에 안전하게 로그를 저장할 수 있게 되었습니다. 하지만 또 다른 문제가 있습니다.

100만 개의 레코드를 처리한다면? 로그 파일은 **최소 100만 줄 이상** 생성됩니다. 장애가 발생해서 복구를 해야 할 때, 이 100만 줄을 **처음부터 끝까지 전부 읽으면서** 리두/언두를 수행해야 합니다.

그런데 생각해 보세요. 이미 안전하게 하드디스크에 저장이 완료되어 **다시 리두할 필요가 없는 트랜잭션**도 있습니다. 커밋이 완료되고 데이터도 이미 안전하게 저장된 트랜잭션을 굳이 다시 리두하는 것은 **시간 낭비**입니다.

> 마치 시험공부를 할 때, 이미 완벽하게 외운 단원까지 **처음부터 다시 공부하는 것**과 같습니다. 모르는 부분만 공부하면 되는데 말이죠!

### 체크포인트란 무엇인가

**체크포인트(Checkpoint, 검사점)**란 일정한 시간 간격으로 **현재까지의 작업 내용을 하드디스크에 강제로 저장하는 시점**을 말합니다.

체크포인트를 설정하면, 체크포인트 **이전에** 이미 커밋된 트랜잭션은 안전하게 저장이 완료된 것이므로, **복구 시 아무 작업도 수행할 필요가 없습니다**.

:::info 아래 한글의 자동 저장과 같은 원리
여러분이 아래아 한글(HWP)이나 워드 프로세서를 사용할 때, 설정에서 "자동 저장" 기능을 본 적이 있을 겁니다. "10분마다 자동 저장"으로 설정하면, 10분에 한 번씩 자동으로 하드디스크에 저장됩니다.

- **내가 직접 저장** = 커밋(Commit)
- **자동 저장** = 체크포인트(Checkpoint)

이것이 바로 체크포인트의 원리입니다!
:::

### 체크포인트의 수행 순서

체크포인트 시점이 되면, 다음 순서로 작업이 진행됩니다:

```
[체크포인트 수행 순서]

① 메모리에 있는 로그 레코드를 하드디스크에 저장 (WAL 규약에 의해 로그 먼저!)
② 메모리에 있는 일반 데이터를 하드디스크에 저장
③ 체크포인트 정보(체크포인트 로그 레코드)를 하드디스크에 저장
```

이 순서가 매우 중요합니다. **①번이 WAL 규약에 의해 가장 먼저** 수행되고, 마지막으로 **③번 체크포인트 자체의 정보**가 저장됩니다.

### 체크포인트 간격의 딜레마

체크포인트 간격을 어떻게 설정하느냐도 성능에 큰 영향을 미칩니다:

| 간격 | 장점 | 단점 |
|------|------|------|
| **너무 짧은 경우** | 복구 시 작업량이 적음 | 자주 저장하므로 **성능 저하** |
| **너무 긴 경우** | 저장 횟수가 적어 성능 좋음 | 장애 시 **복구할 양이 많음** |
| **적절한 간격** | 성능과 안정성의 균형 | - |

:::warning 체크포인트 간격이 너무 짧으면 생기는 문제
실제 사례로, 아래아 한글의 자동 저장 간격을 1분으로 설정한 사용자가 있었습니다. 문서 작업을 하다 보면 1분마다 자동 저장이 실행되면서 **컴퓨터가 멈추는 현상**이 반복되었습니다. 체크포인트(자동 저장) 작업 중에는 **다른 작업을 수행할 수 없기** 때문입니다. 자동 저장 간격을 20~30분으로 늘리자 문제가 해결되었습니다.

데이터베이스의 체크포인트도 마찬가지입니다. 체크포인트 수행 중에는 **다른 트랜잭션 작업이 일시 중단**될 수 있으므로, 시스템에 맞는 최적의 간격을 설정해야 합니다.
:::

### 체크포인트 회복 알고리즘: 단계별 설명

체크포인트를 이용한 회복은 다음 알고리즘으로 수행됩니다:

```
[체크포인트 회복 알고리즘]

1단계: 빈 언두(Undo) 리스트와 빈 리두(Redo) 리스트를 만든다
2단계: 체크포인트 설정 당시에 활동 중인 트랜잭션을 모두 언두 리스트에 넣는다
3단계: 체크포인트 이후에 시작(Start)된 트랜잭션도 모두 언두 리스트에 넣는다
4단계: 로그를 검색하면서 커밋이 있는 트랜잭션을 언두 리스트에서 빼서 리두 리스트로 옮긴다
5단계: 언두 리스트의 트랜잭션 → 역방향으로 언두 수행
       리두 리스트의 트랜잭션 → 순방향으로 리두 수행
```

**한 줄씩 자세히 설명하겠습니다:**

- **1단계**: 마치 빈 상자 두 개를 준비하는 것입니다. 하나는 "취소할 것(Undo)" 상자, 하나는 "다시 실행할 것(Redo)" 상자입니다.
- **2단계**: 체크포인트가 설정된 **그 순간에 아직 진행 중이던** 트랜잭션들을 일단 전부 "취소할 것" 상자에 넣습니다. 아직 완료되지 않았으니까요.
- **3단계**: 체크포인트 **이후에 새로 시작**된 트랜잭션들도 마찬가지로 "취소할 것" 상자에 넣습니다.
- **4단계**: 이제 로그를 확인합니다. 커밋(완료)된 것이 확인되면, 그 트랜잭션을 "취소할 것" 상자에서 빼서 "다시 실행할 것" 상자로 옮깁니다.
- **5단계**: 최종적으로 "취소할 것" 상자에 남은 트랜잭션은 언두하고, "다시 실행할 것" 상자에 있는 트랜잭션은 리두합니다.

### 실전 예시: 5개의 트랜잭션

다음과 같은 상황을 살펴보겠습니다:

```
시간 ──────────────────────────────────────────────────────▶

T1: |===Start====Commit===|
T2:      |=====Start============================Commit===|
T3:           |=======Start================================| (커밋 없음)
T4:                              |====Start====Commit===|
T5:                                   |====Start==========| (커밋 없음)

                         ▲                              ▲
                    체크포인트                        에러 발생
```

이 그림을 정리하면:

| 트랜잭션 | 시작 시점 | 커밋 시점 | 체크포인트와의 관계 |
|----------|-----------|-----------|---------------------|
| **T1** | 체크포인트 이전 | 체크포인트 이전 | 체크포인트 전에 이미 커밋 완료 |
| **T2** | 체크포인트 이전 | 에러 발생 이전 | 체크포인트 당시 활동 중, 이후 커밋 |
| **T3** | 체크포인트 이전 | 커밋 없음 | 체크포인트 당시 활동 중, 커밋 못 함 |
| **T4** | 체크포인트 이후 | 에러 발생 이전 | 체크포인트 이후 시작, 이후 커밋 |
| **T5** | 체크포인트 이후 | 커밋 없음 | 체크포인트 이후 시작, 커밋 못 함 |

이제 알고리즘을 적용해 보겠습니다:

**1단계**: 빈 Undo 리스트와 Redo 리스트 생성

```
Undo 리스트: [ ]
Redo 리스트: [ ]
```

**2단계**: 체크포인트 당시 활동 중인 트랜잭션 → Undo에 추가

체크포인트 시점에 아직 진행 중이던 트랜잭션은 **T2**와 **T3**입니다. (T1은 이미 커밋 완료)

```
Undo 리스트: [T2, T3]
Redo 리스트: [ ]
```

**3단계**: 체크포인트 이후에 시작된 트랜잭션 → Undo에 추가

체크포인트 이후에 새로 시작된 트랜잭션은 **T4**와 **T5**입니다.

```
Undo 리스트: [T2, T3, T4, T5]
Redo 리스트: [ ]
```

**4단계**: 커밋이 있는 트랜잭션 → Undo에서 빼서 Redo로 이동

T2, T3, T4, T5 중에서 커밋이 있는 것은 **T2**와 **T4**입니다.

```
Undo 리스트: [T3, T5]        ← 커밋이 없는 트랜잭션
Redo 리스트: [T2, T4]        ← 커밋이 있는 트랜잭션
```

**5단계**: 회복 수행

```
T1: 아무 작업도 수행하지 않음 ⭐ (체크포인트 이전에 이미 커밋됨!)
T2: 체크포인트 이후 부분에 대해서만 Redo 수행
T3: 전체에 대해 Undo 수행
T4: 전체에 대해 Redo 수행 (체크포인트 이후에 시작되었으므로)
T5: 전체에 대해 Undo 수행
```

:::tip 체크포인트의 핵심 효과
체크포인트가 **없었다면**, T1도 커밋이 있으므로 Redo 연산을 수행해야 했습니다. 하지만 체크포인트 덕분에 **T1은 아무 작업도 하지 않습니다**. 이것이 체크포인트의 핵심 효과입니다!

> **체크포인트 이전에 커밋된 트랜잭션은 Undo도 Redo도 하지 않는다.**

이를 통해 **불필요한 Redo 연산의 횟수를 줄여** 회복 작업의 속도를 높일 수 있습니다.
:::

체크포인트가 없을 때와 있을 때를 비교해 보면:

| 구분 | 체크포인트 없음 | 체크포인트 있음 |
|------|-----------------|-----------------|
| **T1** | Redo 수행 | ❌ 아무 작업 없음 |
| **T2** | 전체 Redo | 체크포인트 이후만 Redo |
| **T3** | 전체 Undo | 전체 Undo |
| **T4** | 전체 Redo | 전체 Redo |
| **T5** | 전체 Undo | 전체 Undo |

체크포인트 덕분에 T1의 Redo가 완전히 생략되었고, T2도 체크포인트 이전 부분의 Redo가 생략되었습니다.

---

## 👻 그림자 페이징(Shadow Paging) — 로그 없이 복구하기

### 왜 로그 없는 복구가 필요한가

지금까지 배운 모든 기법은 **로그(Log)**를 이용합니다. 하지만 로그를 만들고 관리하는 것 자체가 비용이 듭니다. 로그 파일을 생성하고, 저장하고, 나중에 읽어서 처리하는 과정 모두가 시간과 자원을 소모합니다.

그래서 **로그를 아예 사용하지 않고** 복구할 수 있는 방법이 있습니다. 그것이 바로 **그림자 페이징(Shadow Paging)** 기법입니다.

### 그림자 페이징의 기본 구조

그림자 페이징에서는 **페이지(데이터 저장 단위)를 두 개** 유지합니다:

| 페이지 종류 | 저장 위치 | 역할 |
|-------------|-----------|------|
| **현재 페이지(Current Page)** | 메모리 | 실제 작업이 이루어지는 페이지 |
| **그림자 페이지(Shadow Page)** | 하드디스크 | 변경 전 원본을 보관하는 페이지 |

트랜잭션이 시작되면:
1. 현재 페이지와 **동일한 내용의** 그림자 페이지를 만듭니다
2. 작업(갱신)은 **현재 페이지에서만** 수행합니다
3. 그림자 페이지는 **원본 그대로 보존**합니다

### 그림자 페이징의 동작 원리

구체적인 예시로 이해해 보겠습니다:

```
[초기 상태]
실제 데이터:     100
현재 페이지:     100 (메모리)
그림자 페이지:   100 (하드디스크)
```

**작업 수행**: x 값을 100에서 200으로 변경

```
[작업 수행 중]
실제 데이터:     200 (변경됨)
현재 페이지:     200 (변경됨 - 메모리)
그림자 페이지:   100 (원본 그대로 - 하드디스크) ← 이것이 핵심!
```

#### 경우 1: 장애 발생 시 (커밋 실패)

```
[장애 발생! 복구 필요]
현재 페이지:     200 (잘못된 값)
그림자 페이지:   100 (원본 값)

→ 그림자 페이지(100)를 가져와서 현재 페이지에 덮어쓰기
→ 실제 데이터도 100으로 복구 완료! ✅
```

#### 경우 2: 성공적으로 완료 시 (커밋 성공)

```
[커밋 성공!]
현재 페이지:     200 (정상 값)
그림자 페이지:   100 (옛날 값)

→ 그림자 페이지를 200으로 업데이트
→ 다음 작업을 위해 현재 페이지와 그림자 페이지 동기화 ✅
```

:::note 비유로 이해하기
그림자 페이징은 마치 **연필로 글을 쓸 때 지우개를 준비해 두는 것**과 같습니다.

- **현재 페이지** = 연필로 쓰고 있는 종이
- **그림자 페이지** = 복사해 둔 원본

글을 잘못 쓰면? 원본 복사본을 꺼내서 다시 시작하면 됩니다. 로그(수정 이력)를 일일이 기록할 필요가 없죠!
:::

### 그림자 페이징의 장점과 단점

**장점:**

- **로그를 사용하지 않으므로** 로그 생성/관리 비용이 없습니다
- 그림자 페이지를 덮어쓰기만 하면 되므로 **복구 속도가 매우 빠릅니다**
- 언두/리두 연산이 불필요합니다 (**No-Undo/No-Redo** 기법)

**단점:**

| 단점 | 설명 |
|------|------|
| **추가 저장 공간 필요** | 그림자 페이지를 별도로 저장해야 하므로 공간이 더 필요합니다 |
| **쓰레기(Garbage) 발생** | 페이지가 다른 곳에 갱신되면 기존 페이지가 쓰레기가 됩니다. 쓰레기 수집(Garbage Collection)이 필요합니다 |
| **데이터 단편화** | 페이지가 여기저기 흩어져 저장되면서 물리적으로 조각이 많이 생깁니다 |
| **병행 처리 불가** ⚠️ | 동시에 여러 사용자가 접근하는 **병행 처리를 지원하지 못합니다** |

:::danger 그림자 페이징의 가장 치명적인 단점
그림자 페이징은 **병행 처리(동시에 여러 트랜잭션 실행)를 지원할 수 없습니다**. 순차 처리(한 번에 하나의 트랜잭션만)만 가능합니다.

실제 데이터베이스는 수많은 사용자가 **동시에** 접속하여 작업하므로, 그림자 페이징만으로는 실무에서 사용하기 어렵습니다. 따라서 **로그 기법과 그림자 페이징을 함께 조합**하여 사용하기도 합니다.
:::

---

## 🔧 ARIES — 복구 중 에러가 나도 처음부터 다시 하지 않는 기법

### 또 다른 문제: 복구 중에 또 에러가 발생하면?

데이터베이스를 사용하다가 에러가 발생하면 로그를 이용해 복구합니다. 그런데 만약 **복구하는 도중에 또 에러가 발생하면** 어떻게 될까요?

예를 들어 보겠습니다:

```
[상황]
- 전체 복구 작업량: 100%
- 90%까지 복구 완료
- 나머지 10%만 남음
- 그런데 이 시점에 또 에러 발생!

[기존 방식의 문제] ❌
- 처음부터 다시 100% 복구 시작
- 이미 완료한 90%를 또 반복해야 함 → 엄청난 시간 낭비!
```

마치 시험 답안지를 90% 작성했는데 답안지가 찢어져서, **새 답안지에 처음부터 다시 작성해야 하는 것**과 같습니다. 이미 쓴 90%를 다시 쓰는 건 너무 비효율적이죠.

### ARIES란 무엇인가

**ARIES(Algorithm for Recovery and Isolation Exploiting Semantics)**는 이 문제를 해결하는 기법입니다. 핵심 아이디어는 간단합니다:

> **복구 작업을 수행하면서도 로그를 기록해 두자!** 그러면 복구 중에 에러가 나도 이미 완료된 부분은 건너뛸 수 있다.

ARIES의 핵심 원리를 하나씩 살펴보겠습니다:

#### 1. Redo 중에도 로깅한다 (Repeating History)

커밋이 있는 트랜잭션에 대해 Redo 작업을 수행할 때, 그 **Redo 작업 자체도 로그에 기록**합니다. 이것을 **역사 반복(Repeating History)** 정보라고 합니다.

```
[기존 방식] ❌
Redo 작업 수행 → 로그 기록 안 함 → 에러 시 처음부터 다시

[ARIES 방식] ✅
Redo 작업 수행 → Redo 했다는 것도 로그에 기록 → 에러 시 기록된 부분은 건너뜀
```

#### 2. Undo 중에도 로깅한다

마찬가지로 Undo 작업을 수행할 때도 **"이것을 취소했다"는 정보를 로그에 기록**합니다.

```
[예시]
- T3의 작업 100개를 Undo해야 함
- 90개까지 Undo 완료 → 로그에 "90개 취소 완료" 기록
- 이 시점에 에러 발생!
- 재시작 시: 로그 확인 → "90개는 이미 취소했구나" → 나머지 10개만 Undo 수행 ✅
```

:::tip ARIES의 핵심 효과
ARIES를 사용하면 **이미 완료된 복구 작업은 반복하지 않습니다**. 이를 통해:
- Redo 작업의 불필요한 반복 방지
- Undo 작업의 불필요한 반복 방지
- 전체 복구 시간 대폭 단축
:::

### ARIES의 3단계

ARIES는 다음 **3단계**로 복구를 수행합니다:

```
[ARIES 복구 3단계]

① 분석(Analysis) 단계
   - 로그를 검사하여 현재 상태 파악
   - 어떤 트랜잭션이 활동 중이었는지
   - 어떤 트랜잭션이 커밋되었는지
   - 무엇을 Undo/Redo해야 하는지 결정

② Redo 단계
   - 커밋이 있는 트랜잭션에 대해 Redo 수행
   - WAL 원칙에 따라 로그를 먼저 기록하면서 진행

③ Undo 단계
   - 커밋이 없는 트랜잭션에 대해 Undo 수행
   - Undo 작업도 로깅하면서 진행
   - 이미 Undo 완료된 작업은 다시 Undo하지 않음
```

---

## 🗄️ 데이터베이스 복구 알고리즘 총정리

지금까지 배운 모든 회복 기법을 하나의 표로 정리하겠습니다:

| 기법 | Undo | Redo | 로그 사용 | 설명 |
|------|------|------|-----------|------|
| **지연 갱신 기법** | ❌ No-Undo | ✅ Redo | O | 커밋 전까지 아웃풋 안 함. 커밋 없으면 작업 불필요, 커밋 있으면 Redo |
| **즉시 갱신 기법 (100% 저장 보장)** | ✅ Undo | ❌ No-Redo | O | 100% 저장되므로 커밋 있으면 Redo 불필요, 커밋 없으면 Undo |
| **즉시 갱신 기법 (일반)** | ✅ Undo | ✅ Redo | O | 커밋 없으면 Undo, 커밋 있으면 Redo |
| **그림자 페이징** | ❌ No-Undo | ❌ No-Redo | X | 로그 없이 그림자 페이지로 복구. 병행 처리 불가 |

그리고 이번 시간에 추가로 배운 개념들:

| 개념 | 핵심 내용 |
|------|-----------|
| **로그 레코드 버퍼링** | I/O 횟수를 줄이기 위해 로그를 메모리에 모아서 한꺼번에 저장 |
| **WAL(로그 우선 기록 규약)** | 일반 데이터보다 로그를 먼저 저장하여 안전한 복구 보장 |
| **체크포인트** | 일정 간격으로 강제 저장하여 불필요한 Redo 연산 제거 |
| **ARIES** | 복구 중 에러 발생 시 이미 완료된 복구 작업을 반복하지 않음 |

---

## 🏢 백업 센터 운영 방식 — 비용과 복구 속도의 균형

### 왜 백업 센터가 필요한가

덤프(Dump)란 결국 **백업(Backup)**입니다. 그런데 이 백업을 어느 정도 수준으로 운영할 것인지는 **비용**과 **데이터의 가치**에 따라 결정됩니다.

여러분의 개인 컴퓨터를 생각해 보세요:
- 중요한 논문 파일 → 매일매일 USB에 백업
- 게임 스크린샷 → 1년에 한 번 정리할 때 백업
- 임시 다운로드 파일 → 백업 안 함

데이터베이스 백업 센터도 마찬가지로, 서비스의 중요도에 따라 다른 수준으로 운영합니다.

### 백업 센터의 4가지 유형

```
[복구 속도 빠름] ◀─────────────────────────▶ [복구 속도 느림]
[비용 높음]                                    [비용 낮음]

  미러 사이트 → 핫 사이트 → 웜 사이트 → 콜드 사이트
```

#### 🪞 미러 사이트(Mirror Site)

| 항목 | 내용 |
|------|------|
| **복구 시간** | **즉시** (실시간) |
| **구성** | 운영 센터와 **100% 동일한 장비**를 갖춘 백업 센터 |
| **동기화** | 실시간 동기식 — 운영 센터에 데이터가 처리되면 **즉시** 백업 센터에도 반영 |
| **비용** | 매우 높음 |
| **적용 사례** | 은행, 증권거래소, 항공 관제 시스템 등 |

미러(Mirror)는 "거울"이라는 뜻입니다. 운영 센터를 거울에 비춘 것처럼 **완벽하게 동일한** 백업 센터를 운영합니다. 장애가 발생하면 **핫 스와핑(Hot Swapping)** 기술로 즉시 백업 센터로 전환됩니다.

#### 🔥 핫 사이트(Hot Site)

| 항목 | 내용 |
|------|------|
| **복구 시간** | **몇 시간 이내** |
| **구성** | 운영 센터와 유사한 수준의 장비 (100% 동일하지는 않음) |
| **동기화** | 준 실시간 — 약간의 시차가 있을 수 있음 |
| **비용** | 높음 |
| **적용 사례** | 주요 웹 서비스, 전자상거래 플랫폼 등 |

웹 서비스가 다운되었다가 **몇 시간 내에 복구**되는 경우, 대부분 핫 사이트를 운영하고 있기 때문입니다.

#### 🌡️ 웜 사이트(Warm Site)

| 항목 | 내용 |
|------|------|
| **복구 시간** | **며칠** |
| **구성** | 기본 장비는 갖추되, 별도의 백업 센터에 데이터를 옮겨놓는 형태 |
| **동기화** | 비동기식 — 정기적으로 데이터를 옮김 |
| **비용** | 중간 |
| **적용 사례** | 일반 기업 시스템, 내부 관리 시스템 등 |

"며칠 정도 복구에 시간이 걸려도 괜찮다"고 판단되는 시스템에 적합합니다.

#### ❄️ 콜드 사이트(Cold Site)

| 항목 | 내용 |
|------|------|
| **복구 시간** | **한 달 정도** |
| **구성** | 가장 기본적인 시설만 갖춤 (전원, 네트워크 등) |
| **동기화** | 매우 드물게 백업 |
| **비용** | 가장 낮음 |
| **적용 사례** | 중요도가 낮은 아카이브 시스템, 소규모 데이터 등 |

비용이 가장 적게 들지만, 장애 발생 시 복구에 한 달 가까이 걸릴 수 있습니다.

### 어떤 방식을 선택해야 하는가

백업 센터 방식을 결정할 때는 다음 두 가지를 고려해야 합니다:

1. **비용(Cost)** — 미러 사이트는 운영 비용이 매우 비쌉니다
2. **데이터의 비즈니스 가치** — 실시간으로 중요한 데이터인지, 없어져도 크게 문제없는 데이터인지

> **비용 대비 가장 효율이 좋은** 백업 센터를 선택하는 것이 핵심입니다.

:::tip 백업 센터 선택 기준 정리
- "1초라도 서비스가 중단되면 안 된다" → **미러 사이트**
- "몇 시간 내에 복구되면 된다" → **핫 사이트**
- "며칠 정도는 괜찮다" → **웜 사이트**
- "한 달 안에만 복구되면 된다" → **콜드 사이트**
:::

---

## 📌 핵심 정리

- **I/O 연산(인풋/아웃풋)**은 컴퓨터에서 가장 느린 작업이므로, **I/O 횟수를 줄이는 것**이 성능 향상의 핵심이다
- **로그 레코드 버퍼링**은 로그를 매번 디스크에 저장하지 않고 **메모리에 모아서 한꺼번에 저장**하여 I/O를 줄이는 기법이다
- **WAL(로그 우선 기록 규약)**은 일반 데이터보다 **로그를 먼저 하드디스크에 저장**해야 한다는 규약이다 (복구 안전성 보장)
- **체크포인트(Checkpoint)**는 일정 간격으로 강제 저장하여, 체크포인트 이전에 커밋된 트랜잭션은 **Redo/Undo 모두 생략**할 수 있게 해준다
- 체크포인트 간격이 **너무 짧으면 성능 저하**, **너무 길면 복구량 증가**이므로 적절한 간격 설정이 중요하다
- **그림자 페이징**은 로그 없이 현재 페이지와 그림자 페이지 두 개를 이용해 복구하는 기법이다 (No-Undo/No-Redo)
- 그림자 페이징은 복구 속도가 빠르지만, **병행 처리를 지원하지 못하는 치명적 단점**이 있다
- **ARIES**는 복구 중 에러가 발생해도 **이미 완료된 복구 작업을 반복하지 않도록** 복구 과정 자체도 로깅하는 기법이다
- 백업 센터는 **미러 사이트(즉시) → 핫 사이트(수 시간) → 웜 사이트(수일) → 콜드 사이트(한 달)** 순으로 비용과 복구 속도가 다르다
- 백업 센터 선택은 **비용**과 **데이터의 비즈니스 가치**를 함께 고려하여 결정한다

작성일: 2026-02-21