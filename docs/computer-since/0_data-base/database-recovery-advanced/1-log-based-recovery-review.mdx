---
title: "로그 기반 회복 기법 복습 (지연갱신 / 즉시갱신)"
description: "로그 기반 회복 기법 복습 (지연갱신 / 즉시갱신)에 대해 초보자도 쉽게 이해할 수 있도록 설명합니다."
slug: "/database-recovery-advanced/1-log-based-recovery-review"
sidebar_label: "로그 기반 회복"
date: "2026-02-21"
---

# 🗄️ 데이터베이스 고급 회복 기법 완전 정복

데이터베이스를 운영하다 보면 갑작스러운 시스템 오류, 정전, 프로그램 버그 등 다양한 이유로 **데이터가 손상되거나 유실**될 수 있습니다. 이런 상황에서 데이터를 원래 상태로 되돌리는 것을 **회복(Recovery)** 이라고 합니다. 이 문서에서는 데이터베이스 회복의 핵심 개념인 **로그 레코드 버퍼링**, **로그 우선 기록 규약(WAL)**, **체크포인트**, **그림자 페이징**, **ARIES 기법**, 그리고 **백업 사이트 운영 방식**까지 단계별로 자세히 알아보겠습니다.

:::info 이 문서를 읽기 전에
이 문서는 데이터베이스 회복의 기초(덤프, 로그, 지연갱신/즉시갱신, REDO/UNDO 연산)를 이미 학습한 분을 대상으로 합니다. 기초 개념을 먼저 익히신 후 이 문서를 읽으시면 훨씬 효과적으로 이해할 수 있습니다.
:::

---

## 📋 이전 시간 복습: 로그 기반 회복의 기초

본격적인 고급 기법을 설명하기 전에, 지난 시간에 배운 내용을 간단히 정리하고 넘어가겠습니다. 이 내용이 이번 문서 전체의 출발점이 되기 때문입니다.

### 🔄 회복의 기본 흐름

데이터베이스에서 회복을 수행하는 기본적인 흐름은 다음과 같습니다.

1. **덤프(Dump)**: 특정 시점의 데이터베이스 전체를 통째로 복사해서 안전한 장소에 보관합니다. 마치 사진을 찍어 두는 것처럼, 그 순간의 상태를 보존하는 것입니다.
2. **로그(Log) 기록**: 이후 발생하는 모든 데이터 변경 작업을 로그 파일에 기록합니다.
3. **회복 수행**: 장애가 발생하면 덤프 파일을 기준으로, 로그를 이용해 데이터를 원래 상태로 되돌립니다.

### ⚙️ REDO와 UNDO 연산

로그를 이용한 회복에는 두 가지 핵심 연산이 있습니다.

| 연산 | 설명 | 적용 대상 |
|---|---|---|
| **REDO(재실행)** | 커밋이 완료된 트랜잭션의 작업을 다시 실행 | 커밋(COMMIT)이 있는 트랜잭션 |
| **UNDO(취소)** | 커밋이 완료되지 않은 트랜잭션의 작업을 되돌림 | 커밋(COMMIT)이 없는 트랜잭션 |

> 💡 **핵심 원칙**: 커밋이 있는 트랜잭션은 REDO, 커밋이 없는 트랜잭션은 UNDO! 이것이 로그 기반 회복의 가장 기본적인 원칙입니다.

### 📝 지연갱신 vs 즉시갱신

이전 수업에서 배운 두 가지 갱신 방식도 간단히 복습합니다.

| 구분 | 지연갱신(Deferred Update) | 즉시갱신(Immediate Update) |
|---|---|---|
| **언제 저장?** | 트랜잭션 커밋 이후에 저장 | 트랜잭션 진행 중에 바로 저장 |
| **UNDO 필요?** | 필요 없음 (커밋 전이므로 저장 자체가 안 됨) | 필요함 (이미 저장됐을 수 있으므로) |
| **REDO 필요?** | 필요함 | 경우에 따라 필요함 |
| **특징** | No-Undo / Redo | Undo / No-Redo 또는 Undo / Redo |

---

## 💾 로그 레코드 버퍼링: 왜 로그를 메모리에 모아두는가?

### 🤔 문제 인식: 매번 저장하면 어떤 일이 생길까?

로그 파일이 어떻게 만들어지는지부터 생각해 봅시다. 예를 들어, 제가 처리해야 할 데이터가 **10,000개(만 개)** 있다고 가정합니다. 데이터 하나하나를 처리할 때마다 로그 파일에 한 줄씩 기록이 됩니다.

```
[로그 파일 생성 예시]
T1 : X 값을 100 → 200으로 변경  →  로그 1줄 생성
T1 : Y 값을 300 → 400으로 변경  →  로그 1줄 생성
T1 : Z 값을 500 → 600으로 변경  →  로그 1줄 생성
...
(10,000개 데이터 처리 시 → 로그도 최소 10,000줄 생성)
```

만약 데이터를 하나 처리할 때마다 **로그 파일을 하드디스크에 저장**한다면 어떻게 될까요?

- 데이터 1개 처리 → 하드디스크에 로그 저장
- 데이터 1개 처리 → 하드디스크에 로그 저장
- 데이터 1개 처리 → 하드디스크에 로그 저장
- ... (10,000번 반복)

이것은 마치 엑셀 작업을 할 때 **숫자 하나를 입력할 때마다 Ctrl+S를 눌러 저장하는 것**과 같습니다. 10,000개의 숫자를 입력해야 한다면 10,000번 저장을 반복해야 합니다. 이렇게 작업하는 사람은 없겠죠? 실제로는 모든 작업을 다 마치고 **마지막에 한 번만 저장**합니다.

### 🖥️ 컴퓨터의 데이터 처리 흐름 이해

여기서 컴퓨터가 데이터를 처리하는 기본 흐름을 이해해야 합니다.

```
하드디스크 ←→ 메모리(RAM) ←→ CPU
   (저장)        (작업 공간)    (처리)
```

각 단계별 연산의 명칭은 다음과 같습니다.

| 방향 | 연산 이름 | 설명 |
|---|---|---|
| 하드디스크 → 메모리 | **INPUT(입력)** | 데이터를 하드디스크에서 메모리로 가져옴 |
| 메모리 → CPU | **READ(읽기)** | 메모리에서 CPU로 데이터를 읽어옴 |
| CPU → 메모리 | **WRITE(쓰기)** | CPU가 처리한 결과를 메모리에 기록 |
| 메모리 → 하드디스크 | **OUTPUT(출력)** | 메모리의 데이터를 하드디스크에 저장 |

:::warning I/O 연산의 비용
**I/O(Input/Output) 연산**은 하드디스크와 메모리 사이에서 데이터를 주고받는 작업입니다. CPU나 메모리 연산에 비해 **수십~수백 배 느린** 작업입니다. 따라서 I/O 횟수를 최대한 줄이는 것이 데이터베이스 성능 향상의 핵심입니다.
:::

### 💡 해결책: 로그 레코드 버퍼링(Log Record Buffering)

이 문제를 해결하는 방법이 바로 **로그 레코드 버퍼링**입니다. 개념은 간단합니다.

> **로그 레코드 버퍼링**: 로그를 매번 하드디스크에 저장하는 대신, 일단 메모리(버퍼)에 모아두었다가 나중에 한꺼번에 하드디스크에 저장하는 방식

마치 편지를 보낼 때 한 통씩 우체통에 넣는 것이 아니라, 여러 통을 모아서 한 번에 우체국에 가져가는 것과 같습니다.

```
[버퍼링 없이 처리하는 경우 ❌]
데이터 1 처리 → 로그 1 하드디스크 저장
데이터 2 처리 → 로그 2 하드디스크 저장
데이터 3 처리 → 로그 3 하드디스크 저장
... (I/O 10,000번 발생!)

[로그 레코드 버퍼링 사용 ✅]
데이터 1 처리 → 로그 1 메모리에 보관
데이터 2 처리 → 로그 2 메모리에 보관
데이터 3 처리 → 로그 3 메모리에 보관
...
[일정 시점] 메모리의 모든 로그 → 하드디스크에 한꺼번에 저장 (I/O 횟수 대폭 감소!)
```

그런데 이렇게 로그를 메모리에 모아두면 **새로운 문제**가 생깁니다. 메모리는 **휘발성(전원이 꺼지면 데이터가 사라지는 성질)** 저장장치이기 때문에, 시스템이 갑자기 다운되면 메모리에 있던 로그가 모두 사라질 수 있습니다!

이 문제를 해결하기 위한 규칙이 바로 다음에 설명할 **로그 우선 기록 규약**입니다.

---

## ✍️ 로그 우선 기록 규약 (WAL: Write-Ahead Logging)

### 🤔 왜 이 규약이 필요한가?

로그 레코드 버퍼링 덕분에 성능은 향상됐지만, 메모리에 쌓인 로그와 실제 데이터가 동시에 존재하는 상황이 만들어졌습니다. 이제 **어느 것을 먼저 하드디스크에 저장해야 하는가?** 라는 중요한 질문이 생깁니다.

메모리에는 두 가지 종류의 데이터가 있습니다.
1. **일반 데이터 버퍼**: 실제로 처리된 데이터 (예: X = 200으로 변경된 데이터)
2. **로그 버퍼**: 그 작업의 기록 (예: "X를 100에서 200으로 변경했다"는 로그)

하드디스크는 동시에 두 가지를 저장할 수 없으므로, **순서**를 정해야 합니다.

### 🔍 잘못된 순서 vs 올바른 순서

**케이스 1: 일반 데이터를 먼저 저장하는 경우 ❌**

```
1단계: 일반 데이터 → 하드디스크 저장 ✅ (성공)
2단계: 로그 데이터 → 하드디스크 저장 도중... 💥 에러 발생!
```

이렇게 되면:
- 일반 데이터는 하드디스크에 저장됨
- 로그 파일은 저장되지 않음
- 나중에 장애가 발생해서 복구하려 해도 **로그가 없어서 복구 불가능!**

이것은 마치 어떤 작업을 했는데 영수증(증거)이 없는 것과 같습니다. 나중에 문제가 생겼을 때 무슨 작업을 했는지 알 수 없는 상황이 됩니다.

**케이스 2: 로그를 먼저 저장하는 경우 ✅**

```
1단계: 로그 데이터 → 하드디스크 저장 도중... 💥 에러 발생!
```

이렇게 되면:
- 로그 파일도 저장 안 됨
- 일반 데이터도 저장 안 됨
- 결과적으로 **아무 작업도 하지 않은 것과 동일** → 복구에 문제 없음!

```
1단계: 로그 데이터 → 하드디스크 저장 ✅ (성공)
2단계: 일반 데이터 → 하드디스크 저장 도중... 💥 에러 발생!
```

이렇게 되면:
- 로그 파일은 안전하게 저장됨
- 일반 데이터는 저장 실패
- 하지만 **로그가 있으므로** 덤프 파일 + 로그를 이용해서 완벽하게 복구 가능!

### 📌 WAL 규약의 정의

> **로그 우선 기록 규약 (Write-Ahead Logging, WAL)**
> 일반 데이터(버퍼 블록)를 하드디스크에 저장(OUTPUT)하기 전에, **반드시 그 데이터와 관련된 로그 레코드를 먼저 안전한 저장장치에 기록**해야 한다.

영어로는 **Write-Ahead Logging**, 줄여서 **WAL**이라고 부릅니다. "먼저(Ahead) 기록(Write)하는 로깅(Logging)"이라는 의미입니다.

```
[WAL 규약 적용 예시]

트랜잭션 T1이 X를 100 → 200으로 변경하는 경우:

Step 1: 로그 기록 (하드디스크)
        → <T1, X, 100, 200> 로그 레코드 저장 완료 ✅

Step 2: 데이터 저장 (하드디스크)
        → X = 200 데이터 블록 저장 완료 ✅

이 순서를 절대 바꾸면 안 됩니다!
```

:::danger WAL 규약 위반 금지
절대로 **로그보다 일반 데이터를 먼저** 하드디스크에 저장해서는 안 됩니다. 이를 위반하면 장애 발생 시 복구가 불가능한 상황이 생길 수 있으며, 데이터베이스의 **원자성(Atomicity)** 이 보장되지 않습니다.
:::

### ✅ WAL이 보장하는 것

WAL 규약을 통해 데이터베이스는 **트랜잭션의 원자성(작업 전체가 성공하거나, 전체가 취소되거나)** 을 보장할 수 있습니다. 로그가 먼저 안전하게 저장되어 있는 한, 데이터 저장 중에 어떤 오류가 발생해도 로그를 기반으로 상태를 올바르게 복원할 수 있기 때문입니다.

---

## ⏱️ 체크포인트(Checkpoint): 회복 시간을 줄이는 스마트한 방법

### 🤔 왜 체크포인트가 필요한가?

로그를 이용한 회복은 완벽한 방법처럼 보이지만, **큰 성능 문제**가 있습니다.

예를 들어, 100만 개의 레코드를 처리한다면 로그 파일도 최소 100만 줄이 생성됩니다. 장애가 발생해서 회복을 시작하면, 로그 파일을 **처음부터 끝까지** 순서대로 읽으면서 REDO와 UNDO 연산을 수행해야 합니다.

그런데 이미 안전하게 커밋되어 하드디스크에 저장된 트랜잭션도 **다시 REDO를 수행**해야 하는 비효율이 발생합니다. 이미 완벽하게 저장된 데이터를 굳이 다시 복원할 필요가 없는데도 말입니다.

이 문제를 해결하는 것이 바로 **체크포인트(Checkpoint)** 입니다.

### 📖 체크포인트란?

체크포인트는 **일정한 시간 간격으로 현재까지의 모든 데이터를 강제로 하드디스크에 저장**하는 시점입니다.

여러분이 아래한글이나 워드 같은 문서 편집기를 사용할 때 **자동 저장** 기능을 사용해본 적 있으시죠? 10분이나 20분마다 자동으로 저장이 되는 그 기능이 바로 체크포인트와 같은 개념입니다!

:::tip 자동 저장 간격 설정의 딜레마
체크포인트 간격을 **너무 짧게** 설정하면?
- 체크포인트 작업 중에는 다른 트랜잭션이 실행되지 못함
- 자주 저장하느라 정작 중요한 작업을 못 하는 상황 발생 (성능 저하)

체크포인트 간격을 **너무 길게** 설정하면?
- 간격 사이에 오류가 발생하면 복구해야 할 데이터가 너무 많아짐
- 회복 시간이 길어짐

따라서 시스템의 특성에 맞는 **적절한 간격**을 설정하는 것이 중요합니다.
:::

### 🔧 체크포인트 수행 순서

체크포인트가 실행되면 다음 순서로 작업이 진행됩니다. 이 순서는 매우 중요합니다!

```
체크포인트 실행 시 작업 순서:

1️⃣ 메모리(로그 버퍼)에 있는 로그 레코드 → 하드디스크에 저장
   (WAL 규약에 따라 로그를 먼저!)

2️⃣ 메모리(데이터 버퍼)에 있는 일반 데이터 → 하드디스크에 저장

3️⃣ 체크포인트 정보를 담은 로그 레코드 → 하드디스크에 저장
   (체크포인트가 완료됐다는 기록을 남김)
```

### 📊 체크포인트 회복 알고리즘

체크포인트를 이용한 회복은 다음 알고리즘으로 수행됩니다.

```
[체크포인트 회복 알고리즘]

1단계: 빈 UNDO 리스트와 REDO 리스트를 생성한다.

2단계: 체크포인트 설정 당시에 활동 중(진행 중)이었던 모든 트랜잭션을
       UNDO 리스트에 추가한다.

3단계: 체크포인트 이후에 새로 시작(START)된 모든 트랜잭션도
       UNDO 리스트에 추가한다.
       (일단 모두 UNDO 대상으로 간주)

4단계: 로그를 처음부터 검색하면서,
       커밋(COMMIT)이 발견된 트랜잭션은
       UNDO 리스트에서 제거하고 REDO 리스트로 이동한다.

5단계: 회복 수행:
       - UNDO 리스트에 있는 트랜잭션: 역방향으로 UNDO 연산 수행
       - REDO 리스트에 있는 트랜잭션: 순방향으로 REDO 연산 수행
```

### 🎯 체크포인트 예제로 이해하기

다음 예제를 통해 체크포인트 알고리즘을 실제로 적용해 봅시다. 5개의 트랜잭션(T1~T5)이 있습니다.

```
시간 흐름 →

T1: [===시작===커밋===]
                        ↑체크포인트        ↑장애 발생
T2:              [===시작====커밋=====]
T3:                   [===시작==========](커밋 없음)
T4:                        [===시작==커밋=====]
T5:                             [===시작======](커밋 없음)
```

**각 트랜잭션의 상태 정리:**

| 트랜잭션 | 체크포인트 시점 상태 | 커밋 여부 |
|---|---|---|
| T1 | 체크포인트 **이전**에 이미 커밋 완료 | ✅ 커밋 있음 |
| T2 | 체크포인트 시점에 **활동 중** | ✅ 커밋 있음 |
| T3 | 체크포인트 시점에 **활동 중** | ❌ 커밋 없음 |
| T4 | 체크포인트 **이후** 시작 | ✅ 커밋 있음 |
| T5 | 체크포인트 **이후** 시작 | ❌ 커밋 없음 |

**알고리즘 적용 과정:**

```
1단계: UNDO 리스트 = [], REDO 리스트 = [] 생성

2단계: 체크포인트 당시 활동 중인 T2, T3 → UNDO 리스트에 추가
       UNDO = [T2, T3]

3단계: 체크포인트 이후 시작한 T4, T5 → UNDO 리스트에 추가
       UNDO = [T2, T3, T4, T5]

4단계: 로그 검색 → T2 커밋 발견 → UNDO에서 제거, REDO로 이동
                    T4 커밋 발견 → UNDO에서 제거, REDO로 이동
       UNDO = [T3, T5]
       REDO = [T2, T4]

5단계: T3, T5 → UNDO 연산 수행 (전체 작업 취소)
       T2, T4 → REDO 연산 수행 (체크포인트 이후 부분만)
       T1 → 아무것도 하지 않음! (체크포인트 이전에 이미 커밋 완료)
```

**최종 회복 연산 요약:**

| 트랜잭션 | 수행할 연산 | 범위 |
|---|---|---|
| T1 | **없음** (아무것도 안 함) | 체크포인트 이전에 이미 안전하게 저장됨 |
| T2 | **REDO** | 체크포인트 이후 부분만 |
| T3 | **UNDO** | 전체 범위 |
| T4 | **REDO** | 전체 범위 (체크포인트 이후 시작했으므로) |
| T5 | **UNDO** | 전체 범위 |

:::note 체크포인트의 핵심 효과
체크포인트가 없었다면 T1, T2, T4 모두 REDO 연산을 수행해야 했습니다. 하지만 체크포인트 덕분에 **T1은 REDO를 건너뛸 수 있습니다.** 이것이 체크포인트가 회복 시간을 단축시키는 원리입니다. 처리해야 할 데이터가 많을수록, 체크포인트의 효과는 더욱 극적으로 나타납니다.
:::

---

## 👥 그림자 페이징(Shadow Paging): 로그 없이 회복하기

### 🤔 왜 로그 없이 회복하는 방법이 필요한가?

지금까지 살펴본 모든 회복 기법은 로그 파일을 사용합니다. 로그 파일을 생성하고, 관리하고, 회복할 때 처음부터 읽는 데 드는 **비용(시간과 저장 공간)** 이 만만치 않습니다. 특히 데이터 변경이 빈번한 환경에서는 로그 파일 관리 자체가 큰 부담이 됩니다.

이런 배경에서 등장한 것이 **그림자 페이징(Shadow Paging)** 기법입니다. 이 기법은 로그를 전혀 사용하지 않고, **두 개의 페이지(현재 페이지 + 그림자 페이지)** 를 이용해서 회복을 수행합니다.

### 📄 그림자 페이징의 구조

그림자 페이징에는 두 가지 페이지가 필요합니다.

| 구분 | 위치 | 내용 |
|---|---|---|
| **현재 페이지(Current Page Table)** | 메모리 | 트랜잭션 진행 중 실시간으로 변경되는 데이터 |
| **그림자 페이지(Shadow Page Table)** | 하드디스크 | 트랜잭션 시작 시점의 원본 데이터 (변경하지 않고 유지) |

### 🔄 그림자 페이징 동작 원리

**트랜잭션 시작 시:**

```
[트랜잭션 시작 시점]

하드디스크의 실제 데이터: X = 100

→ 현재 페이지(메모리) 생성:   X = 100  ← 작업 공간
→ 그림자 페이지(하드디스크):   X = 100  ← 원본 보존
```

**작업 진행 중:**

```
[작업: X를 100 → 200으로 변경]

현재 페이지(메모리):    X = 200  ← 변경됨
그림자 페이지(하드디스크): X = 100  ← 그대로 유지! (변경하지 않음)
```

**장애 발생 시 (UNDO 필요):**

```
[장애 발생 → 커밋 실패]

그림자 페이지(X = 100)를 가져와서 현재 페이지를 덮어씀
→ X = 100으로 복구 완료!
```

**커밋 성공 시:**

```
[커밋 성공]

현재 페이지의 변경 내용(X = 200)을
그림자 페이지에도 반영
→ 그림자 페이지: X = 200으로 업데이트
```

### 👍 그림자 페이징의 장점

- **처리 속도가 매우 빠름**: 로그를 읽고 REDO/UNDO를 수행하는 복잡한 과정 없이, 그림자 페이지를 덮어쓰는 것만으로 회복 완료
- **회복 작업이 단순함**: 실패하면 그림자로 덮어쓰고, 성공하면 그림자를 업데이트하는 두 가지 경우만 처리하면 됨
- **로그 관련 비용 절감**: 로그 파일 생성, 관리, 저장에 드는 오버헤드가 없음

### 👎 그림자 페이징의 단점

그림자 페이징이 완벽한 방법이라면 모든 데이터베이스가 이 방식을 채택했겠지만, 실제로는 여러 단점이 존재합니다.

1. **별도의 저장 공간 필요**: 그림자 페이지를 항상 유지해야 하므로 추가적인 저장 공간이 필요합니다.

2. **쓰레기 데이터(Garbage) 발생**: 데이터를 다른 위치에 새로 쓰는 방식이므로, 기존 위치의 데이터가 더 이상 사용되지 않아 쓸모없는 데이터(쓰레기)가 생깁니다. 이를 주기적으로 수거(Garbage Collection)해야 합니다.

3. **데이터 단편화(Fragmentation) 발생**: 데이터가 물리적으로 여기저기 흩어지게 되어 성능이 저하될 수 있습니다. 마치 책의 페이지가 뒤섞인 것처럼, 데이터가 연속적으로 저장되지 않아 읽는 속도가 느려집니다.

4. **병행 처리(동시 처리) 불가**: 이것이 가장 치명적인 단점입니다. **동시에 여러 사용자가 접근하는 병행 처리를 지원하지 못합니다.** 실제 데이터베이스 환경에서는 수많은 사용자가 동시에 접근하는 것이 기본이기 때문에, 이 단점이 그림자 페이징의 실용적 활용을 크게 제한합니다.

:::tip 그림자 페이징과 로그의 결합 활용
병행 처리의 한계를 극복하기 위해, 일부 시스템에서는 **그림자 페이징과 로그 기반 회복을 결합**하여 사용하기도 합니다. 각각의 장점을 살리면서 단점을 보완하는 방식입니다.
:::

---

## 🔁 회복 알고리즘 유형 총정리

지금까지 배운 내용을 바탕으로, 데이터베이스 회복 알고리즘의 유형을 한눈에 정리해 봅시다.

### 📊 4가지 회복 기법 비교

| 기법 이름 | UNDO | REDO | 해당 갱신 방식 | 설명 |
|---|---|---|---|---|
| **No-Undo / Redo** | ❌ 불필요 | ✅ 필요 | 지연갱신 | 커밋 전에는 저장 안 했으니 UNDO 필요 없음. 커밋된 것만 REDO |
| **Undo / No-Redo** | ✅ 필요 | ❌ 불필요 | 즉시갱신 (100% 저장 보장) | 커밋된 것은 이미 완전 저장. UNDO만 필요 |
| **Undo / Redo** | ✅ 필요 | ✅ 필요 | 즉시갱신 (일반적) | 커밋 없는 것은 UNDO, 커밋된 것은 REDO |
| **No-Undo / No-Redo** | ❌ 불필요 | ❌ 불필요 | 그림자 페이징 | 로그 자체를 사용하지 않으므로 UNDO/REDO 모두 불필요 |

### 🔍 지연갱신 기법 (No-Undo / Redo)

지연갱신 기법은 트랜잭션이 **커밋되기 전까지는 절대로 실제 데이터를 하드디스크에 저장하지 않습니다.** 모든 변경 사항은 메모리에만 존재하다가 커밋이 완료된 후에야 하드디스크에 반영됩니다.

따라서 커밋이 없는 트랜잭션은 어차피 하드디스크에 저장된 게 없으므로 **UNDO(취소) 연산이 필요 없습니다.** 커밋이 완료된 트랜잭션의 경우에만 로그를 이용해 **REDO(재실행)** 를 수행합니다.

### 🔍 즉시갱신 기법 (Undo / Redo)

즉시갱신 기법은 트랜잭션이 진행되는 도중에 **바로바로 변경 내용을 하드디스크에 저장**합니다. 커밋 여부와 관계없이 변경이 발생하면 즉시 저장합니다.

따라서 커밋 없이 실패한 트랜잭션의 경우, 이미 일부 데이터가 하드디스크에 저장됐을 수 있으므로 **UNDO(취소)** 가 필요합니다. 반면 커밋이 완료됐지만 미처 저장되지 못한 데이터는 **REDO(재실행)** 로 복원합니다.

---

## 🔄 ARIES 기법: 회복 중의 회복을 위한 알고리즘

### 🤔 왜 ARIES가 필요한가?

데이터베이스를 사용하다가 오류가 발생하면 로그를 이용해 회복을 시작합니다. 그런데 **회복하는 도중에 또 오류가 발생**한다면 어떻게 될까요?

예를 들어, 회복 작업의 90%를 완료했는데 갑자기 또 오류가 나버렸습니다. 기존 방식대로라면 처음부터 다시 회복을 시작해야 합니다. 이미 90%나 완료한 작업을 버리고 처음부터 다시 시작하는 것은 매우 비효율적입니다.

이 문제를 해결하기 위해 등장한 것이 **ARIES(Algorithm for Recovery and Isolation Exploiting Semantics)** 기법입니다.

### 💡 ARIES의 핵심 아이디어

ARIES의 핵심 아이디어는 간단합니다.

> **"회복 작업을 수행하는 중에도 로그를 남겨라!"**

회복 작업(REDO, UNDO)을 수행할 때도 그 작업 내역을 로그로 기록합니다. 그래서 만약 회복 도중에 또 오류가 발생하더라도, **이미 완료한 회복 작업을 다시 반복하지 않고** 남은 부분만 처리할 수 있습니다.

마치 이사를 할 때 이미 옮긴 짐 목록을 기록해 두는 것과 같습니다. 이사 중에 갑자기 차가 고장 나도, 이미 옮긴 짐 목록을 보고 아직 옮기지 못한 짐만 다시 옮기면 됩니다.

### 📋 ARIES의 3단계 처리 과정

```
[ARIES 3단계]

1단계 - 분석(Analysis):
  로그를 처음부터 분석하여
  - 어떤 트랜잭션이 활동 중인지
  - 어떤 트랜잭션이 커밋됐는지
  - 어떤 것을 REDO하고 어떤 것을 UNDO해야 하는지 파악

2단계 - REDO(재실행):
  커밋된 트랜잭션에 대해 REDO 연산 수행
  이때도 WAL 원칙에 따라 로그 먼저 기록
  → 이미 수행한 REDO는 다시 반복하지 않도록 기록 관리

3단계 - UNDO(취소):
  커밋되지 않은 트랜잭션에 대해 UNDO 연산 수행
  이때도 완료된 UNDO 작업을 로그로 기록
  → 도중에 오류 발생 시 이미 완료한 UNDO는 건너뜀
```

### 🔑 ARIES에서의 핵심 개념: 반복 역사(Repeating History)

ARIES는 **리피팅 히스토리(Repeating History)** 라는 개념을 사용합니다. REDO 연산을 수행할 때, 과거에 일어났던 일을 그대로 재현(반복)한다는 의미입니다. 이렇게 역사를 반복하면서 데이터베이스를 장애 직전 상태로 되돌린 후, UNDO 연산으로 커밋되지 않은 작업을 취소합니다.

```python
# ARIES 개념을 의사 코드(Pseudo Code)로 표현

def ARIES_recovery():
    # 1단계: 분석
    undo_list, redo_list = analyze_log()

    # 2단계: REDO 수행
    for transaction in redo_list:
        if not already_redone(transaction):  # 이미 REDO 했으면 건너뜀
            redo(transaction)
            log_redo_completion(transaction)  # REDO 완료를 로그에 기록

    # 3단계: UNDO 수행
    for transaction in undo_list:
        if not already_undone(transaction):  # 이미 UNDO 했으면 건너뜀
            undo(transaction)
            log_undo_completion(transaction)  # UNDO 완료를 로그에 기록
```

:::tip ARIES의 효과
ARIES를 사용하면 회복 작업 도중 오류가 발생해도 **이미 완료한 회복 작업을 반복하지 않아도 됩니다.** 이로 인해 전체적인 회복 시간이 단축되고, 시스템의 가용성이 향상됩니다.
:::

---

## 🏢 백업 사이트 운영 방식: 장애 대비의 마지막 보루

### 🤔 왜 백업 사이트가 필요한가?

지금까지 배운 모든 회복 기법은 **데이터베이스 소프트웨어 수준**에서의 회복 방법입니다. 하지만 건물 전체가 화재로 소실되거나, 자연재해로 서버가 완전히 파괴된다면 어떻게 할까요? 이런 **물리적인 재해**에 대비하기 위해 필요한 것이 **백업 사이트(Backup Site)** 입니다.

여러분도 중요한 사진이나 문서를 **USB나 외장하드에 백업**해 놓거나, **클라우드 저장소**에 올려놓는 습관이 있다면, 이미 백업 사이트의 개념을 일상에서 실천하고 계신 겁니다.

### 🌡️ 백업 사이트의 4가지 유형

백업 사이트는 **복구 속도**와 **비용**에 따라 크게 4가지로 분류됩니다.

#### 🪞 미러 사이트(Mirror Site) - 즉시 복구

```
[미러 사이트 개념]
주 운영 센터 ←→ 백업 센터
    (실시간 동기화 - 100% 동일한 상태 유지)
```

- **복구 시간**: 즉시 (수 초 이내)
- **데이터 동기화**: 실시간 완전 동기화 (운영 센터와 100% 동일)
- **비용**: 가장 높음
- **적합한 환경**: 은행, 증권거래소, 국가 핵심 인프라 등 단 1초의 다운타임도 허용할 수 없는 시스템
- **특징**: 주 센터에 장애가 발생하면 백업 센터가 **즉시 자동으로** 서비스를 이어받습니다. 이것을 **실시간 이중화** 또는 **핫 스와핑**이라고도 합니다.

#### 🔥 핫 사이트(Hot Site) - 수 시간 내 복구

```
[핫 사이트 개념]
주 운영 센터 → (주기적 동기화) → 백업 센터
    (거의 동일한 수준의 장비와 환경 구축)
```

- **복구 시간**: 수 시간 이내
- **데이터 동기화**: 거의 실시간 (약간의 지연 있음)
- **비용**: 높음
- **적합한 환경**: 인터넷 쇼핑몰, 대형 포털 사이트 등 몇 시간의 다운타임은 감수할 수 있는 시스템
- **특징**: 미러 사이트보다 비용이 낮으면서도, 장애 발생 시 비교적 빠르게 서비스를 재개할 수 있습니다.

#### 🌡️ 웜 사이트(Warm Site) - 수일 내 복구

```
[웜 사이트 개념]
주 운영 센터 → (주기적 백업 전송) → 별도 백업 센터
    (기본 장비는 갖추고 있으나 데이터는 별도 전송 필요)
```

- **복구 시간**: 수일
- **데이터 동기화**: 주기적 백업 (일간, 주간 등)
- **비용**: 중간
- **적합한 환경**: 며칠의 다운타임을 감수할 수 있는 중소규모 시스템
- **특징**: 데이터를 직접 가져와서 복구해야 하므로 시간이 걸리지만, 핫 사이트보다 비용을 절감할 수 있습니다.

#### 🧊 콜드 사이트(Cold Site) - 수주~수개월 내 복구

```
[콜드 사이트 개념]
주 운영 센터 → (불규칙 백업) → 최소한의 시설만 갖춘 공간
    (장비도 최소화, 데이터도 별도 준비 필요)
```

- **복구 시간**: 수주~수개월
- **데이터 동기화**: 불규칙 (필요 시 별도 준비)
- **비용**: 가장 낮음
- **적합한 환경**: 장기간 다운타임을 감수할 수 있는 비핵심 시스템
- **특징**: 가장 저렴한 비용으로 운영할 수 있지만, 실제 재해 발생 시 복구에 매우 오랜 시간이 소요됩니다.

### 📊 4가지 백업 사이트 비교표

| 구분 | 복구 시간 | 비용 | 동기화 방식 | 적합한 용도 |
|---|---|---|---|---|
| **미러 사이트** | 즉시 (초 단위) | ⭐⭐⭐⭐⭐ 가장 높음 | 실시간 완전 동기화 | 금융, 국가 핵심 인프라 |
| **핫 사이트** | 수 시간 이내 | ⭐⭐⭐⭐ 높음 | 거의 실시간 동기화 | 대형 포털, 쇼핑몰 |
| **웜 사이트** | 수일 | ⭐⭐⭐ 중간 | 주기적 백업 | 중소규모 기업 시스템 |
| **콜드 사이트** | 수주~수개월 | ⭐ 가장 낮음 | 불규칙 백업 | 비핵심 시스템 |

:::tip 어떤 백업 사이트를 선택해야 할까?
백업 사이트를 선택할 때는 두 가지 요소를 반드시 함께 고려해야 합니다.

1. **데이터의 비즈니스 가치**: 서비스가 다운됐을 때 발생하는 비즈니스 손실이 얼마나 큰가?
2. **운영 비용**: 백업 사이트를 유지하는 데 드는 비용을 감당할 수 있는가?

이 두 가지를 균형 있게 고려하여 가장 효율적인 백업 사이트 유형을 선택해야 합니다. 비용이 부담되더라도 서비스 다운으로 인한 손실이 더 크다면 미러 사이트를, 비용을 최우선으로 고려한다면 콜드 사이트를 선택하는 식으로 결정합니다.
:::

---

## ⚠️ 주의사항 및 실전 팁

### 🚨 자주 하는 실수와 오해

**오해 1: 로그를 메모리에 오래 두면 무조건 나쁘다?**

로그 레코드 버퍼링은 성능 향상을 위한 **의도적인 설계**입니다. 메모리에 로그를 모아두는 것 자체는 문제가 아닙니다. 중요한 것은 **WAL 규약을 반드시 준수**하면서 적절한 시점에 저장하는 것입니다.

**오해 2: 체크포인트 간격은 짧을수록 좋다?**

체크포인트 간격이 너무 짧으면 체크포인트 작업 중에 다른 트랜잭션이 일시 정지되어 **전체 시스템 성능이 저하**됩니다. 아래한글의 자동 저장을 1분마다 하도록 설정하면 오히려 문서 작성이 불편해지는 것과 같은 이치입니다.

**오해 3: 그림자 페이징이 더 빠르니까 항상 그림자 페이징을 써야 한다?**

그림자 페이징은 **단일 사용자 환경**에서는 빠르지만, 현실의 데이터베이스처럼 **다수의 사용자가 동시에 접근**하는 환경에서는 병행 처리를 지원하지 못해 사용할 수 없습니다.

### 💡 실전 팁

:::tip WAL 확인하기
현재 사용 중인 데이터베이스가 WAL을 사용하는지 확인하고 싶다면, PostgreSQL의 경우 `pg_wal` 디렉토리를 확인하거나, `SHOW wal_level;` 명령으로 WAL 설정을 확인할 수 있습니다. MySQL/InnoDB의 경우 `innodb_log_files_in_group` 설정으로 로그 파일 수를 확인할 수 있습니다.
:::

:::tip 체크포인트 설정 가이드
실무에서 체크포인트 간격을 설정할 때는 다음을 고려하세요:
- 트랜잭션의 평균 처리 시간
- 허용 가능한 회복 시간(RTO: Recovery Time Objective)
- 허용 가능한 데이터 손실 범위(RPO: Recovery Point Objective)

대부분의 DBMS는 이를 자동으로 조정하는 기능을 제공하므로, 처음에는 기본값을 사용하고 성능 모니터링 결과를 바탕으로 조정하는 것이 좋습니다.
:::

---

## 📌 핵심 정리

이번 문서에서 다룬 내용을 핵심만 간추려 정리합니다.

- **로그 파일**은 데이터 변경 작업이 발생할 때마다 한 줄씩 자동으로 생성된다.
- **로그 레코드 버퍼링**은 I/O 횟수를 줄이기 위해 로그를 즉시 저장하지 않고 메모리에 모아뒀다가 한꺼번에 저장하는 기법이다.
- **WAL(Write-Ahead Logging, 로그 우선 기록 규약)** 은 일반 데이터보다 로그를 반드시 먼저 하드디스크에 저장해야 한다는 규칙이다.
- **WAL을 지키지 않으면** 로그 없이 데이터만 저장된 상황이 발생해 복구가 불가능해질 수 있다.
- **체크포인트**는 일정 시간 간격으로 데이터를 강제 저장하여, 불필요한 REDO 연산을 줄이고 회복 시간을 단축시킨다.
- **체크포인트 이전에 커밋이 완료된 트랜잭션**은 REDO도 UNDO도 수행하지 않는다.
- **체크포인트 작업 순서**: 로그 레코드 저장 → 일반 데이터 저장 → 체크포인트 로그 기록
- **그림자 페이징**은 현재 페이지(메모리)와 그림자 페이지(하드디스크)를 이용하며, 로그를 사용하지 않는 No-Undo/No-Redo 기법이다.
- **그림자 페이징의 가장 큰 단점**은 병행 처리(동시 다중 사용자 접근)를 지원하지 못한다는 것이다.
- **4가지 회복 기법 유형**: No-Undo/Redo(지연갱신), Undo/No-Redo(즉시갱신 완전저장보장), Undo/Redo(즉시갱신 일반), No-Undo/No-Redo(그림자 페이징)
- **ARIES 기법**은 회복 작업 중 오류가 발생해도 이미 완료한 회복을 반복하지 않도록 회복 중에도 로그를 기록하는 고급 회복 알고리즘이다.
- **ARIES는 3단계**로 동작한다: 분석(Analysis) → REDO → UNDO
- **백업 사이트**는 물리적 재해에 대비하기 위한 별도의 데이터 보관 시설이다.
- **미러 사이트**는 실시간 완전 동기화로 즉시 복구, **핫 사이트**는 수 시간 복구, **웜 사이트**는 수일 복구, **콜드 사이트**는 수주~수개월 복구가 가능하다.
- 백업 사이트 유형 선택 시에는 **데이터의 비즈니스 가치**와 **운영 비용**을 함께 고려해야 한다.

---

작성일: 2026-02-21