---
title: "I/O 횟수 최소화와 데이터베이스 성능 향상"
description: "I/O 횟수 최소화와 데이터베이스 성능 향상에 대해 초보자도 쉽게 이해할 수 있도록 설명합니다."
slug: "/database-recovery-advanced/3-io-optimization-and-output-reduction"
sidebar_label: "I/O 최적화"
date: "2026-02-21"
---

# 🗄️ I/O 횟수 최소화와 데이터베이스 성능 향상

데이터베이스를 운영하다 보면 "왜 이렇게 느리지?"라는 질문을 자주 하게 됩니다. 그 원인의 상당수는 바로 **I/O(Input/Output, 입출력) 횟수**가 너무 많기 때문입니다. 이번 문서에서는 데이터베이스가 어떻게 I/O 횟수를 줄여 성능을 높이는지, 그리고 안전한 복구(Recovery)를 위해 어떤 고급 기법들을 사용하는지 아주 쉽고 자세하게 살펴보겠습니다.

:::info 이전 시간 복습
지난 시간에는 데이터베이스 회복의 기본 원리를 배웠습니다.
- **덤프(Dump)**: 데이터베이스 전체를 특정 시점에 백업해두는 것
- **로그(Log)**: 트랜잭션(작업 묶음)이 수행될 때마다 변경 내역을 기록하는 파일
- **지연 갱신 기법**: 커밋(작업 확정) 전까지 실제 저장을 미루는 방법 → Redo(재실행)만 필요
- **즉시 갱신 기법**: 변경 즉시 저장하는 방법 → Undo(취소) 또는 Redo 필요
:::

---

## 🔍 I/O란 무엇이고, 왜 줄여야 할까?

### I/O의 개념 이해하기

**I/O**란 **Input(입력)/Output(출력)**의 줄임말로, 컴퓨터가 하드디스크(저장장치)와 데이터를 주고받는 행위를 말합니다. 우리가 컴퓨터로 작업할 때 데이터는 다음과 같은 경로로 이동합니다.

```
하드디스크 → 메모리(RAM) → CPU(처리) → 메모리(RAM) → 하드디스크
```

이 흐름을 좀 더 구체적으로 용어와 함께 정리하면 다음과 같습니다.

| 동작 방향 | 용어 | 설명 |
|---|---|---|
| 하드디스크 → 메모리 | **Input(인풋)** | 저장된 데이터를 메모리로 불러오기 |
| 메모리 → CPU | **Read(리드)** | 메모리에서 CPU로 데이터 읽기 |
| CPU → 메모리 | **Write(라이트)** | CPU가 처리한 결과를 메모리에 쓰기 |
| 메모리 → 하드디스크 | **Output(아웃풋)** | 메모리의 데이터를 하드디스크에 저장하기 |

> 💡 **핵심**: 이 네 단계 중 가장 시간이 오래 걸리는 부분은 **하드디스크와 메모리 사이의 I/O(Input/Output)**입니다. CPU와 메모리 간의 Read/Write는 매우 빠르지만, 하드디스크는 물리적인 장치이기 때문에 속도가 훨씬 느립니다.

### 왜 I/O 횟수가 많으면 성능이 떨어질까?

마치 **편의점에서 물건을 하나씩 계산하는 것**과 같습니다. 10개의 물건을 살 때 한 번에 모아서 계산하면 금방 끝나지만, 물건 하나 살 때마다 계산대에 줄을 서고, 계산하고, 영수증 받고를 반복하면 엄청나게 오래 걸리겠죠? 데이터베이스도 마찬가지입니다.

만약 10만 개의 레코드(데이터 행)를 처리한다면, 처리할 때마다 하드디스크에 저장하는 방식은 **10만 번의 I/O**가 발생합니다. 반면 메모리에 모아뒀다가 한 번에 저장하면 **단 1번의 I/O**만 발생합니다. 이 차이가 곧 **데이터베이스 성능의 차이**로 나타납니다.

:::warning I/O 횟수 주의
트랜잭션(작업 묶음)을 처리할 때마다 매번 하드디스크에 저장(Output)하면 성능이 급격히 저하됩니다. 실무에서는 반드시 **버퍼링(Buffering, 메모리에 모아두기)** 기법을 활용해야 합니다.
:::

---

## 📦 로그 레코드 버퍼링 — 메모리에 모아서 한꺼번에 저장하자

### 로그 레코드란 무엇인가?

데이터베이스에서 **트랜잭션(작업 묶음)**이 수행될 때마다 **로그 레코드(Log Record)**가 생성됩니다. 로그 레코드는 "어떤 데이터가, 어떤 값에서, 어떤 값으로 바뀌었는가"를 기록하는 일종의 **작업 일지**입니다. 마치 공사 현장에서 매일 작업 일지를 작성하는 것처럼, 데이터베이스도 모든 변경 작업을 로그로 남깁니다.

예를 들어, 데이터 X의 값을 100에서 200으로 변경하면 다음과 같은 로그 레코드가 생성됩니다.

```sql
-- 로그 레코드 예시 (개념적 표현)
-- [트랜잭션 ID] [대상 데이터] [변경 전 값] [변경 후 값]
T1, X, 100, 200   -- T1 트랜잭션이 X를 100에서 200으로 변경
T1, Y, 50, 150    -- T1 트랜잭션이 Y를 50에서 150으로 변경
```

만약 처리해야 하는 데이터가 **10만 개**라면, 로그 레코드도 최소 **10만 줄** 이상 생성됩니다. 하나하나 처리할 때마다 로그가 만들어지기 때문입니다.

### 버퍼링 없이 처리하면 어떻게 될까? (❌ 나쁜 방식)

```
레코드 1 처리 → 로그 생성 → 하드디스크에 로그 저장
레코드 2 처리 → 로그 생성 → 하드디스크에 로그 저장
레코드 3 처리 → 로그 생성 → 하드디스크에 로그 저장
...
레코드 100,000 처리 → 로그 생성 → 하드디스크에 로그 저장
```

이 방식은 **10만 번의 하드디스크 I/O**가 발생합니다. 엑셀 작업을 예로 들어보겠습니다. 셀 하나를 더할 때마다 Ctrl+S를 눌러서 저장하고, 또 더하고, 또 저장하고... 이렇게 작업하는 사람은 없겠죠? 너무 비효율적이니까요.

### 버퍼링을 활용한 효율적인 처리 (✅ 좋은 방식)

```
레코드 1 처리 → 로그 생성 → [메모리(로그 버퍼)에 임시 저장]
레코드 2 처리 → 로그 생성 → [메모리(로그 버퍼)에 임시 저장]
레코드 3 처리 → 로그 생성 → [메모리(로그 버퍼)에 임시 저장]
...
레코드 100,000 처리 → 로그 생성 → [메모리(로그 버퍼)에 임시 저장]
↓
커밋(작업 확정) 시점에 한꺼번에 → 하드디스크에 저장 (단 1회 I/O!)
```

이것이 바로 **로그 레코드 버퍼링(Log Record Buffering)**입니다. 메모리 안에 **로그 버퍼(Log Buffer)**라는 임시 저장 공간을 만들어두고, 로그 레코드들을 그곳에 모아뒀다가 적절한 시점에 한꺼번에 하드디스크로 저장하는 방식입니다.

> 📌 **비유**: 마치 은행에서 하루 동안 발생한 모든 거래를 장부에 기록해뒀다가, 영업 종료 후 한꺼번에 전산 시스템에 입력하는 것과 같습니다. 물론 실제 은행은 실시간 처리를 하지만, 개념적으로는 "모아서 처리"하는 원리와 같습니다.

:::tip 로그 버퍼링의 핵심 효과
- **I/O 횟수 대폭 감소**: 매번 저장하던 것을 모아서 한 번에 저장
- **CPU 처리 효율 향상**: I/O 대기 시간이 줄어 CPU가 더 많은 작업을 처리 가능
- **전체 데이터베이스 처리 속도 향상**: 트랜잭션 처리 속도가 크게 빨라짐
:::

### 버퍼링의 문제점 — 메모리는 휘발성이다

그런데 여기서 심각한 문제가 생깁니다. **메모리(RAM)는 휘발성(Volatile)**입니다. 즉, 전원이 꺼지거나 시스템이 갑자기 종료되면 메모리에 저장된 모든 데이터가 사라집니다.

로그 버퍼에 열심히 로그 레코드를 모아뒀는데, 시스템 장애가 발생하면? 모아둔 로그 레코드가 전부 사라집니다. 그러면 복구에 필요한 로그가 없으니 **데이터베이스를 복구할 수 없는 최악의 상황**이 발생합니다.

이 문제를 해결하기 위한 규칙이 바로 다음에 설명할 **로그 우선 기록 규약(WAL)**입니다.

---

## 📝 로그 우선 기록 규약 (WAL — Write-Ahead Logging)

### 왜 이 규약이 필요한가?

메모리에는 두 종류의 데이터가 존재합니다.

1. **일반 데이터 버퍼**: 실제 처리 중인 데이터 (예: 고객 정보, 주문 내역 등)
2. **로그 버퍼**: 변경 내역을 기록한 로그 레코드들

이 두 가지를 모두 하드디스크에 저장해야 하는데, **어떤 것을 먼저 저장해야 할까요?** 하드디스크는 동시에 두 가지를 저장할 수 없으므로, 반드시 순서를 정해야 합니다.

### 잘못된 순서 — 일반 데이터 먼저 저장 (❌)

```
[시나리오]
1단계: 일반 데이터를 하드디스크에 저장 → ✅ 성공
2단계: 로그 레코드를 하드디스크에 저장 → ❌ 에러 발생!

[결과]
- 일반 데이터: 하드디스크에 저장됨
- 로그 레코드: 저장 실패, 사라짐
- 문제: 복구하려고 보니 로그가 없음! → 복구 불가능 😱
```

일반 데이터는 저장됐지만 로그가 없기 때문에, 만약 나중에 이 데이터에 문제가 생겨도 **어떻게 되돌려야 할지 알 수 없습니다**. 마치 요리를 다 만들었는데 레시피를 잃어버린 것처럼, 같은 요리를 다시 재현할 수도, 실수를 수정할 수도 없게 됩니다.

### 올바른 순서 — 로그 먼저 저장 (✅ WAL 규약)

```
[시나리오 A: 로그 저장 중 에러 발생]
1단계: 로그 레코드를 하드디스크에 저장 → ❌ 에러 발생!
2단계: 일반 데이터 저장 → 진행 안 됨

[결과]
- 로그: 저장 실패
- 일반 데이터: 저장 안 됨
- 문제 없음! 아무 작업도 안 한 것과 동일 → 복구 필요 없음 ✅

---

[시나리오 B: 데이터 저장 중 에러 발생]
1단계: 로그 레코드를 하드디스크에 저장 → ✅ 성공
2단계: 일반 데이터를 하드디스크에 저장 → ❌ 에러 발생!

[결과]
- 로그: 안전하게 저장됨
- 일반 데이터: 저장 실패
- 해결 가능! 로그를 이용해서 복구 가능 ✅
```

> 💡 **WAL의 핵심 원칙**: "**로그 레코드를 먼저 안전한 저장장치에 기록하지 않으면, 일반 데이터를 절대 하드디스크에 출력(Output)하지 않는다.**"

이것이 바로 **WAL(Write-Ahead Logging, 로그 우선 기록 규약)**입니다. 영어 이름 그대로 "미리(Ahead) 로그를 기록(Write Logging)하라"는 뜻입니다.

```
WAL 규약 요약:
로그 레코드 저장 → 일반 데이터 저장
(이 순서를 절대 바꾸면 안 됨!)
```

### WAL이 보장하는 것 — 원자성(Atomicity)

WAL을 지킴으로써 데이터베이스는 트랜잭션의 **원자성(Atomicity, 작업이 전부 성공하거나 전부 실패하거나 둘 중 하나여야 하는 성질)**을 보장할 수 있습니다.

- **로그가 있으면**: 성공한 트랜잭션은 Redo(재실행), 실패한 트랜잭션은 Undo(취소) 가능
- **로그가 없으면**: 무엇을 Redo하고 무엇을 Undo해야 할지 알 수 없음

:::danger 절대 하면 안 되는 것
일반 데이터를 먼저 하드디스크에 저장하고, 로그를 나중에 저장하는 방식은 **절대로 사용하면 안 됩니다**. 로그 저장 중 에러가 발생하면 복구가 완전히 불가능해지는 치명적인 상황이 발생합니다.
:::

---

## ⏱️ 체크포인트 — 불필요한 Redo를 줄여 복구 속도를 높이자

### 로그만으로는 부족한 이유

WAL 규약을 통해 로그를 안전하게 관리하더라도, 한 가지 큰 문제가 남아있습니다. 바로 **복구 시간**입니다.

100만 개의 레코드를 처리했다면 로그 파일에는 최소 100만 줄이 기록됩니다. 장애가 발생해서 복구를 해야 할 때, 로그 파일은 **무조건 처음부터 끝까지 전부 읽어서 처리**해야 합니다.

그런데 생각해보면, 이미 오래 전에 커밋(작업 확정)이 완료되고 하드디스크에도 안전하게 저장된 트랜잭션들이 있습니다. 이런 트랜잭션들은 **굳이 Redo(재실행)를 할 필요가 없습니다**. 하지만 로그를 처음부터 읽다 보면 이미 완료된 작업들도 다시 Redo하게 되는 비효율이 발생합니다.

> 📌 **비유**: 1년치 가계부를 전부 다시 검토해서 오늘 잔액을 계산하는 것과 같습니다. 6개월 전 데이터는 이미 검증이 끝났는데도, 처음부터 다시 보는 것은 낭비입니다. 차라리 6개월 전에 "이때까지는 다 확인 완료!"라는 표시를 해뒀다면, 그 이후 데이터만 보면 되겠죠.

### 체크포인트(Checkpoint)의 개념

**체크포인트(Checkpoint, 검사점)**는 일정한 시간 간격으로 "현재까지의 모든 데이터를 안전하게 저장했다"는 표식을 남기는 작업입니다. 여러분이 워드나 한글 문서 작업을 할 때 사용하는 **자동 저장 기능**과 정확히 같은 개념입니다.

한글 프로그램에서 자동 저장 간격을 10분으로 설정하면, 10분마다 자동으로 파일을 저장합니다. 데이터베이스의 체크포인트도 이와 동일하게, 일정 간격으로 메모리의 모든 데이터를 하드디스크에 저장하고 "이 시점까지는 안전하게 저장 완료!"라는 정보를 로그에 남깁니다.

### 체크포인트 시점에 수행하는 작업 순서

체크포인트가 발생하면 다음 순서로 작업이 수행됩니다. **이 순서는 매우 중요합니다.**

```
[체크포인트 작업 순서]

1️⃣ 메모리의 로그 레코드(로그 버퍼)를 하드디스크에 저장
   (WAL 규약에 따라 로그를 항상 먼저 저장)

2️⃣ 메모리의 일반 데이터(데이터 버퍼)를 하드디스크에 저장

3️⃣ 체크포인트 정보가 담긴 로그 레코드를 하드디스크에 저장
   (언제 체크포인트가 있었는지 기록)
```

:::note 왜 3단계로 나뉘는가?
WAL 규약에 따라 로그를 먼저 저장하고, 그다음 일반 데이터를 저장합니다. 마지막으로 "체크포인트가 완료되었다"는 정보 자체도 로그에 기록하는데, 이것이 나중에 복구 시 "어디서부터 Redo를 시작해야 하는가"를 알려주는 기준점이 됩니다.
:::

### 체크포인트와 함께하는 복구 알고리즘

체크포인트를 이용한 복구는 다음과 같은 순서로 수행됩니다.

```
[체크포인트를 이용한 복구 알고리즘]

Step 1: Undo 리스트와 Redo 리스트 두 개의 빈 목록 생성

Step 2: 체크포인트 설정 당시 활동 중이던 트랜잭션들을 모두 Undo 리스트에 추가

Step 3: 체크포인트 이후 새로 시작된(Start된) 트랜잭션들도 모두 Undo 리스트에 추가

Step 4: 로그를 검색하면서 커밋(Commit)이 있는 트랜잭션을 발견하면,
        Undo 리스트에서 제거하고 Redo 리스트로 이동

Step 5: Undo 리스트의 트랜잭션들은 역방향(최신→과거)으로 Undo 연산 수행

Step 6: Redo 리스트의 트랜잭션들은 순방향(과거→최신)으로 Redo 연산 수행
```

### 실제 예시로 이해하는 체크포인트

다음 그림을 보면서 이해해 봅시다. 5개의 트랜잭션이 있고, 중간에 체크포인트가 설정되었으며, 이후 어느 시점에 장애(에러)가 발생했다고 가정합니다.

```
시간 흐름 ──────────────────────────────────────────────────►

T1: ──[START]────────[COMMIT]──────────────────────────────────
T2:           ──[START]──────────────────────[COMMIT]──────────
T3:                   ──[START]────────────────────────────────  (COMMIT 없음)
T4:                          ──[START]────────[COMMIT]──────────
T5:                                   ──[START]─────────────────  (COMMIT 없음)

                              ▲                        ▲
                         체크포인트                  장애 발생
```

이 상황에서 각 트랜잭션의 상태를 분석하면 다음과 같습니다.

| 트랜잭션 | 커밋 여부 | 체크포인트와의 관계 | 처리 방법 |
|---|---|---|---|
| **T1** | ✅ 커밋 있음 | 체크포인트 이전에 커밋 완료 | **아무것도 안 함** (이미 안전하게 저장됨) |
| **T2** | ✅ 커밋 있음 | 체크포인트 당시 활동 중, 이후 커밋 | **Redo 수행** (체크포인트 이후 부분만) |
| **T3** | ❌ 커밋 없음 | 체크포인트 당시 활동 중 | **Undo 수행** (전체 취소) |
| **T4** | ✅ 커밋 있음 | 체크포인트 이후 시작, 커밋 완료 | **Redo 수행** (전체) |
| **T5** | ❌ 커밋 없음 | 체크포인트 이후 시작 | **Undo 수행** (전체 취소) |

**체크포인트가 없었다면** T1, T2, T4 모두 Redo 연산을 해야 합니다. 하지만 **체크포인트 덕분에** T1은 Redo 연산 없이 건너뛸 수 있습니다. 이것이 체크포인트의 핵심 효과입니다.

> 🎯 **체크포인트의 핵심**: "**체크포인트 이전에 커밋이 완료된 트랜잭션은 Undo도 Redo도 하지 않는다.**"

### 체크포인트 간격 설정의 중요성

체크포인트 간격은 너무 짧아도, 너무 길어도 문제가 됩니다.

| 간격 설정 | 장점 | 단점 |
|---|---|---|
| **너무 짧게** | 장애 시 복구 범위가 작음 | 체크포인트 수행 중 다른 트랜잭션 중단 → 성능 저하 |
| **너무 길게** | 체크포인트 빈도가 낮아 성능에 영향 적음 | 장애 시 복구해야 하는 범위가 넓어짐 |
| **적절하게** | 성능과 복구 효율의 균형 | — |

:::tip 한글 자동 저장 간격 예시
실제로 한글(HWP) 프로그램에서 자동 저장 간격을 1분으로 너무 짧게 설정하면, 작업 중 자꾸 저장이 일어나면서 컴퓨터가 버벅이는 현상이 생깁니다. 이것이 바로 체크포인트 간격을 너무 짧게 설정했을 때의 문제입니다. 보통 10분~30분 정도로 적절하게 설정하는 것이 좋습니다.
:::

:::danger 체크포인트 수행 중 주의사항
체크포인트가 수행되는 동안에는 다른 트랜잭션 작업이 **일시적으로 중단**됩니다. 따라서 체크포인트 간격을 너무 짧게 설정하면 시스템 전체 성능이 크게 저하됩니다.
:::

---

## 👻 그림자 페이징 — 로그 없이 복구하는 방법

### 그림자 페이징이란?

지금까지 살펴본 회복 기법들은 모두 **로그(Log)**를 이용했습니다. 그런데 로그를 사용하면 로그 파일 생성, 저장, 관리에 드는 비용(저장 공간, 처리 시간)이 발생합니다. **그림자 페이징(Shadow Paging)**은 로그를 전혀 사용하지 않고 복구를 수행하는 방법입니다.

그림자 페이징은 **No Undo, No Redo** 기법으로 분류됩니다. 즉, Undo 연산도 Redo 연산도 필요 없습니다.

### 그림자 페이징의 구조 — 두 개의 페이지

그림자 페이징은 두 종류의 페이지(Page, 데이터를 저장하는 단위 블록)를 사용합니다.

| 페이지 종류 | 저장 위치 | 역할 |
|---|---|---|
| **현재 페이지 (Current Page)** | 메모리 | 현재 트랜잭션이 작업 중인 페이지 |
| **그림자 페이지 (Shadow Page)** | 하드디스크 | 작업 시작 전의 원본 데이터를 보관하는 페이지 |

마치 **문서 작업을 할 때 원본 파일은 따로 보관하고, 복사본에서 작업하는 것**과 같은 원리입니다. 원본(그림자 페이지)은 절대 건드리지 않고, 복사본(현재 페이지)에서만 수정 작업을 합니다.

### 그림자 페이징의 동작 원리

```
[초기 상태]
하드디스크(그림자 페이지): [100]
메모리(현재 페이지):      [100]  ← 그림자 페이지와 동일한 값으로 시작

[작업 수행 중]
트랜잭션이 100을 200으로 변경하려 함

메모리(현재 페이지): [200]  ← 현재 페이지만 변경
하드디스크(그림자 페이지): [100]  ← 그림자 페이지는 그대로 유지

[장애 발생 시 — Undo 없이 복구]
하드디스크(그림자 페이지): [100]을 메모리(현재 페이지)에 덮어씌우면 끝!
→ 원래 값 100으로 즉시 복구 ✅

[성공적으로 커밋된 경우 — 완료 처리]
메모리(현재 페이지): [200]을 하드디스크(그림자 페이지)에 덮어씌우면 끝!
→ 그림자 페이지도 200으로 업데이트 ✅
```

이 과정을 코드로 개념적으로 표현하면 다음과 같습니다.

```python
# 그림자 페이징 개념 코드 (Python 의사코드)

class ShadowPaging:
    def __init__(self, original_value):
        # 하드디스크에 있는 그림자 페이지 (원본 보관)
        self.shadow_page = original_value      # 100 (하드디스크에 안전하게 보관)
        # 메모리에 있는 현재 페이지 (작업용)
        self.current_page = original_value     # 100 (메모리에서 작업)

    def update(self, new_value):
        # 현재 페이지(메모리)만 변경, 그림자 페이지(하드디스크)는 건드리지 않음
        self.current_page = new_value          # 200으로 변경 (그림자는 여전히 100)

    def rollback(self):
        # 장애 발생 시: 그림자 페이지로 현재 페이지를 복원 (로그 없이 즉시 복구!)
        self.current_page = self.shadow_page   # 다시 100으로 되돌림

    def commit(self):
        # 성공 시: 현재 페이지의 값을 그림자 페이지에도 반영
        self.shadow_page = self.current_page   # 그림자도 200으로 업데이트
```

### 그림자 페이징의 장점과 단점

**장점:**
- **처리 속도가 매우 빠름**: 로그를 쓰는 오버헤드(추가 비용)가 없어, 복구 작업이 그림자 페이지를 덮어씌우는 것만으로 끝납니다.
- **회복 작업이 단순함**: 복잡한 Undo/Redo 연산 대신, 그냥 덮어씌우면 됩니다.

**단점:**
- **저장 공간이 추가로 필요함**: 현재 페이지와 그림자 페이지 두 개를 항상 유지해야 합니다.
- **데이터 단편화(Fragmentation) 발생**: 페이지를 다른 곳에 쓰고, 또 다른 곳에 쓰다 보면 데이터가 물리적으로 흩어져 조각이 생깁니다. 마치 퍼즐 조각이 여기저기 흩어진 것처럼, 이렇게 되면 전체 시스템 성능이 떨어집니다.
- **가비지(Garbage, 쓰레기 데이터) 수집 필요**: 더 이상 필요 없게 된 페이지들이 디스크에 남아 쓰레기 공간이 됩니다.
- **병행 처리 불가**: 가장 치명적인 단점입니다. 동시에 여러 트랜잭션이 처리되는 **병행 처리(Concurrent Processing)**를 지원하지 못합니다.

:::warning 그림자 페이징의 치명적 한계
실제 데이터베이스 시스템에서는 수많은 사용자가 동시에 접속해 데이터를 처리합니다. 그림자 페이징은 이런 **병행(동시) 처리를 지원하지 못하기** 때문에, 단독으로 사용하는 것은 현실적으로 어렵습니다. 이 단점을 보완하기 위해 로그 기법과 그림자 페이징을 결합한 방식을 사용하기도 합니다.
:::

---

## 🔄 데이터베이스 복구 알고리즘 정리

지금까지 배운 내용을 포함해, 데이터베이스 복구 알고리즘은 크게 4가지 방식으로 분류할 수 있습니다.

| 기법 | Undo | Redo | 설명 |
|---|---|---|---|
| **No Undo, Redo** | ❌ | ✅ | 지연 갱신 기법. 커밋 전까지 저장 안 하므로 Undo 불필요, 커밋된 것만 Redo |
| **Undo, No Redo** | ✅ | ❌ | 즉시 갱신 기법 (100% 저장 보장). 이미 모두 저장됐으므로 Redo 불필요, 실패한 것만 Undo |
| **Undo, Redo** | ✅ | ✅ | 즉시 갱신 기법 (일반). 커밋 없으면 Undo, 커밋 있으면 Redo |
| **No Undo, No Redo** | ❌ | ❌ | 그림자 페이징 기법. 로그 없이 페이지 교체로 복구 |

---

## 🏥 ARIES — 복구 중에 에러가 나면 어떻게 할까?

### ARIES란?

복구 작업 자체도 실패할 수 있습니다. 예를 들어 전체 복구 작업의 90%를 완료했는데 갑자기 에러가 발생했다면, 처음부터 다시 복구를 시작해야 할까요? 이것은 매우 비효율적입니다.

**ARIES(Algorithms for Recovery and Isolation Exploiting Semantics)**는 이 문제를 해결하기 위한 복구 알고리즘입니다. 핵심 아이디어는 **복구 작업 자체도 로그로 기록하자**는 것입니다.

### ARIES의 핵심 원리

```
[기존 방식의 문제]
복구 작업 90% 완료 → 에러 발생 → 처음부터 다시 복구 시작 😭
(90% 한 작업이 전부 허사!)

[ARIES의 해결 방법]
복구 작업 수행 중에도 로그를 남긴다!

Redo 작업 수행 시 → 로그 기록
Undo 작업 수행 시 → 로그 기록 (CLR: Compensation Log Record)

에러 발생해도 → 로그를 보고 이미 완료된 작업은 건너뜀
나머지 10%만 마저 수행 ✅
```

**CLR(Compensation Log Record, 보상 로그 레코드)**은 Undo 작업을 수행했다는 것을 기록하는 특수한 로그입니다. "이 작업은 이미 취소(Undo)했다"는 표식을 남겨, 복구 도중 에러가 생겨도 이미 취소한 작업을 다시 취소하는 일이 없도록 합니다.

### ARIES의 3단계 작업

```
[ARIES 3단계]

1단계 — 분석(Analysis):
로그를 분석하여 장애 시점에 활동 중이던 트랜잭션 파악
→ 무엇을 Undo하고, 무엇을 Redo해야 하는지 결정

2단계 — Redo(재실행):
커밋된 트랜잭션들을 로그 순서대로 재실행
(WAL 규약에 따라 로그를 먼저 기록하며 진행)

3단계 — Undo(취소):
커밋되지 않은 트랜잭션들을 역순으로 취소
(이미 취소된 작업은 CLR 덕분에 건너뜀)
```

:::tip ARIES의 핵심 효과
- **Undo 작업 중복 방지**: CLR 덕분에 이미 완료된 Undo는 다시 하지 않음
- **복구 효율 극대화**: 복구 도중 에러가 나도 처음부터 다시 하지 않아도 됨
- **WAL 규약 준수**: 복구 작업 중에도 항상 로그를 먼저 기록
:::

---

## 💾 백업 센터의 종류 — 얼마나 빠르게 복구해야 하는가?

### 백업(Dump)의 개념

**백업(Backup)**은 데이터베이스를 특정 시점의 상태로 복사해두는 작업입니다. 앞서 배운 덤프(Dump)와 동일한 개념입니다. 백업 주기는 데이터의 중요도와 비용을 고려해서 결정합니다.

- 매우 중요한 데이터: 실시간 백업
- 중요한 데이터: 매일 백업
- 일반 데이터: 주간 또는 월간 백업

### 백업 센터의 4가지 유형

실제 기업에서는 별도의 **백업 센터(재해 복구 센터)**를 운영합니다. 백업 센터의 유형은 복구 속도와 비용에 따라 4가지로 분류됩니다.

| 유형 | 복구 시간 | 특징 | 비용 | 예시 |
|---|---|---|---|---|
| **미러 사이트 (Mirror Site)** | 즉시 (수초 이내) | 실시간 동기식 복제, 100% 동일한 시스템 운영 | 매우 높음 | 은행, 증권 거래소 |
| **핫 사이트 (Hot Site)** | 수 시간 이내 | 주 센터와 유사한 수준의 장비 갖춤 | 높음 | 대형 포털, 전자상거래 |
| **웜 사이트 (Warm Site)** | 수일 이내 | 별도 센터에 데이터를 주기적으로 복사 | 중간 | 중소기업 |
| **콜드 사이트 (Cold Site)** | 수주~한 달 | 최소한의 기본 시설만 갖춤 | 낮음 | 중요도 낮은 시스템 |

### 각 유형 자세히 살펴보기

**🪞 미러 사이트 (Mirror Site)**

미러(Mirror)란 거울이라는 뜻입니다. 주 운영 센터와 **100% 동일한 시스템**을 갖추고, 데이터가 발생하는 즉시 백업 센터에도 똑같이 반영합니다. 주 센터에 장애가 발생하면 백업 센터가 즉시 주 센터 역할을 대신합니다. 이를 **실시간 이중화**라고 하며, 가장 안전하지만 비용이 가장 많이 드는 방식입니다. 은행이나 주식 거래소처럼 1초도 서비스가 중단되면 안 되는 곳에서 사용합니다.

**🔥 핫 사이트 (Hot Site)**

미러 사이트처럼 완전히 동기화되지는 않지만, 주 센터와 유사한 수준의 장비와 데이터를 갖추고 있어 **수 시간 내에 복구**가 가능한 방식입니다. 대형 포털 사이트나 전자상거래 플랫폼처럼 빠른 복구가 필요하지만 미러 사이트를 운영하기에는 비용 부담이 큰 곳에서 사용합니다.

**🌡️ 웜 사이트 (Warm Site)**

백업 데이터를 별도의 센터에 **주기적으로 복사**해두지만, 완전한 환경은 아니어서 복구에 **며칠** 정도 소요됩니다. 데이터를 가져오고, 시스템을 구성하고, 복구하는 과정이 필요합니다. 비용과 복구 속도의 균형을 맞춰야 하는 중소기업에서 많이 사용합니다.

**❄️ 콜드 사이트 (Cold Site)**

가장 기본적인 시설만 갖춘 백업 센터입니다. 장애가 발생하면 데이터를 가져와 시스템을 처음부터 구성해야 하므로 **수 주에서 한 달** 정도의 복구 시간이 필요합니다. 비용이 가장 적게 들지만, 복구에 가장 오래 걸립니다. 서비스 중단이 어느 정도 허용되는 시스템에서 사용합니다.

:::info 백업 센터 선택 기준
백업 센터의 유형은 다음 두 가지를 고려해서 결정합니다.
1. **데이터의 비즈니스 가치**: 서비스가 중단되었을 때 얼마나 큰 손실이 발생하는가?
2. **운영 비용**: 얼마까지 비용을 투자할 수 있는가?

비용과 가치의 균형점을 찾아 가장 효율적인 방식을 선택해야 합니다.
:::

---

## ⚠️ 주의사항과 실무 팁

### 자주 하는 실수들

**1. WAL을 무시하고 데이터 먼저 저장하는 설계**

```python
# ❌ 잘못된 방식 — 데이터를 먼저 저장하면 절대 안 됨!
def wrong_save(data, log):
    save_to_disk(data)   # 일반 데이터 먼저 저장 (위험!)
    save_to_disk(log)    # 로그는 나중에 저장
    # 만약 로그 저장 중 에러 발생 → 복구 불가능!

# ✅ 올바른 방식 — 반드시 로그를 먼저!
def correct_save(data, log):
    save_to_disk(log)    # 로그 먼저 저장 (WAL 규약 준수!)
    save_to_disk(data)   # 데이터는 그 다음에 저장
    # 만약 데이터 저장 중 에러 발생 → 로그로 복구 가능 ✅
```

**2. 체크포인트 간격을 너무 짧게 설정**

```
# ❌ 너무 짧은 체크포인트 간격
checkpoint_interval = 30  # 30초마다 체크포인트 → 성능 심각하게 저하

# ✅ 적절한 체크포인트 간격
checkpoint_interval = 600  # 10분마다 체크포인트 → 성능과 안전성의 균형
```

**3. 로그 파일 크기를 무시하고 방치**

로그 레코드는 트랜잭션이 수행될 때마다 계속 쌓입니다. 관리하지 않으면 로그 파일이 무한정 커져 저장 공간이 부족해집니다. 체크포인트를 기점으로 불필요해진 오래된 로그는 주기적으로 정리(Archiving 또는 삭제)해야 합니다.

### 실무에서 알아두면 좋은 팁

:::tip 실무 팁 모음
1. **로그 파일은 별도의 디스크에 저장**: 데이터 파일과 로그 파일이 같은 디스크에 있으면, 디스크 장애 시 둘 다 손실될 수 있습니다. 반드시 다른 물리적 디스크에 분리해서 저장하세요.

2. **정기적인 백업 테스트**: 백업을 해뒀다고 안심하지 말고, 주기적으로 실제 복구가 가능한지 테스트해야 합니다.

3. **체크포인트 간격은 시스템 부하에 맞게**: 트랜잭션이 많이 발생하는 시스템은 체크포인트 간격을 조금 길게, 적게 발생하는 시스템은 짧게 설정하는 것이 좋습니다.

4. **그림자 페이징은 단독으로 사용하지 말 것**: 병행 처리가 필요한 실제 데이터베이스 환경에서는 그림자 페이징 단독 사용이 불가능합니다.
:::

---

## 📚 핵심 정리

이번 문서에서 배운 핵심 개념들을 정리합니다.

- **I/O(입출력)**는 하드디스크와 메모리 사이의 데이터 이동으로, 횟수가 많을수록 성능이 저하된다.
- **로그 레코드 버퍼링**은 로그를 메모리(로그 버퍼)에 모아뒀다가 한꺼번에 저장해 I/O 횟수를 줄이는 기법이다.
- **메모리는 휘발성**이므로 시스템 장애 시 로그 버퍼에 있는 데이터가 사라질 위험이 있다.
- **WAL(Write-Ahead Logging, 로그 우선 기록 규약)**은 일반 데이터보다 로그를 반드시 먼저 저장해야 한다는 규칙이다.
- WAL을 지키면 어떤 순서로 에러가 발생해도 **로그를 이용한 복구가 가능**하다.
- **체크포인트(Checkpoint)**는 일정 간격으로 메모리의 모든 데이터를 하드디스크에 저장하고, 표식을 남기는 작업이다.
- 체크포인트 덕분에 **이미 안전하게 저장된 커밋 완료 트랜잭션에 대한 불필요한 Redo를 생략**할 수 있다.
- **체크포인트 이전에 커밋 완료된 트랜잭션은 Undo도 Redo도 하지 않는다.**
- 체크포인트 작업 순서는 **로그 저장 → 일반 데이터 저장 → 체크포인트 로그 저장** 순이다.
- **그림자 페이징(Shadow Paging)**은 로그 없이 현재 페이지(메모리)와 그림자 페이지(하드디스크) 두 개를 이용해 복구하는 No Undo, No Redo 기법이다.
- 그림자 페이징은 **병행 처리를 지원하지 못한다**는 치명적인 단점이 있다.
- 복구 알고리즘은 **No Undo Redo, Undo No Redo, Undo Redo, No Undo No Redo** 4가지로 분류된다.
- **ARIES**는 복구 작업 자체도 로그에 기록해, 복구 중 에러 발생 시 이미 완료된 복구 작업을 반복하지 않도록 하는 알고리즘이다.
- 백업 센터는 복구 속도와 비용에 따라 **미러 사이트 → 핫 사이트 → 웜 사이트 → 콜드 사이트** 순으로 분류된다.
- 미러 사이트는 즉시 복구, 핫 사이트는 수 시간, 웜 사이트는 수일, 콜드 사이트는 수 주 내 복구가 가능하다.
- 백업 센터 유형 선택 시 **데이터의 비즈니스 가치와 운영 비용**을 함께 고려해야 한다.

---

작성일: 2026-02-21