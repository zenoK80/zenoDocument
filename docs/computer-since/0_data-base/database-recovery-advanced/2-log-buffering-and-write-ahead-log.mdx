---
title: "로그 버퍼링과 로그 우선 기록 규약"
description: "로그 버퍼링과 로그 우선 기록 규약에 대해 초보자도 쉽게 이해할 수 있도록 설명합니다."
slug: "/database-recovery-advanced/2-log-buffering-and-write-ahead-log"
sidebar_label: "로그 버퍼링"
date: "2026-02-21"
---

# 📖 로그 버퍼링과 로그 우선 기록 규약 (Write-Ahead Logging)

데이터베이스 고급 회복 기법의 핵심 개념인 **로그 버퍼링**과 **로그 우선 기록 규약(WAL)**을 처음 듣는 분도 이해할 수 있도록 차근차근 설명해 드리겠습니다. 지난 시간에 덤프(dump, 데이터 전체 복사본)와 로그(log, 작업 기록 파일)를 이용해 데이터베이스를 회복하는 기본 개념을 배웠다면, 이번 시간에는 그 로그를 **어떻게 효율적으로 관리하고**, **어떤 순서로 저장해야 안전한지**를 깊이 있게 다룹니다.

---

## 🗂️ 지난 시간 복습: 데이터베이스 회복의 기본 흐름

본격적인 내용에 앞서, 우리가 배운 내용을 간단히 짚고 넘어가겠습니다.

데이터베이스에서 장애가 발생했을 때 복구하려면 크게 두 가지가 필요합니다.

- **덤프(Dump)**: 일정 시점의 데이터베이스 전체를 백업해 놓은 복사본. 마치 사진 찍듯이 그 순간의 상태를 저장해 두는 것입니다.
- **로그(Log)**: 트랜잭션(작업 묶음)이 수행되는 동안 어떤 작업이 일어났는지를 기록한 파일. "x 값을 100에서 200으로 바꿨다"는 식의 기록이 쌓입니다.

회복할 때는 덤프를 기준점으로 삼고, 이후에 쌓인 로그를 읽어서 복원합니다. 이 과정에서 두 가지 연산이 등장합니다.

| 연산 | 대상 | 설명 |
|------|------|------|
| **리두(Redo)** | 커밋(commit, 성공 완료)이 있는 트랜잭션 | 작업을 다시 수행하여 최신 상태로 만듦 |
| **언두(Undo)** | 커밋이 없는 트랜잭션 | 작업을 취소하여 이전 상태로 되돌림 |

그리고 로그를 이용하는 갱신 방식에는 크게 두 가지가 있었습니다.

- **지연 갱신 기법(Deferred Update)**: 트랜잭션이 완료될 때까지 실제 데이터베이스에 쓰기를 미루는 방식
- **즉시 갱신 기법(Immediate Update)**: 트랜잭션 수행 중에도 바로 데이터베이스에 반영하는 방식

이 기반 위에서, 이제 **로그 파일 자체를 어떻게 관리해야 하는가**라는 심화 주제로 들어가 보겠습니다.

---

## 💾 로그 파일은 어떻게 만들어지는가?

### 트랜잭션 처리와 로그 생성의 관계

트랜잭션이 실행되면 그 안에서 이루어지는 모든 **쓰기(Write) 연산**마다 로그 레코드(log record, 로그 한 줄)가 하나씩 생성됩니다. 마치 일기를 쓰듯이, 작업 하나하나가 로그 파일에 한 줄씩 기록되는 것입니다.

예를 들어 처리해야 할 데이터가 **10,000개(만 개)**라면 어떻게 될까요?

```
[로그 파일 예시]
T1: x = 100 → 200  (x 값을 100에서 200으로 변경)
T1: y = 50  → 150  (y 값을 50에서 150으로 변경)
T1: z = 30  → 90   (z 값을 30에서 90으로 변경)
...
(이런 줄이 만 개 쭉 이어짐)
```

즉, 만 개의 레코드를 처리하면 로그 파일에도 최소 **만 줄** 이상의 로그 레코드가 생깁니다.

### I/O 연산이란 무엇인가?

컴퓨터가 데이터를 처리하는 흐름을 먼저 이해해야 합니다. 데이터는 하드디스크(영구 저장장치)에서 메모리(임시 저장장치)로 읽혀 오고, CPU가 메모리의 데이터를 처리한 후, 결과를 다시 메모리에 쓰고, 최종적으로 하드디스크에 저장합니다.

```
[컴퓨터 데이터 처리 흐름]

하드디스크 ---(Input/인풋)--→ 메모리 ---(Read/읽기)--→ CPU
     ↑                           ↓
  (Output/아웃풋)         (Write/쓰기)
     ↑                           ↓
     └──────────────────────────┘
```

여기서 **I/O(Input/Output, 입출력) 연산**이란 하드디스크와 메모리 사이에서 데이터를 주고받는 작업을 말합니다. 이 I/O 연산은 CPU가 계산하는 속도에 비해 **수백 배에서 수천 배 느린** 작업입니다. 왜냐하면 하드디스크는 물리적인 장치이기 때문입니다.

> 💡 **비유**: CPU가 생각하는 속도가 고속철도라면, 하드디스크에서 데이터를 꺼내오는 속도는 자전거 수준입니다. 그래서 하드디스크를 왔다 갔다 하는 횟수(I/O 횟수)를 줄이는 것이 성능 향상의 핵심입니다.

---

## 🧺 로그 레코드 버퍼링(Log Record Buffering): 왜 모아서 처리하는가?

### 매번 저장하면 생기는 문제

만약 로그 레코드가 생성될 때마다 바로바로 하드디스크에 저장한다면 어떻게 될까요?

```
[매번 저장하는 비효율적인 방식 ❌]

1번 데이터 처리 → 로그 1줄 생성 → 하드디스크에 저장
2번 데이터 처리 → 로그 1줄 생성 → 하드디스크에 저장
3번 데이터 처리 → 로그 1줄 생성 → 하드디스크에 저장
...
10,000번 데이터 처리 → 로그 1줄 생성 → 하드디스크에 저장
```

만 개의 데이터를 처리하면 하드디스크 I/O가 **최소 만 번** 이상 발생합니다. 이것은 마치 엑셀 작업을 할 때 숫자 하나 입력할 때마다 Ctrl+S를 눌러 저장하는 것과 같습니다. 아무도 그렇게 하지 않죠. 너무 비효율적이기 때문입니다.

:::warning 성능 저하의 원인
I/O 연산이 많아질수록 시스템 전체의 성능이 급격히 떨어집니다. 만 번의 I/O는 몇 번의 I/O에 비해 처리 시간이 수십 배~수백 배 더 걸릴 수 있습니다.
:::

### 버퍼링: 모아서 한 번에 처리하기

그래서 데이터베이스는 **버퍼링(Buffering)**이라는 방식을 사용합니다. 버퍼(Buffer)란 메모리 안에 데이터를 임시로 모아두는 공간입니다. 마치 트럭에 짐을 잔뜩 실어서 한 번에 배달하는 것처럼, 로그 레코드를 메모리에 모아두었다가 나중에 한꺼번에 하드디스크에 저장하는 것입니다.

```
[버퍼링을 사용하는 효율적인 방식 ✅]

1번 데이터 처리 → 로그 1줄 생성 → 메모리(로그 버퍼)에 저장
2번 데이터 처리 → 로그 1줄 생성 → 메모리(로그 버퍼)에 저장
3번 데이터 처리 → 로그 1줄 생성 → 메모리(로그 버퍼)에 저장
...
10,000번 데이터 처리 → 로그 1줄 생성 → 메모리(로그 버퍼)에 저장
          ↓
   (적절한 시점에)
          ↓
    메모리 → 하드디스크로 한꺼번에 저장 (I/O 횟수 대폭 감소!)
```

:::info 로그 레코드 버퍼링이란?
**로그 레코드 버퍼링(Log Record Buffering)**은 로그 레코드를 하나하나 하드디스크에 저장하지 않고, 메모리(로그 버퍼)에 모아두었다가 적절한 시점에 한꺼번에 하드디스크로 저장하는 기법입니다. 이를 통해 I/O 횟수를 크게 줄여 데이터베이스 성능을 향상시킵니다.
:::

### 버퍼링이 만들어내는 새로운 문제

그런데 여기서 중요한 문제가 생깁니다. 메모리는 **휘발성(Volatile)** 저장장치입니다. 즉, 전원이 꺼지거나 시스템 장애가 발생하면 메모리에 있던 데이터가 **모두 사라진다**는 뜻입니다.

상황을 정리하면 이렇습니다:
- **일반 데이터**(처리 중인 트랜잭션 데이터)도 메모리에 있음
- **로그 레코드**도 로그 버퍼링 때문에 메모리에 있음
- 시스템 장애 발생 → 메모리 내용 전부 소멸

이 상황에서 **일반 데이터와 로그 레코드 중 어느 것을 먼저 하드디스크에 저장해야 하는가?** 라는 질문이 바로 다음에 설명할 **로그 우선 기록 규약(WAL)**의 핵심입니다.

---

## ✍️ 로그 우선 기록 규약(Write-Ahead Logging, WAL)

### 왜 저장 순서가 중요한가?

하드디스크는 한 번에 하나씩만 데이터를 쓸 수 있습니다(동시에 두 데이터를 쓰면 충돌이 발생). 따라서 **저장 순서를 정해야만 합니다**. 두 가지 시나리오를 비교해 보겠습니다.

#### ❌ 잘못된 순서: 일반 데이터를 먼저 저장하는 경우

```
[시나리오 1: 일반 데이터 먼저 저장 ❌]

Step 1: 일반 데이터 → 하드디스크 저장 (성공!)
Step 2: 로그 레코드 → 하드디스크 저장 중... 💥 에러 발생!

결과:
  - 일반 데이터: 하드디스크에 저장됨 ✅
  - 로그 레코드: 저장 안 됨 ❌

문제:
  → 나중에 장애가 발생해도 로그 파일이 없음
  → 복구 불가능! 😱
```

데이터는 있는데 로그가 없다면, 이 데이터가 올바른 상태인지 확인할 방법이 없습니다. 설령 문제가 생겨도 로그가 없으니 복구할 수가 없는 치명적인 상황이 됩니다.

#### ✅ 올바른 순서: 로그 레코드를 먼저 저장하는 경우

```
[시나리오 2: 로그 레코드 먼저 저장 ✅]

Step 1: 로그 레코드 → 하드디스크 저장 중... 💥 에러 발생!

결과:
  - 로그 레코드: 저장 안 됨
  - 일반 데이터: 저장 안 됨

문제:
  → 아무것도 저장이 안 됐으니 아무 작업도 안 한 것과 동일
  → 복구에 전혀 문제 없음! ✅

--------------------------------------------

Step 1: 로그 레코드 → 하드디스크 저장 (성공!)
Step 2: 일반 데이터 → 하드디스크 저장 중... 💥 에러 발생!

결과:
  - 로그 레코드: 하드디스크에 저장됨 ✅
  - 일반 데이터: 저장 안 됨

문제:
  → 로그가 있으니 덤프 + 로그로 얼마든지 복구 가능! ✅
```

로그를 먼저 저장하면, 어느 단계에서 에러가 나도 복구가 가능합니다. 이것이 바로 **로그 우선 기록 규약(Write-Ahead Logging, WAL)**입니다.

:::tip 핵심 원칙
**"로그 먼저, 데이터 나중"** — 이 순서만 기억하면 WAL의 핵심을 이해한 것입니다.
:::

### WAL의 정식 정의

> **로그 우선 기록 규약(Write-Ahead Logging, WAL)**이란, 데이터 버퍼 블록(일반 데이터)을 하드디스크에 저장하기 전에, 반드시 그 데이터와 관련된 로그 레코드를 먼저 안전한 저장장치(하드디스크)에 기록해야 한다는 규약입니다.

쉽게 말하면 이렇습니다:

- 트랜잭션이 커밋(성공 완료) 상태로 들어가려면, 먼저 그 트랜잭션과 관련된 **모든 로그 레코드를 하드디스크에 기록**해야 합니다.
- 그 다음에야 일반 데이터를 하드디스크에 저장(아웃풋)할 수 있습니다.

| 구분 | 저장 순서 | 이유 |
|------|-----------|------|
| 로그 레코드 | **먼저 (1순위)** | 복구의 근거가 되기 때문 |
| 일반 데이터 | 나중 (2순위) | 로그가 있으면 복구 가능 |

이 규약을 통해 데이터베이스 트랜잭션의 **원자성(Atomicity, 작업이 전부 성공하거나 전부 실패해야 하는 성질)**을 보장할 수 있습니다.

:::note WAL의 영어 이름
WAL은 **W**rite-**A**head **L**ogging의 약자입니다. "Ahead(먼저)"라는 단어가 핵심을 담고 있습니다. 로깅(Logging, 기록)을 먼저(Ahead) 수행하라는 뜻입니다.
:::

---

## 🔖 체크포인트(Checkpoint): 복구 시간을 줄이는 방법

### 로그만 사용할 때의 문제점

WAL 덕분에 로그를 안전하게 관리할 수 있게 됐습니다. 그런데 100만 개의 레코드를 처리했다면 로그 파일에도 100만 줄이 생깁니다. 장애가 발생해서 복구를 해야 할 때, 로그 파일의 **처음부터 끝까지 전부 읽으며 리두/언두 연산**을 수행해야 합니다.

문제는 **이미 안전하게 하드디스크에 저장된 데이터**도 다시 리두 연산을 해야 한다는 점입니다. 굳이 다시 할 필요가 없는 작업을 또 반복하는 것이죠.

:::warning 불필요한 리두 연산
로그 파일을 처음부터 읽으면, 이미 완벽하게 저장된 커밋 트랜잭션들도 또다시 리두 연산을 수행해야 합니다. 데이터가 많을수록 이 낭비는 심해집니다.
:::

### 체크포인트란 무엇인가?

**체크포인트(Checkpoint, 검사점)**는 이 문제를 해결하기 위한 방법입니다. 일정한 시간 간격으로 **"지금까지 처리된 내용을 하드디스크에 저장했다"는 표식(마킹)**을 남기는 것입니다.

> 💡 **비유**: 아래아한글이나 MS Word의 **자동 저장 기능**이 바로 체크포인트와 같은 개념입니다. 10분마다 자동 저장이 된다면, 프로그램이 갑자기 꺼져도 최대 10분 전 상태로 복구됩니다. 처음부터 다시 작성할 필요가 없죠.

체크포인트가 설정되는 순간, 다음 순서로 작업이 진행됩니다:

```
[체크포인트 시점의 작업 순서]

1단계: 메모리(로그 버퍼)의 로그 레코드 → 하드디스크에 저장
       (WAL 원칙에 따라 로그 먼저!)

2단계: 메모리(데이터 버퍼)의 일반 데이터 → 하드디스크에 저장

3단계: 체크포인트 정보 로그 레코드 → 하드디스크에 저장
       ("이 시점에 체크포인트가 설정됐음"을 기록)
```

:::danger 순서를 절대 바꾸면 안 됩니다
체크포인트 수행 시 반드시 **로그 레코드 → 일반 데이터 → 체크포인트 로그** 순서를 지켜야 합니다. WAL 원칙은 체크포인트 내에서도 동일하게 적용됩니다.
:::

### 체크포인트의 핵심 효과

체크포인트를 설정하면 **"체크포인트 이전에 커밋된 트랜잭션은 리두/언두 연산을 수행하지 않아도 된다"**는 것이 핵심입니다.

체크포인트 이전에 커밋된 트랜잭션은 이미 안전하게 하드디스크에 저장되었기 때문입니다. 복구 시 체크포인트 이전의 내용은 건너뛸 수 있으므로 **복구 시간이 대폭 단축**됩니다.

### 체크포인트 알고리즘 단계별 이해

체크포인트 기반 회복 알고리즘은 다음 단계로 동작합니다:

```
[체크포인트 회복 알고리즘]

1단계: 빈 Undo 리스트와 Redo 리스트 준비
       Undo 리스트 = []
       Redo 리스트 = []

2단계: 체크포인트 설정 당시 활동 중인 트랜잭션을 모두 Undo 리스트에 추가
       → 아직 커밋하지 않았을 수 있으니 일단 취소 대상으로 분류

3단계: 체크포인트 이후에 시작된 트랜잭션도 모두 Undo 리스트에 추가
       → 마찬가지로 커밋 여부 불명확

4단계: 로그를 순서대로 검색하며, 커밋 기록이 있는 트랜잭션은
       Undo 리스트에서 제거하고 Redo 리스트로 이동

5단계: 회복 수행
       - Undo 리스트에 남은 트랜잭션: 역방향으로 언두 연산 수행
       - Redo 리스트의 트랜잭션: 순방향으로 리두 연산 수행
```

### 실제 예제로 이해하기

5개의 트랜잭션 T1~T5가 있다고 가정합니다. 아래 타임라인을 보겠습니다.

```
시간 →  ──────────────────────────────────────────────────▶

T1:     [START]──────────[COMMIT]
T2:             [START]────────────────────────[COMMIT]
T3:                    [START]────────────────────────────── (커밋 없음)
T4:                                   [START]───[COMMIT]
T5:                                          [START]──────── (커밋 없음)
                               ↑                      ↑
                           체크포인트              장애 발생
```

이 상황을 알고리즘에 적용해 보겠습니다:

**1단계**: 빈 리스트 준비
```
Undo 리스트 = []
Redo 리스트 = []
```

**2단계**: 체크포인트 설정 당시 활동 중인 트랜잭션 → Undo에 추가
```
체크포인트 시점에 활동 중: T2, T3
Undo 리스트 = [T2, T3]
```

**3단계**: 체크포인트 이후 시작된 트랜잭션 → Undo에 추가
```
체크포인트 이후 시작: T4, T5
Undo 리스트 = [T2, T3, T4, T5]
```

**4단계**: 커밋이 있는 트랜잭션 → Undo에서 제거, Redo로 이동
```
T2: 커밋 있음 → Undo에서 제거, Redo로 이동
T4: 커밋 있음 → Undo에서 제거, Redo로 이동

최종:
Undo 리스트 = [T3, T5]   ← 언두(취소) 대상
Redo 리스트 = [T2, T4]   ← 리두(재수행) 대상
```

**T1은 어디에도 없습니다!** 체크포인트 이전에 이미 커밋되어 저장이 완료된 T1은 **아무 연산도 하지 않아도 됩니다.** 이것이 체크포인트의 가장 핵심적인 효과입니다.

**5단계**: 실제 회복 수행
```
T1: 아무 작업 없음 (체크포인트 이전 커밋 완료)
T2: 체크포인트 이후 구간에 대해서만 리두 연산
T3: 전체 구간에 대해 언두 연산 (처음부터 취소)
T4: 전체 구간에 대해 리두 연산 (체크포인트 이후 시작)
T5: 전체 구간에 대해 언두 연산 (처음부터 취소)
```

:::tip 체크포인트 간격 설정 주의사항
- **간격이 너무 짧으면**: 체크포인트 작업 중에는 다른 트랜잭션이 중단되므로 오히려 성능이 저하됩니다.
- **간격이 너무 길면**: 장애 발생 시 복구해야 할 범위가 넓어져 복구 시간이 오래 걸립니다.
- **최적 간격**: 서비스의 특성과 부하에 따라 적절히 조정해야 합니다.

아래아한글의 자동 저장 간격이 너무 짧으면 작업 중에 자꾸 멈추고, 너무 길면 갑자기 꺼졌을 때 많은 내용을 잃는 것과 같은 원리입니다.
:::

---

## 🪞 그림자 페이징(Shadow Paging): 로그 없이 복구하기

### 그림자 페이징이란?

지금까지 배운 방법들은 모두 로그 파일을 기반으로 했습니다. 그런데 **로그 파일 없이도 복구할 수 있는 방법**이 있습니다. 바로 **그림자 페이징(Shadow Paging)** 기법입니다.

그림자 페이징은 **No-Undo, No-Redo 기법**이라고도 합니다. 언두도 없고 리두도 없다는 뜻으로, 복구 방식이 완전히 다릅니다.

:::info 그림자 페이징의 핵심 아이디어
페이지(Page, 데이터 저장 단위)를 두 개 유지합니다:
- **현재 페이지(Current Page)**: 메모리에 위치, 실제 작업이 이루어지는 곳
- **그림자 페이지(Shadow Page)**: 하드디스크에 위치, 작업 이전의 안전한 복사본
:::

### 그림자 페이징의 동작 원리

```
[그림자 페이징 초기 상태]

실제 데이터: x = 100

현재 페이지 (메모리):   x = 100
그림자 페이지 (하드디스크): x = 100

→ 처음에는 두 페이지의 내용이 동일합니다.
```

```python
# 그림자 페이징 동작 원리 (의사 코드)

# 트랜잭션 시작 시
current_page = copy(shadow_page)  # 그림자 페이지를 복사하여 현재 페이지 생성

# 작업 수행 (현재 페이지만 수정, 그림자 페이지는 건드리지 않음)
current_page['x'] = 200  # x 값을 100 → 200으로 변경
# shadow_page['x']는 여전히 100 (변경 없음)

# 장애 발생 시 (커밋 전)
if 장애발생:
    # 그림자 페이지로 덮어쓰면 됨 → 원래 상태(100)로 복구
    current_page = copy(shadow_page)
    # 결과: x = 100 (원래 값으로 복구 완료)

# 트랜잭션 성공 시 (커밋)
if 커밋성공:
    # 현재 페이지 내용을 그림자 페이지에도 반영
    shadow_page = copy(current_page)
    # 결과: shadow_page['x'] = 200 (새로운 안전한 상태)
```

```
[그림자 페이징 장애 발생 시나리오]

작업: x = 100 → 200으로 변경 중...

현재 페이지 (메모리):   x = 200  ← 변경됨
그림자 페이지 (하드디스크): x = 100  ← 변경 안 됨

💥 장애 발생!

복구: 그림자 페이지(x=100)를 현재 페이지에 덮어씀
결과: x = 100으로 복구 완료 ✅ (로그 파일 없이!)
```

```
[그림자 페이징 커밋 성공 시나리오]

작업: x = 100 → 200으로 변경 완료 ✅

현재 페이지 (메모리):   x = 200
그림자 페이지 (하드디스크): x = 100

커밋 성공! → 그림자 페이지도 200으로 업데이트
결과:
현재 페이지 (메모리):   x = 200
그림자 페이지 (하드디스크): x = 200 ← 새로운 안전한 상태
```

### 그림자 페이징의 장단점

| 구분 | 내용 |
|------|------|
| **장점** | 로그 파일 불필요 → 로그 관련 비용 절약 |
| **장점** | 복구 속도가 매우 빠름 (그림자를 덮어쓰기만 하면 됨) |
| **단점** | 그림자 페이지를 저장할 별도 공간 필요 |
| **단점** | 페이지 테이블이 크면 복사 비용 증가 |
| **단점** | 데이터 단편화(Fragmentation, 데이터가 조각조각 흩어지는 현상) 발생 |
| **치명적 단점** | **병행 처리(Concurrency, 동시에 여러 사용자가 접속) 지원 불가** |

:::danger 그림자 페이징의 치명적 한계
실제 데이터베이스는 동시에 수많은 사용자가 접속하여 데이터를 처리합니다. 그림자 페이징은 **병행 처리를 지원하지 못하기 때문에** 단독으로 사용하기에는 현실적인 한계가 있습니다. 이를 보완하기 위해 로그 기법과 그림자 페이징을 함께 사용하는 혼합 방식을 채택하기도 합니다.
:::

---

## 🔁 ARIES 알고리즘: 복구 중에 또 장애가 나면?

### ARIES가 해결하는 문제

데이터베이스를 복구하는 도중에 또 장애가 발생할 수 있습니다. 예를 들어 90%를 복구했는데 나머지 10%를 복구하던 중 에러가 나면, 기존 방식에서는 처음부터 다시 복구를 시작해야 합니다. 90%의 노력이 물거품이 되는 것이죠.

**ARIES(Algorithms for Recovery and Isolation Exploiting Semantics)**는 이 문제를 해결합니다.

:::info ARIES의 핵심 아이디어
복구 작업 자체에도 로그를 남겨서, 복구 중 장애가 발생해도 **이미 완료된 복구 작업은 반복하지 않는다**.
:::

### ARIES의 세 가지 단계

```
[ARIES 복구 3단계]

1단계: 분석(Analysis)
   - 로그를 읽어 어떤 트랜잭션이 활동 중인지, 커밋됐는지 파악
   - 무엇을 Undo해야 하고, 무엇을 Redo해야 하는지 결정

2단계: 리두(Redo)
   - 커밋된 트랜잭션 재수행
   - 이 과정에서도 WAL 원칙에 따라 로그 기록!
   - (리피팅 히스토리: Repeating History, 역사를 반복하여 장애 전 상태 재현)

3단계: 언두(Undo)
   - 커밋되지 않은 트랜잭션 취소
   - 언두 작업을 하면서도 로그 기록!
   - 언두가 완료된 작업은 다시 언두하지 않음
```

```
[ARIES 언두 중 장애 시나리오]

전체 Undo 해야 할 작업: 100개
↓
90개 Undo 완료 → 각 단계에서 "90번째까지 취소 완료" 로그 기록
10개 남았음
↓
💥 장애 발생!
↓
다시 복구 시작
↓
로그 확인: "90번째까지 취소 완료" 기록이 있음
↓
90개는 건너뛰고 나머지 10개만 Undo 수행 ✅ (효율적!)
```

ARIES는 이처럼 **불필요한 반복 연산을 막아 복구 효율을 극대화**합니다.

---

## 🗃️ 복구 알고리즘 총정리와 백업 센터 운영

### 4가지 데이터베이스 복구 기법 비교

지금까지 배운 내용을 하나의 표로 정리합니다.

| 기법 | 언두(Undo) | 리두(Redo) | 특징 |
|------|-----------|-----------|------|
| **지연 갱신(No-Undo Redo)** | ❌ 불필요 | ✅ 필요 | 커밋 전까지 데이터 미저장, 커밋된 것만 리두 |
| **즉시 갱신 - 유형1(Undo No-Redo)** | ✅ 필요 | ❌ 불필요 | 100% 저장 보장, 커밋 없는 것만 언두 |
| **즉시 갱신 - 유형2(Undo Redo)** | ✅ 필요 | ✅ 필요 | 커밋 없으면 언두, 커밋 있으면 리두 |
| **그림자 페이징(No-Undo No-Redo)** | ❌ 불필요 | ❌ 불필요 | 로그 불사용, 그림자 페이지로 복구 |

### 백업 센터(Backup Site)의 종류

데이터베이스의 회복 능력은 **백업(Backup, 미리 저장해 두는 복사본)**에 달려 있습니다. 백업 센터를 어떻게 운영하느냐에 따라 복구 속도와 비용이 달라집니다.

#### 🔴 미러 사이트(Mirror Site) — 가장 빠른 복구

**실시간으로** 운영 센터와 동일한 데이터를 유지하는 백업 센터입니다. 마치 거울처럼 100% 동일하게 복사됩니다. 운영 센터에 장애가 발생하면 **즉시** 백업 센터로 전환됩니다.

- **복구 시간**: 즉시 (수초 이내)
- **비용**: 매우 높음
- **적합한 경우**: 은행, 증권, 실시간 서비스처럼 1초도 중단되면 안 되는 시스템

#### 🟠 핫 사이트(Hot Site) — 몇 시간 내 복구

미러 사이트와 유사하게 갖춰진 백업 센터이지만, 100% 실시간 동기화는 아닙니다. 어느 정도 동일한 수준의 장비를 갖추고 있어 **몇 시간 이내**에 복구할 수 있습니다.

- **복구 시간**: 수 시간 이내
- **비용**: 높음
- **적합한 경우**: 중요 서비스이지만 약간의 중단은 허용되는 경우

#### 🟡 웜 사이트(Warm Site) — 며칠 내 복구

별도의 백업 센터에 데이터를 따로 옮겨놓는 방식으로 운영합니다. 데이터를 가져오는 시간이 필요해서 복구에 **며칠** 정도 걸립니다.

- **복구 시간**: 수일 이내
- **비용**: 보통
- **적합한 경우**: 복구에 어느 정도 시간이 걸려도 괜찮은 경우

#### 🔵 콜드 사이트(Cold Site) — 한 달 내 복구

가장 최소한의 시설만 갖춘 백업 센터입니다. 장애 발생 시 복구하는 데 **한 달 가량** 소요될 수 있습니다.

- **복구 시간**: 수주~한 달
- **비용**: 가장 낮음
- **적합한 경우**: 데이터의 중요도가 낮거나 비용이 매우 제한적인 경우

:::tip 백업 센터 선택 기준
백업 센터 종류는 **비용(Cost)**과 **서비스 가치(Business Value)**를 함께 고려하여 결정합니다. 은행이나 증권처럼 실시간 정확성이 생명인 서비스는 미러 사이트를, 내부 문서 관리 시스템처럼 일정 중단이 허용되는 서비스는 웜/콜드 사이트를 선택하는 것이 합리적입니다.
:::

---

## ⚠️ 주의사항 및 실무 팁

### 주의사항 1: WAL은 절대 원칙

```
[❌ 절대 이렇게 하면 안 됩니다]

일반 데이터 먼저 저장 → 로그 저장 시도 중 장애 → 복구 불가!

[✅ 반드시 이 순서를 지키세요]

로그 레코드 먼저 저장 → 일반 데이터 저장 → 안전!
```

어떤 상황에서도 WAL 원칙을 어기면 복구 가능성이 사라집니다. 이것은 데이터베이스 시스템의 **절대 규칙**입니다.

### 주의사항 2: 체크포인트 간격 최적화

```
[체크포인트 간격 설정 비교]

너무 짧은 간격 (예: 1분):
→ 체크포인트 중 트랜잭션 중단 빈번
→ 전체 시스템 성능 저하
→ 아래아한글 자동 저장 1분마다 → 컴퓨터 느려짐 (실제 사례!)

너무 긴 간격 (예: 1시간):
→ 장애 발생 시 1시간치 로그 전부 처리 필요
→ 복구 시간 매우 오래 걸림

최적 간격:
→ 시스템 부하, 데이터 중요도, 서비스 특성에 맞게 조정
```

### 주의사항 3: 그림자 페이징은 병행 처리 불가

그림자 페이징은 복구 속도가 빠르고 간단하지만, **여러 사용자가 동시에 접속하는 환경(병행 처리)**에서는 사용할 수 없습니다. 실제 서비스에서는 대부분 로그 기반 방식을 사용하거나, 로그와 그림자 페이징을 혼합하는 방식을 택합니다.

### 주의사항 4: ARIES는 로그를 두 번 씁니다

ARIES에서는 복구 작업(리두/언두) 중에도 WAL 원칙에 따라 로그를 기록합니다. 복구 로그가 없으면 복구 중 장애 시 처음부터 다시 시작해야 하므로, 이 로그 기록은 필수입니다.

---

## 📌 핵심 정리

- **로그 레코드 버퍼링**: I/O 횟수를 줄이기 위해 로그 레코드를 메모리(버퍼)에 모아두었다가 한꺼번에 하드디스크에 저장하는 기법
- **WAL (Write-Ahead Logging, 로그 우선 기록 규약)**: 일반 데이터를 저장하기 전에 반드시 관련 로그 레코드를 먼저 하드디스크에 기록해야 한다는 규약
- **WAL의 목적**: 원자성 보장, 복구 가능성 확보 — 로그가 있어야 복구할 수 있기 때문
- **체크포인트(Checkpoint)**: 일정 간격으로 데이터를 저장하고 표식을 남겨, 복구 시 불필요한 리두 연산을 줄이는 기법
- **체크포인트 이전 커밋 트랜잭션**: 리두/언두 연산 모두 수행하지 않아도 됨 — 이것이 체크포인트의 핵심 효과
- **그림자 페이징(Shadow Paging)**: 현재 페이지(메모리)와 그림자 페이지(하드디스크)를 유지하여 로그 없이 복구하는 No-Undo No-Redo 기법
- **그림자 페이징의 한계**: 병행 처리(동시 다중 사용자) 환경에서 사용 불가
- **ARIES**: 복구 작업 중에도 로그를 기록하여, 복구 중 장애 발생 시 이미 완료된 복구 작업의 반복을 방지하는 알고리즘
- **ARIES 3단계**: 분석(Analysis) → 리두(Redo) → 언두(Undo)
- **미러 사이트**: 실시간 동기화, 즉시 복구, 최고 비용
- **핫 사이트**: 수 시간 내 복구, 높은 비용
- **웜 사이트**: 수일 내 복구, 보통 비용
- **콜드 사이트**: 수주 내 복구, 최저 비용

---

작성일: 2026-02-21